{
  "/docs/infrastructure/new-relic-infrastructure/filter-group/filter-sets-organize-your-infrastructure-hosts": [
    {
      "sections": [
        "Group infrastructure results by specific attributes",
        "Group charts by specific attributes",
        "Combine filter sets and grouping",
        "Increased CPU usage on a single host"
      ],
      "title": "Group infrastructure results by specific attributes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Filter and group"
      ],
      "external_id": "8436b1d0391cd7caa2a79c4080528697ff7a012d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/filter-group/group-infrastructure-results-specific-attributes/",
      "published_at": "2021-10-01T13:01:55Z",
      "updated_at": "2021-03-11T10:49:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our infrastructure monitoring tool, you can use the Group by feature to group chart results by specific attributes. For example, on the Hosts page, you might display the AWS regions with the highest CPU usage grouped by awsRegion. Group by is available near the top of some infrastructure monitoring UI pages. Group charts by specific attributes On some infrastructure pages you can use Group by to group page results and charts by a specific attribute, such as host name, entity ID, or AWS region. The attributes available to group by will depend on your system setup. These may include: Default infrastructure attributes Custom attributes APM-related attributes To group infrastructure results by a specific attribute: On pages that have this feature, select Group by (located beside the time picker). From the dropdown, select an attribute to group by. Combine filter sets and grouping Grouping applies to any filter sets you have selected. By combining filter sets with Group by, you can find detailed system information quickly. Increased CPU usage on a single host On the Filter sets sidebar, you see alert threshold violations as Critical icon or Warning icon on one of your filter sets. To view only the hosts related to the filter set on your Hosts page, click the filter set name. To determine which of the hosts is causing the problem, select Group by, then select the hostname attribute. Review the charts which now show the hosts, by name, with the highest CPU usage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.09306,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Group</em> <em>infrastructure</em> results by specific attributes",
        "sections": "<em>Group</em> <em>infrastructure</em> results by specific attributes",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " monitoring UI pages. <em>Group</em> charts by specific attributes On some <em>infrastructure</em> pages you can use <em>Group</em> by to <em>group</em> page results and charts by a specific attribute, such as host name, entity ID, or AWS region. The attributes available to <em>group</em> by will depend on <em>your</em> system setup. These may include: Default"
      },
      "id": "6043edcd64441fd920378ecf"
    },
    {
      "sections": [
        "On-host integrations metrics",
        "BETA FEATURE",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-10-01T00:13:13Z",
      "updated_at": "2021-09-14T20:50:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentSha",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.4173,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-10-01T13:00:53Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 99.33412,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host <em>filter</em> sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/filter-group/group-infrastructure-results-specific-attributes": [
    {
      "sections": [
        "Filter sets: Organize your hosts",
        "Benefits of filter sets",
        "Create filter sets",
        "Edit filter sets",
        "Delete filter sets",
        "Combine filter sets with grouping",
        "Copy filters from filter set to alerts",
        "Important",
        "Filter set logic",
        "Inclusion and exclusion",
        "Recommended: Select values by matching a string",
        "Tip",
        "Select values individually",
        "And/Or"
      ],
      "title": "Filter sets: Organize your hosts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Filter and group"
      ],
      "external_id": "ae70ce239865f3cb006e2ed47fc9bf3fc0598d81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/filter-group/filter-sets-organize-your-infrastructure-hosts/",
      "published_at": "2021-09-30T23:07:10Z",
      "updated_at": "2021-03-11T08:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic infrastructure monitoring, you can combine filters into a filter set to organize hosts based on criteria that matter the most to you. Read on to learn about the benefits, use, and logic of filter sets. Benefits of filter sets You can create filter sets using available attributes or tags. For example, you can organize your infrastructure into categories such as: Regions Operating system versions Hosts associated with Docker containers Test environments You can share filter sets with other people in your account, and you can quickly identify infrastructure problems by checking the color-coded health status of each host in the filter set. Create filter sets The default infrastructure filter set is All hosts, and it serves as a template for you to create filter sets. To create a filter set: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. If All hosts is not displayed in the left sidebar, open that filter set by selecting Saved filter sets > All hosts. In All hosts, click Filter hosts. In the list, click an item to see a list of values. Click Include or Exclude (see Filter set logic). Click values individually or enter text to match multiple values. Continue adding filters until you have the filter set you want. To name your filter, click the icon, type a name, and click Save. Edit filter sets To change an existing filter set: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. In the sidebar, click Saved filter sets to open a list. Locate the filter set by scrolling or by entering a search term. Click the filter set to open it. In the sidebar, click an option to update your filter set, and then save. Delete filter sets You can delete any saved filter set except the default All hosts. Go to one.newrelic.com > Infrastructure > Settings > Filter sets. Click to delete the filter set. Combine filter sets with grouping On some pages you can use Group by to group chart results by specific attributes. For example, on the Hosts page, you can group by awsRegion to display the AWS regions with the highest CPU usage. Grouping applies to the selected filter sets. By combining filter sets with grouping, you can find detailed system information quickly. For an example of using these tools to troubleshoot a problem, see Combining filter sets and grouping. Copy filters from filter set to alerts When you create an alert condition, you can build filters individually, or you can copy all the filters from a filter set into a new alert condition. This is a quick shortcut to populate a new alert condition with some filters. Important When you copy filter set filters to a new alert condition, these filters are no longer tied to the filter set. If you make changes to the filter set, the alert filters are not affected. To copy filter set filters to a new alert condition: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. In the sidebar, click Saved filter sets to open a list. Locate the filter set by scrolling or by entering a search term. Click the filter set to open it. Mouse over any chart and click > Create alert. Enter an alert condition name. Make adjustments to filters as necessary. Complete the remaining alert fields (see Create alert conditions). Filter set logic When you create a filter set, you generate a list of attributes and/or tags that narrow the results. This section explains how filter sets apply various rules to the list. Inclusion and exclusion As part of building a filter set, you designate whether a filter should include or exclude entities that match certain values. The way the inclusion or exclusion works depends on how you select values: Recommended: Select values by matching a string You can generate a list of values by entering a string that you want values to match. This is useful for matching multiple values. Tip String matching efficiently generates a list of values, and this approach scales as you add new entities. Here is the logic filter sets use with string matching: Comparator Logic Include If you click Include and then enter a string that you want values to match, the filter uses the comparator LIKE, which means the results include any entities that are like the string. For example, you could filter by the term East-, and all entities that contain that term are returned. Exclude If you click Exclude and then enter a string that you want values to match, the filter uses the comparator NOT LIKE, which means the results exclude any entities that are like the string. For example, you could filter by the term West-, and all entities that do not contain that term are returned. Select values individually You can click through the list of attributes/tags to identify individual values. Tip This approach does not scale well if you add new entities. Here is the logic filter sets use with individual value selection: Comparator Logic Include If you click Include and then click specific values, the filter uses the comparator IN, which means the filter looks for entities that exactly match one or more values in your list of selections. Exclude If you click Exclude and then click specific values, the filter set uses the comparator NOT IN, which means the filter returns all entities that do not exactly match one or more values in your list of selections. And/Or Filter sets use the logical operators AND and OR behind the scenes to join the data. Here are the rules for AND and OR: When you click values from multiple attributes or tags, they are joined by AND. When you click values from within an attribute or tags, they are joined by OR. The filter results display hosts for which both of the following are true: Hosts containing any one of the selected infrastructure agent versions Hosts in any one of the selected AWS availability zones",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.08954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Filter</em> sets: Organize <em>your</em> hosts",
        "sections": "<em>Filter</em> sets: Organize <em>your</em> hosts",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " or tags. For example, you can organize <em>your</em> <em>infrastructure</em> into categories such as: Regions Operating system versions Hosts associated with Docker containers Test environments You can share <em>filter</em> sets with other people in <em>your</em> account, and you can quickly identify <em>infrastructure</em> problems by checking"
      },
      "id": "6043ed8ee7b9d289955799cb"
    },
    {
      "sections": [
        "On-host integrations metrics",
        "BETA FEATURE",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-10-01T00:13:13Z",
      "updated_at": "2021-09-14T20:50:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentSha",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.4173,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-10-01T13:00:53Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 99.33412,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host <em>filter</em> sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes": [
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Caution",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-10-01T12:35:22Z",
      "updated_at": "2021-09-20T19:26:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. Caution If you have filtered your Host Not Reporting condition using tags or labels and then remove a critical tag or label from a targeted host, the system will open a Host Not Reporting violation, since it will characterize that host as having lost its connection. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Alternatively, you can add the hostStatus: shutdown tag to your host along with checking the option mentioned above. This will stop all Host Not Reporting violations from opening for that host, as long as that tag is on it, regardless of agent version or OS. Removing the tag will allow the system to open Host Not Reporting violations for that host again. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.95374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    },
    {
      "sections": [
        "Alerts for infrastructure: Add, edit, or view host alert information",
        "Create alert conditions for infrastructure",
        "Important",
        "Other infrastructure alert condition methods",
        "Use the Alerts UI",
        "Use the Infrastructure UI",
        "Use infrastructure settings for integrations",
        "Tip",
        "View host alert events",
        "Update or delete host alert information",
        "Use New Relic Alerts to monitor your entire infrastructure",
        "Add a description",
        "Add or edit a runbook URL",
        "Violation time limit for violations",
        "Alert conditions that generate too-long NRQL queries"
      ],
      "title": "Alerts for infrastructure: Add, edit, or view host alert information",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "00207a1020aa29ea6d5d5bbb8e806a50a5966f80",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information/",
      "published_at": "2021-09-30T23:08:13Z",
      "updated_at": "2021-08-02T12:47:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic Alerts. Instead, you can immediately select your filter set and tailor the alert condition directly from the chart you are viewing. This helps you proactively manage and monitor the alerting system for your environment. Any alert violations will be created per entity within the filter set. Create alert conditions for infrastructure Alert conditions apply to alert policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to use other types of notification channels, create a new policy from within the Alerts UI. Important The Infrastructure REST API has a limit of 3,700 alert conditions, including both active and disabled conditions. The API, whether used directly or via the UI, will reject all requests to add any additional alert conditions beyond the 3,700 alert condition limit. To add an infrastructure alert condition to an alerts policy: Go to one.newrelic.com > Infrastructure, then select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Type a meaningful condition name. Select the Alert type, or refer to the examples to decide which type to select. Create individual filters, or copy all the filters from a filter set to identify the hosts that you want the alert condition to use. Important For more information about the rules behind filters, see Filter set logic. Define the Critical (required) and Warning (optional, if available) thresholds for triggering the alert notification. Optional: To create the condition criteria proactively but not receive alert notifications at this time, turn off the Enabled checkbox option. Select an existing policy for the new condition. OR Select the option to create a new policy and identify the email for alert notifications. Optional: Add a runbook url. Optional: Set Violation time limit for violations (this defaults to 24 hours). Select Create. Important If New Relic hasn't received a cloud integration service's attribute in the past 60 minutes, we refer to this as a \"silent attribute,\" and it won't be available to use as an alert condition in the UI. In this situation, you can use the API to create alert conditions for silent attributes. Other infrastructure alert condition methods You can also use these other methods to create an infrastructure alert condition: Use the Alerts UI Go to one.newrelic.com > Alerts & AI > Alerts > Alert policies > New alert policy > Create new condition, then select Infrastructure as the product. Use the Infrastructure UI Go to one.newrelic.com > Infrastructure. Select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Use infrastructure settings for integrations Tip Use this method to create an alert condition for infrastructure integrations. Go to one.newrelic.com > Infrastructure > Settings > Alerts, and then click Create alert condition. Name and describe the alert condition. Click the Integrations alert type, and then select the integration data source you'd like to use. Use the Filter entities dropdown to limit your condition to specific attributes. Use the Define thresholds dropdowns to define your condition's thresholds, and then click Create. The configuration settings are optional. You can always update them later. View host alert events Anyone included in the policy's notification channels receive alert notifications directly. In addition, anyone with permissions for your New Relic account can view Infrastructure alert incidents and individual violations through the user interface. Go to one.newrelic.com > Infrastructure > Events. To change the hosts or time frame, use the search window, Filter set, or Time functions. From the Events list, select the alert violation. To view detailed information in Alerts about the selected violation, select the link. Update or delete host alert information To edit, disable (or re-enable), or delete host alert information: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Use the search window or Select all checkbox to locate one or more alert conditions. Select any of the available functions to edit, disable, enable, or delete the selected conditions. Use New Relic Alerts to monitor your entire infrastructure New Relic Alerts provides a single, coordinated alerting tool across all of your New Relic products. This allows you to manage alert policies and conditions that focus on the metrics for entities that you care about the most, such as Docker containers, JVMs, and more. Alert features Features in Infrastructure Alert conditions Create: Use the Infrastructure UI. View, change, disable (or re-enable), or delete: Use the Infrastructure Settings > Alerts UI. Information on alerts View summary information about events: Use the Infrastructure Events UI. View detailed information about alert incidents or individual violations: Use the Alerts UI or the notification channel integrated with the associated policy. Alert policies View, add, change, disable, or delete: For policies with a variety of notification channels: Use the Alerts UI. For policies only needing email notifications: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Create a new policy, and add one or more email addresses as needed. Add host conditions to an existing policy: Use the Infrastructure UI. Notification channels To view, add, change, or delete available notification options: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Search for the condition or policy name. From the list of conditions, select the policy link to view notification channel information in the Alerts UI. Add a description The use of the Description field is available for these alert condition types: NRQL conditions: add a description using the NerdGraph API. Infrastructure conditions: add a description using the UI or the REST API. The text you place in an alert condition's Description field is passed downstream to associated violations and notifications. A description can be used for several purposes, including: Capturing the reason for the alert condition. Defining the signal being monitored. Defining next steps. Add metadata to downstream systems. You can use template substitution to insert values from the attributes in the associated violation event. The template format is {{attributeName}}. For the attributes you can use when creating a description, see Violation event attributes. One available attribute is the special {{tag.*}} attribute. This attribute prefix is used to access any of the tag values that are included with the target signal, or any of the entity tags that are associated with the target signal. If there are entity tags associated with your violation, then they can be accessed using the entity tag name. An example of this would be {{tag.aws.awsRegion}}. When entity tags are available to use, you see them included with the violation, and displayed when you view the violations in an incident. This field has a maximum character size of 4,000. Add or edit a runbook URL The alert condition creation process includes an option for setting a URL for runbook instructions. This lets you link to information or standard procedures for handling a violation. Before adding or updating the link, make sure you use a valid URL. To add, update, or delete an alert condition's runbook URL: Select an alert condition, and make changes to the Runbook URL link. Save the condition. In order to be saved, the URL must be a valid URL. Violation time limit for violations The violation time limit allows you to define a time period after which violations will be force-closed. By default, violation time limit is 24 hours. To add or update an alert condition's violation time limit: Select an alert condition, and make changes to the violation time limit. Save the condition. Alert conditions that generate too-long NRQL queries Alert conditions created for infrastructure rely on behind-the-scenes NRQL queries, and NRQL queries have a 4096-character limit. This means that if your condition generates a very complex NRQL query that filters on many elements (for example, including many hosts or many tags), it will exceed this limit and display an error message saying that the condition failed. To solve this problem, reduce the number of elements you are using in your alert condition. For example: Problem Solution Hosts If you entered a large number of hosts that caused the condition to fail, reduce the number of hosts. Use substrings to target hosts. For example, instead of targeting prod-host-01, prod-host-02, and prod-host-03, just target all hosts with prod-host-0 in the name. Entities Edit your alert condition to target specific attributes that apply to the entities you're trying to target. Create custom attributes for the entities you want to target, and use those attributes in your alert condition. For more information, see Best practices for filtering in infrastructure alerts in New Relic's Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.21194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> for <em>infrastructure</em>: Add, edit, or view host <em>alert</em> information",
        "sections": "Create <em>alert</em> <em>conditions</em> for <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "With New Relic&#x27;s <em>infrastructure</em> monitoring, you can create <em>alert</em> <em>conditions</em> directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic <em>Alerts</em>"
      },
      "id": "6043fa3428ccbc401d2c60b9"
    },
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-09-30T23:08:14Z",
      "updated_at": "2021-07-27T14:15:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. The no_trigger_on field is optional. When set to [\"shutdown\"] this enables the Don't trigger alerts for hosts that perform a clean shutdown infrastructure condition option. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12, \"no_trigger_on\": [\"shutdown\"] } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. For new conditions, if a value is not provided, the following default values are used: All conditions: 24 hours When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.09799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerting-examples": [
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Caution",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-10-01T12:35:22Z",
      "updated_at": "2021-09-20T19:26:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. Caution If you have filtered your Host Not Reporting condition using tags or labels and then remove a critical tag or label from a targeted host, the system will open a Host Not Reporting violation, since it will characterize that host as having lost its connection. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Alternatively, you can add the hostStatus: shutdown tag to your host along with checking the option mentioned above. This will stop all Host Not Reporting violations from opening for that host, as long as that tag is on it, regardless of agent version or OS. Removing the tag will allow the system to open Host Not Reporting violations for that host again. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.95374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    },
    {
      "sections": [
        "Alerts for infrastructure: Add, edit, or view host alert information",
        "Create alert conditions for infrastructure",
        "Important",
        "Other infrastructure alert condition methods",
        "Use the Alerts UI",
        "Use the Infrastructure UI",
        "Use infrastructure settings for integrations",
        "Tip",
        "View host alert events",
        "Update or delete host alert information",
        "Use New Relic Alerts to monitor your entire infrastructure",
        "Add a description",
        "Add or edit a runbook URL",
        "Violation time limit for violations",
        "Alert conditions that generate too-long NRQL queries"
      ],
      "title": "Alerts for infrastructure: Add, edit, or view host alert information",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "00207a1020aa29ea6d5d5bbb8e806a50a5966f80",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information/",
      "published_at": "2021-09-30T23:08:13Z",
      "updated_at": "2021-08-02T12:47:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic Alerts. Instead, you can immediately select your filter set and tailor the alert condition directly from the chart you are viewing. This helps you proactively manage and monitor the alerting system for your environment. Any alert violations will be created per entity within the filter set. Create alert conditions for infrastructure Alert conditions apply to alert policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to use other types of notification channels, create a new policy from within the Alerts UI. Important The Infrastructure REST API has a limit of 3,700 alert conditions, including both active and disabled conditions. The API, whether used directly or via the UI, will reject all requests to add any additional alert conditions beyond the 3,700 alert condition limit. To add an infrastructure alert condition to an alerts policy: Go to one.newrelic.com > Infrastructure, then select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Type a meaningful condition name. Select the Alert type, or refer to the examples to decide which type to select. Create individual filters, or copy all the filters from a filter set to identify the hosts that you want the alert condition to use. Important For more information about the rules behind filters, see Filter set logic. Define the Critical (required) and Warning (optional, if available) thresholds for triggering the alert notification. Optional: To create the condition criteria proactively but not receive alert notifications at this time, turn off the Enabled checkbox option. Select an existing policy for the new condition. OR Select the option to create a new policy and identify the email for alert notifications. Optional: Add a runbook url. Optional: Set Violation time limit for violations (this defaults to 24 hours). Select Create. Important If New Relic hasn't received a cloud integration service's attribute in the past 60 minutes, we refer to this as a \"silent attribute,\" and it won't be available to use as an alert condition in the UI. In this situation, you can use the API to create alert conditions for silent attributes. Other infrastructure alert condition methods You can also use these other methods to create an infrastructure alert condition: Use the Alerts UI Go to one.newrelic.com > Alerts & AI > Alerts > Alert policies > New alert policy > Create new condition, then select Infrastructure as the product. Use the Infrastructure UI Go to one.newrelic.com > Infrastructure. Select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Use infrastructure settings for integrations Tip Use this method to create an alert condition for infrastructure integrations. Go to one.newrelic.com > Infrastructure > Settings > Alerts, and then click Create alert condition. Name and describe the alert condition. Click the Integrations alert type, and then select the integration data source you'd like to use. Use the Filter entities dropdown to limit your condition to specific attributes. Use the Define thresholds dropdowns to define your condition's thresholds, and then click Create. The configuration settings are optional. You can always update them later. View host alert events Anyone included in the policy's notification channels receive alert notifications directly. In addition, anyone with permissions for your New Relic account can view Infrastructure alert incidents and individual violations through the user interface. Go to one.newrelic.com > Infrastructure > Events. To change the hosts or time frame, use the search window, Filter set, or Time functions. From the Events list, select the alert violation. To view detailed information in Alerts about the selected violation, select the link. Update or delete host alert information To edit, disable (or re-enable), or delete host alert information: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Use the search window or Select all checkbox to locate one or more alert conditions. Select any of the available functions to edit, disable, enable, or delete the selected conditions. Use New Relic Alerts to monitor your entire infrastructure New Relic Alerts provides a single, coordinated alerting tool across all of your New Relic products. This allows you to manage alert policies and conditions that focus on the metrics for entities that you care about the most, such as Docker containers, JVMs, and more. Alert features Features in Infrastructure Alert conditions Create: Use the Infrastructure UI. View, change, disable (or re-enable), or delete: Use the Infrastructure Settings > Alerts UI. Information on alerts View summary information about events: Use the Infrastructure Events UI. View detailed information about alert incidents or individual violations: Use the Alerts UI or the notification channel integrated with the associated policy. Alert policies View, add, change, disable, or delete: For policies with a variety of notification channels: Use the Alerts UI. For policies only needing email notifications: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Create a new policy, and add one or more email addresses as needed. Add host conditions to an existing policy: Use the Infrastructure UI. Notification channels To view, add, change, or delete available notification options: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Search for the condition or policy name. From the list of conditions, select the policy link to view notification channel information in the Alerts UI. Add a description The use of the Description field is available for these alert condition types: NRQL conditions: add a description using the NerdGraph API. Infrastructure conditions: add a description using the UI or the REST API. The text you place in an alert condition's Description field is passed downstream to associated violations and notifications. A description can be used for several purposes, including: Capturing the reason for the alert condition. Defining the signal being monitored. Defining next steps. Add metadata to downstream systems. You can use template substitution to insert values from the attributes in the associated violation event. The template format is {{attributeName}}. For the attributes you can use when creating a description, see Violation event attributes. One available attribute is the special {{tag.*}} attribute. This attribute prefix is used to access any of the tag values that are included with the target signal, or any of the entity tags that are associated with the target signal. If there are entity tags associated with your violation, then they can be accessed using the entity tag name. An example of this would be {{tag.aws.awsRegion}}. When entity tags are available to use, you see them included with the violation, and displayed when you view the violations in an incident. This field has a maximum character size of 4,000. Add or edit a runbook URL The alert condition creation process includes an option for setting a URL for runbook instructions. This lets you link to information or standard procedures for handling a violation. Before adding or updating the link, make sure you use a valid URL. To add, update, or delete an alert condition's runbook URL: Select an alert condition, and make changes to the Runbook URL link. Save the condition. In order to be saved, the URL must be a valid URL. Violation time limit for violations The violation time limit allows you to define a time period after which violations will be force-closed. By default, violation time limit is 24 hours. To add or update an alert condition's violation time limit: Select an alert condition, and make changes to the violation time limit. Save the condition. Alert conditions that generate too-long NRQL queries Alert conditions created for infrastructure rely on behind-the-scenes NRQL queries, and NRQL queries have a 4096-character limit. This means that if your condition generates a very complex NRQL query that filters on many elements (for example, including many hosts or many tags), it will exceed this limit and display an error message saying that the condition failed. To solve this problem, reduce the number of elements you are using in your alert condition. For example: Problem Solution Hosts If you entered a large number of hosts that caused the condition to fail, reduce the number of hosts. Use substrings to target hosts. For example, instead of targeting prod-host-01, prod-host-02, and prod-host-03, just target all hosts with prod-host-0 in the name. Entities Edit your alert condition to target specific attributes that apply to the entities you're trying to target. Create custom attributes for the entities you want to target, and use those attributes in your alert condition. For more information, see Best practices for filtering in infrastructure alerts in New Relic's Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.21194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> for <em>infrastructure</em>: Add, edit, or view host <em>alert</em> information",
        "sections": "Create <em>alert</em> <em>conditions</em> for <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "With New Relic&#x27;s <em>infrastructure</em> monitoring, you can create <em>alert</em> <em>conditions</em> directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic <em>Alerts</em>"
      },
      "id": "6043fa3428ccbc401d2c60b9"
    },
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-09-30T23:08:14Z",
      "updated_at": "2021-07-27T14:15:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. The no_trigger_on field is optional. When set to [\"shutdown\"] this enables the Don't trigger alerts for hosts that perform a clean shutdown infrastructure condition option. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12, \"no_trigger_on\": [\"shutdown\"] } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. For new conditions, if a value is not provided, the following default values are used: All conditions: 24 hours When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.09799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information": [
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Caution",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-10-01T12:35:22Z",
      "updated_at": "2021-09-20T19:26:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. Caution If you have filtered your Host Not Reporting condition using tags or labels and then remove a critical tag or label from a targeted host, the system will open a Host Not Reporting violation, since it will characterize that host as having lost its connection. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Alternatively, you can add the hostStatus: shutdown tag to your host along with checking the option mentioned above. This will stop all Host Not Reporting violations from opening for that host, as long as that tag is on it, regardless of agent version or OS. Removing the tag will allow the system to open Host Not Reporting violations for that host again. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.95367,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    },
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-09-30T23:08:14Z",
      "updated_at": "2021-07-27T14:15:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. The no_trigger_on field is optional. When set to [\"shutdown\"] this enables the Don't trigger alerts for hosts that perform a clean shutdown infrastructure condition option. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12, \"no_trigger_on\": [\"shutdown\"] } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. For new conditions, if a value is not provided, the following default values are used: All conditions: 24 hours When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.09799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-09-30T23:07:11Z",
      "updated_at": "2021-07-27T13:58:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances on one host This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.09418,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances"
      },
      "id": "603eb49128ccbca939eba74a"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts": [
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Caution",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-10-01T12:35:22Z",
      "updated_at": "2021-09-20T19:26:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. Caution If you have filtered your Host Not Reporting condition using tags or labels and then remove a critical tag or label from a targeted host, the system will open a Host Not Reporting violation, since it will characterize that host as having lost its connection. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Alternatively, you can add the hostStatus: shutdown tag to your host along with checking the option mentioned above. This will stop all Host Not Reporting violations from opening for that host, as long as that tag is on it, regardless of agent version or OS. Removing the tag will allow the system to open Host Not Reporting violations for that host again. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.95367,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    },
    {
      "sections": [
        "Alerts for infrastructure: Add, edit, or view host alert information",
        "Create alert conditions for infrastructure",
        "Important",
        "Other infrastructure alert condition methods",
        "Use the Alerts UI",
        "Use the Infrastructure UI",
        "Use infrastructure settings for integrations",
        "Tip",
        "View host alert events",
        "Update or delete host alert information",
        "Use New Relic Alerts to monitor your entire infrastructure",
        "Add a description",
        "Add or edit a runbook URL",
        "Violation time limit for violations",
        "Alert conditions that generate too-long NRQL queries"
      ],
      "title": "Alerts for infrastructure: Add, edit, or view host alert information",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "00207a1020aa29ea6d5d5bbb8e806a50a5966f80",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information/",
      "published_at": "2021-09-30T23:08:13Z",
      "updated_at": "2021-08-02T12:47:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic Alerts. Instead, you can immediately select your filter set and tailor the alert condition directly from the chart you are viewing. This helps you proactively manage and monitor the alerting system for your environment. Any alert violations will be created per entity within the filter set. Create alert conditions for infrastructure Alert conditions apply to alert policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to use other types of notification channels, create a new policy from within the Alerts UI. Important The Infrastructure REST API has a limit of 3,700 alert conditions, including both active and disabled conditions. The API, whether used directly or via the UI, will reject all requests to add any additional alert conditions beyond the 3,700 alert condition limit. To add an infrastructure alert condition to an alerts policy: Go to one.newrelic.com > Infrastructure, then select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Type a meaningful condition name. Select the Alert type, or refer to the examples to decide which type to select. Create individual filters, or copy all the filters from a filter set to identify the hosts that you want the alert condition to use. Important For more information about the rules behind filters, see Filter set logic. Define the Critical (required) and Warning (optional, if available) thresholds for triggering the alert notification. Optional: To create the condition criteria proactively but not receive alert notifications at this time, turn off the Enabled checkbox option. Select an existing policy for the new condition. OR Select the option to create a new policy and identify the email for alert notifications. Optional: Add a runbook url. Optional: Set Violation time limit for violations (this defaults to 24 hours). Select Create. Important If New Relic hasn't received a cloud integration service's attribute in the past 60 minutes, we refer to this as a \"silent attribute,\" and it won't be available to use as an alert condition in the UI. In this situation, you can use the API to create alert conditions for silent attributes. Other infrastructure alert condition methods You can also use these other methods to create an infrastructure alert condition: Use the Alerts UI Go to one.newrelic.com > Alerts & AI > Alerts > Alert policies > New alert policy > Create new condition, then select Infrastructure as the product. Use the Infrastructure UI Go to one.newrelic.com > Infrastructure. Select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Use infrastructure settings for integrations Tip Use this method to create an alert condition for infrastructure integrations. Go to one.newrelic.com > Infrastructure > Settings > Alerts, and then click Create alert condition. Name and describe the alert condition. Click the Integrations alert type, and then select the integration data source you'd like to use. Use the Filter entities dropdown to limit your condition to specific attributes. Use the Define thresholds dropdowns to define your condition's thresholds, and then click Create. The configuration settings are optional. You can always update them later. View host alert events Anyone included in the policy's notification channels receive alert notifications directly. In addition, anyone with permissions for your New Relic account can view Infrastructure alert incidents and individual violations through the user interface. Go to one.newrelic.com > Infrastructure > Events. To change the hosts or time frame, use the search window, Filter set, or Time functions. From the Events list, select the alert violation. To view detailed information in Alerts about the selected violation, select the link. Update or delete host alert information To edit, disable (or re-enable), or delete host alert information: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Use the search window or Select all checkbox to locate one or more alert conditions. Select any of the available functions to edit, disable, enable, or delete the selected conditions. Use New Relic Alerts to monitor your entire infrastructure New Relic Alerts provides a single, coordinated alerting tool across all of your New Relic products. This allows you to manage alert policies and conditions that focus on the metrics for entities that you care about the most, such as Docker containers, JVMs, and more. Alert features Features in Infrastructure Alert conditions Create: Use the Infrastructure UI. View, change, disable (or re-enable), or delete: Use the Infrastructure Settings > Alerts UI. Information on alerts View summary information about events: Use the Infrastructure Events UI. View detailed information about alert incidents or individual violations: Use the Alerts UI or the notification channel integrated with the associated policy. Alert policies View, add, change, disable, or delete: For policies with a variety of notification channels: Use the Alerts UI. For policies only needing email notifications: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Create a new policy, and add one or more email addresses as needed. Add host conditions to an existing policy: Use the Infrastructure UI. Notification channels To view, add, change, or delete available notification options: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Search for the condition or policy name. From the list of conditions, select the policy link to view notification channel information in the Alerts UI. Add a description The use of the Description field is available for these alert condition types: NRQL conditions: add a description using the NerdGraph API. Infrastructure conditions: add a description using the UI or the REST API. The text you place in an alert condition's Description field is passed downstream to associated violations and notifications. A description can be used for several purposes, including: Capturing the reason for the alert condition. Defining the signal being monitored. Defining next steps. Add metadata to downstream systems. You can use template substitution to insert values from the attributes in the associated violation event. The template format is {{attributeName}}. For the attributes you can use when creating a description, see Violation event attributes. One available attribute is the special {{tag.*}} attribute. This attribute prefix is used to access any of the tag values that are included with the target signal, or any of the entity tags that are associated with the target signal. If there are entity tags associated with your violation, then they can be accessed using the entity tag name. An example of this would be {{tag.aws.awsRegion}}. When entity tags are available to use, you see them included with the violation, and displayed when you view the violations in an incident. This field has a maximum character size of 4,000. Add or edit a runbook URL The alert condition creation process includes an option for setting a URL for runbook instructions. This lets you link to information or standard procedures for handling a violation. Before adding or updating the link, make sure you use a valid URL. To add, update, or delete an alert condition's runbook URL: Select an alert condition, and make changes to the Runbook URL link. Save the condition. In order to be saved, the URL must be a valid URL. Violation time limit for violations The violation time limit allows you to define a time period after which violations will be force-closed. By default, violation time limit is 24 hours. To add or update an alert condition's violation time limit: Select an alert condition, and make changes to the violation time limit. Save the condition. Alert conditions that generate too-long NRQL queries Alert conditions created for infrastructure rely on behind-the-scenes NRQL queries, and NRQL queries have a 4096-character limit. This means that if your condition generates a very complex NRQL query that filters on many elements (for example, including many hosts or many tags), it will exceed this limit and display an error message saying that the condition failed. To solve this problem, reduce the number of elements you are using in your alert condition. For example: Problem Solution Hosts If you entered a large number of hosts that caused the condition to fail, reduce the number of hosts. Use substrings to target hosts. For example, instead of targeting prod-host-01, prod-host-02, and prod-host-03, just target all hosts with prod-host-0 in the name. Entities Edit your alert condition to target specific attributes that apply to the entities you're trying to target. Create custom attributes for the entities you want to target, and use those attributes in your alert condition. For more information, see Best practices for filtering in infrastructure alerts in New Relic's Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.21194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> for <em>infrastructure</em>: Add, edit, or view host <em>alert</em> information",
        "sections": "Create <em>alert</em> <em>conditions</em> for <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "With New Relic&#x27;s <em>infrastructure</em> monitoring, you can create <em>alert</em> <em>conditions</em> directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic <em>Alerts</em>"
      },
      "id": "6043fa3428ccbc401d2c60b9"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-09-30T23:07:11Z",
      "updated_at": "2021-07-27T13:58:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances on one host This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.09418,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances"
      },
      "id": "603eb49128ccbca939eba74a"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range": [
    {
      "sections": [
        "Infrastructure monitoring Hosts page",
        "System tab",
        "System tab functions",
        "APM and infrastructure data",
        "Important",
        "Network tab",
        "Network tab functions",
        "Processes tab",
        "Tip",
        "Processes tab functions",
        "Storage tab",
        "Storage tab functions",
        "Docker containers tab",
        "Docker containers tab functions"
      ],
      "title": "Infrastructure monitoring Hosts page",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "41d8a2ac3ecbbdee164fd0bec6ac94bb3e8def64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page/",
      "published_at": "2021-09-30T23:07:10Z",
      "updated_at": "2021-08-27T07:06:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to help determine root causes. You can also set alert notifications to help prevent problems. To view your hosts information, go to one.newrelic.com > Infrastructure > Hosts, then click any of the following tabs: System: Overview of your hosts' performance Network: Bandwidth and error data about your network interfaces Processes: Data about CPU percentage, I/O bytes, and memory usage for individual or groups of processes Storage: Resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations Docker containers: CPU percentage, I/O bytes, and memory usage for individual or group of containers System tab Here are the default graphs shown on the Hosts page. For additional chart options, select the dropdown for any chart. CPU %: On the System tab, CPU Percent is a derived metric that is part of the SystemSample event. The CPU percentage is not collected by New Relic, but derived from several other metrics. Specifically, the cpuPercent attribute is an aggregation of cpuUserPercent, cpuSystemPercent, cpuIoWaitPercent and cpuStealPercent. Load average five minute: represents an average of the number of tasks waiting to do work on a system over the last 5 minutes. Memory free %: compares the amount of free memory bytes to the amount of used memory bytes. For explanations of different chart metrics, see Default infrastructure attributes and events. Functions for adjusting chart data include: Select different host groups: Use the host filter. Change time range: Use the time picker above the charts, or drag and select a time range on a chart. Change the number of elements on charts: use the Chart shows dropdown. Change data used to order hosts: Use the table below the charts to order the chart elements by different metrics; for example, from highest to lowest CPU user % to lowest, or from lowest to highest Disk free. System tab functions Here are some of the things you can do from the System tab: If you want to... Do this... Filter and group hosts Use filter sets to show only hosts matching certain criteria, or use group by to aggregate the results. Understand host health Use the Health column of the table. To see more details about specific violations, select the health status icons. Find root causes of issues Use the Events heatmap at the top of the page to compare performance to important events happening in your infrastructure. For more, see Events heatmap. Set an alert condition for a metric Mouse over a chart, select and then Create alert. View host's alert threshold violation If present, select the host's Critical icon or Warning icon. APM and infrastructure data If you have APM data associated with your infrastructure data, there are several ways to access your APM data on the Hosts page: Use the hosts filter to filter on hosts running specific applications. In the host list below the charts, select the Application column to filter on specific applications. From the chart selector dropdown beside a chart's name, select one of the application-related charts. Important APM charts in infrastructure monitoring do not have View query or Create alert options like the other infrastructure charts do. For more about using APM and infrastructure monitoring together, see APM data in infrastructure. Network tab The Network page provides real-time visibility into the health and performance of individual hosts, web servers, or other groups of resources across your network. Default charts show bandwidth metrics by packet, bandwidth by bytes, and errors per second. Details about individual interfaces can help you: Examine saturation levels across your network or for selected filter sets. Compare load balances between specific resources. Identify unexpected differences in capacity patterns between similar hosts. Evaluate the top five network errors that New Relic automatically presents for the selected time period. This real-time network data can then help you determine whether to resolve errors by reconfiguring your network, rebalancing the loads, or taking other preventative maintenance actions before needing to make a purchase decision. From the Network tab you can view bandwidth and error data about your network interfaces. The Network page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Network page chart, see NetworkSample attributes. Network tab functions Here are some of the things you can do from the Network tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings, including: Received Bytes Received Dropped Received Errors Received Packets Transmitted Bytes Transmitted Dropped Transmitted Errors Transmitted Packets Search and filter the list Type in the Search interfaces search bar to filter the list to only those items containing the text you've typed. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add items to chart The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item from a chart, select its name below the chart. Set an alert condition for a metric Mouse over a chart, select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Processes tab Important By default, the infrastructure agent doesn't send data about the operating system's processes unless you use guided install. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Use the Processes tab to get information about processes running on your hosts, and to set alerts on process metrics. The Processes tab shows data such as CPU percentage, I/O bytes, and memory usage for individual processes or groupings of processes. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Pinpoint processes that are causing performance issues. Create alerts for conditions such as CPU percentage and memory usage. On the Processes page, CPU percent is scoped to individual processes, rather than hosts. Because of this, the CPU percent metric does not take into account the resources of the entire system. Instead, it shows how much of a single CPU core each process is taking. Example Here's an example of how to pinpoint an issue and set an alert: You notice on the Hosts page that a cluster has a CPU percentage much higher than normal. You go to the Processes page and filter down to that cluster's processes. You notice that several instances of the same process have excessive CPU percentage. After fixing the issue, you decide to create an alert condition that triggers when the CPU percentage for that process type exceeds a certain threshold. For a technical explanation of the attributes used to populate the Processes page chart, see ProcessSample attributes. Tip You cannot start, stop, or restart processes from the UI. Instead, follow standard procedures to start, stop, check, or restart the infrastructure agent manually. Processes tab functions Here are some of the things you can do from the Processes tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as hostID and entityName. If you are monitoring AWS EC2 instances, EC2-related attributes such as awsRegion will be available. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker metrics To view process usage by Docker containers, see Docker instrumentation. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: Memory: Resident or virtual size CPU percentage Disk I/O: Read or write Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Storage tab The Storage page allows you to monitor your resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations. This can help you to: Examine unexpected patterns; for example, a cluster of mirrored machines that do not process I/O tasks uniformly. Monitor usage levels before disk space completely runs out. Set alert conditions to notify you about problems with one or more hosts; for example, long processing times for read or write operations, disk availability or utilization based on percentage or bytes, etc. Make informed decisions about where to redistribute hosts with higher or lower than normal processing requests. Use data to help plan for additions or changes to your infrastructure budget before an emergency arises. The Storage page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Storage page chart, see StorageSample attributes. Storage tab functions Here are some of the things you can do from the Storage tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker on the upper right to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings. Choices include: Total Utilization % Read Utilization % Write Utilization % Disk Used Bytes Disk Free Bytes I/O Read Operations I/O Write Operations Search and filter the list Type in the Search devices search bar to filter the list. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add/remove chart items The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item, select its name below the chart. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Docker containers tab Use the Docker containers tab to get information about the containers running on your hosts, and to set alerts on container metrics. The Docker containers tab shows data such as CPU percentage, I/O bytes, and memory usage for individual containers or groupings of containers. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Identify containers that are experiencing performance issues. Create alerts for conditions such as CPU percentage and memory usage. Docker containers tab functions Here are some of the things you can do from the Docker containers tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as image and operatingSystem. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker integration dashboard To open the Docker integration dashboard, click the Dashboard link above the data table. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: CPU: Used cores, kernel percentage Memory: Size limit, cache bytes I/O: Write count per second, total bytes Network: Errors per second, packets Process: Process count, restart count Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. View host's alert threshold violation Select the host's Critical icon or Warning icon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.5699,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "sections": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": "-related charts. Important APM charts in <em>infrastructure</em> <em>monitoring</em> do not have View query or Create alert options like the other <em>infrastructure</em> charts do. For more about using APM and <em>infrastructure</em> <em>monitoring</em> together, see APM data in <em>infrastructure</em>. Network tab The Network page provides real-time"
      },
      "id": "60440a6d196a675f6c960f58"
    },
    {
      "sections": [
        "Infrastructure Inventory page: Search your entire infrastructure",
        "Inventory item naming",
        "Tip",
        "Page functions",
        "Filter the data",
        "Search inventory",
        "View inventory item details",
        "View host's alert threshold violations",
        "Inventory data collection",
        "Linux built-in agent data",
        "Windows built-in agent data",
        "Amazon AWS cloud integrations inventory",
        "Inventory data retention",
        "Chart data attributes"
      ],
      "title": "Infrastructure Inventory page: Search your entire infrastructure",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "64aef10b24b74ac3c0f070358d37f3cab099e5b2",
      "image": "https://docs.newrelic.com/static/2d17c192725956ff09b5e987be5b997b/747d8/inventory-name-source-path.jpg",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure/",
      "published_at": "2021-10-01T12:35:21Z",
      "updated_at": "2021-03-11T12:47:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can collect detailed information about a system's configuration per host, including system modules, configuration files, metadata, packages, services, user sessions, etc. The Inventory page provides a real-time, filterable, searchable view into each host's configuration. Use the Inventory page to: Ensure a version update was applied successfully across all your hosts. Audit version discrepancies across your hosts. Quickly identify which hosts require an update to fix a security vulnerability. To view and search your inventory data: Go to one.newrelic.com > Infrastructure > Inventory. Inventory item naming The infrastructure inventory is a qualified namespace (structured like a directory) that organizes inventory items into names that resemble a source path. The inventory item name is comprised of three elements: Element Description Category Basic, top level type of data source, typically based on its role in the system. Common examples include config, package, kernel, user session, services, and modules. Source The specific data source for the inventory item. Label The name of the specific inventory item; for example, the filename, package name, or system setting name. Tip For detailed metadata and other information about your hosts, use tagging with New Relic One. Page functions Use Inventory page functions to find information about a particular item on your hosts: Filter the data Use Filter Sets to show only hosts matching certain criteria. Search inventory Search for an inventory item using the search function. For example, if you want to find information related to OpenSSL, search openssl. The search term is matched again the inventory item name. View inventory item details Inventory item details provide host and system information for each host it resides on according to the New Relic inventory item name. If you have different versions of the same item on other hosts, New Relic detects that and flags them on the Inventory page with the variant hosts label and lists each host running each version. Item details are attributes (key/value pairs) that are dictated by their source. Specific attributes are generally stable over time, but new ones may be added and others could be deprecated. Attributes carry the critical metadata that are at the heart of each inventory item. Common inventory item attributes include: Variant hosts (hostname) Architecture Description Essential Priority Status Version View host's alert threshold violations To view one or more host's alert threshold violations, select the host's Critical icon or Warning icon. Inventory data collection Inventory is collected from the infrastructure agent's built-in data collectors, Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the Infrastructure monitoring's user interface. Linux built-in agent data The infrastructure agent collects this data for Linux systems. Category Source Data collected using... applications apm APM Language Agent metadata config selinux sestatus -b, semodule -l selinux-policies sestatus -b, semodule -l selinux-modules sestatus -b, semodule -l sshd /etc/sshd_config (PermitRootLogin, PermitEmptyPasswords, PasswordAuthentication, and ChallengeResponseAuthentication only) kernel modules /sbin/modinfo, /sbin/lsmod, /proc/modules sysctl /proc/sys metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), hostname -f, hostname cloud_security_groups Cloud provider security-groups system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name facter facter -p -j services daemontool ps -e, svstat systemd initctl list upstart systemctl -l, systemctl show, modinfo, lsmod supervisord /var/run/supervisor.sock unix socket connection, supervisor.getAllProcessInfo pidfile var/run, find -L -name, /proc/N/status, /proc/N/stat sessions users who system network_interfaces net.Interfaces() packages dpkg dpkg-query -W -f rpm rpm -qa Windows built-in agent data The infrastructure agent collects this data for Windows systems. Category Source Data collected using... applications apm APM language agent metadata metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), Registry (SYSTEM \\ CurrentControlSet \\ Services \\ Tcpip \\ Parameters (Domain, DhcpDomain, Hostname) system kernel32.dll (GetPhysicallyInstalledSystemMemory), WMI (Win32_OperatingSystem, Win32_Processor), os.Hostname() services windows_services WMI (Win32_Service WHERE State = \"Running\" AND StartMode = \"Auto\") system network_interfaces net.Interfaces() packages windows_programs Registry (SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\, SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\) windows_updates WMI (Win32_QuickFixEngineering) (off by default) Amazon AWS cloud integrations inventory Data collected varies by Amazon Elastic Compute Cloud (EC2) integration. For more information, see New Relic's individual Amazon Integrations documentation. Inventory data retention Inventory data is real-time. If a host stops reporting, its inventory data still displays for up to 24 hours. Chart data attributes For a technical explanation about attributes used to populate the Inventory page, see Default infrastructure attributes and events. This includes a summary of common events by operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.51697,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "sections": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": ", Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the <em>Infrastructure</em> <em>monitoring</em>&#x27;s user interface. Linux built-in agent data The <em>infrastructure</em> agent collects"
      },
      "id": "60440a6d64441fdf50378ee7"
    },
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-09-30T23:09:10Z",
      "updated_at": "2021-03-11T11:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > E * *vents. The Events * * page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.51535,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change": [
    {
      "sections": [
        "Events heatmap: Examine patterns in time range"
      ],
      "title": "Events heatmap: Examine patterns in time range",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "bc50e789884c9c4eea404d558d4070519a3eab0c",
      "image": "https://docs.newrelic.com/static/96c3e087c9dfb8b4cb4ad72b79c47e94/c1b63/infra-events-timeline.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range/",
      "published_at": "2021-09-30T23:09:10Z",
      "updated_at": "2021-09-08T16:49:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The events heatmap provides a snapshot of the infrastructure events occurring within the same time range as the displayed metrics. The darker the color on the heatmap, the more events occurred during that time period. By comparing the heatmap to the charts on the infrastructure page, you can quickly pinpoint issues in your ecosystem. For example, if a massive CPU spike occurs, you can click on the events heatmap for that time range to find the event that caused it. From there you can dive deeper to uncover the real issue. one.newrelic.com > Infrastructure: The heatmap on Infrastructure monitoring UI pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several Infrastructure UI pages, including: System Network Processes Storage Events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.52582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>monitoring</em> <em>UI</em> pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several <em>Infrastructure</em> <em>UI</em> pages, including: System Network Processes Storage Events"
      },
      "id": "603e8455196a67833da83dc2"
    },
    {
      "sections": [
        "Infrastructure monitoring Hosts page",
        "System tab",
        "System tab functions",
        "APM and infrastructure data",
        "Important",
        "Network tab",
        "Network tab functions",
        "Processes tab",
        "Tip",
        "Processes tab functions",
        "Storage tab",
        "Storage tab functions",
        "Docker containers tab",
        "Docker containers tab functions"
      ],
      "title": "Infrastructure monitoring Hosts page",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "41d8a2ac3ecbbdee164fd0bec6ac94bb3e8def64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page/",
      "published_at": "2021-09-30T23:07:10Z",
      "updated_at": "2021-08-27T07:06:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to help determine root causes. You can also set alert notifications to help prevent problems. To view your hosts information, go to one.newrelic.com > Infrastructure > Hosts, then click any of the following tabs: System: Overview of your hosts' performance Network: Bandwidth and error data about your network interfaces Processes: Data about CPU percentage, I/O bytes, and memory usage for individual or groups of processes Storage: Resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations Docker containers: CPU percentage, I/O bytes, and memory usage for individual or group of containers System tab Here are the default graphs shown on the Hosts page. For additional chart options, select the dropdown for any chart. CPU %: On the System tab, CPU Percent is a derived metric that is part of the SystemSample event. The CPU percentage is not collected by New Relic, but derived from several other metrics. Specifically, the cpuPercent attribute is an aggregation of cpuUserPercent, cpuSystemPercent, cpuIoWaitPercent and cpuStealPercent. Load average five minute: represents an average of the number of tasks waiting to do work on a system over the last 5 minutes. Memory free %: compares the amount of free memory bytes to the amount of used memory bytes. For explanations of different chart metrics, see Default infrastructure attributes and events. Functions for adjusting chart data include: Select different host groups: Use the host filter. Change time range: Use the time picker above the charts, or drag and select a time range on a chart. Change the number of elements on charts: use the Chart shows dropdown. Change data used to order hosts: Use the table below the charts to order the chart elements by different metrics; for example, from highest to lowest CPU user % to lowest, or from lowest to highest Disk free. System tab functions Here are some of the things you can do from the System tab: If you want to... Do this... Filter and group hosts Use filter sets to show only hosts matching certain criteria, or use group by to aggregate the results. Understand host health Use the Health column of the table. To see more details about specific violations, select the health status icons. Find root causes of issues Use the Events heatmap at the top of the page to compare performance to important events happening in your infrastructure. For more, see Events heatmap. Set an alert condition for a metric Mouse over a chart, select and then Create alert. View host's alert threshold violation If present, select the host's Critical icon or Warning icon. APM and infrastructure data If you have APM data associated with your infrastructure data, there are several ways to access your APM data on the Hosts page: Use the hosts filter to filter on hosts running specific applications. In the host list below the charts, select the Application column to filter on specific applications. From the chart selector dropdown beside a chart's name, select one of the application-related charts. Important APM charts in infrastructure monitoring do not have View query or Create alert options like the other infrastructure charts do. For more about using APM and infrastructure monitoring together, see APM data in infrastructure. Network tab The Network page provides real-time visibility into the health and performance of individual hosts, web servers, or other groups of resources across your network. Default charts show bandwidth metrics by packet, bandwidth by bytes, and errors per second. Details about individual interfaces can help you: Examine saturation levels across your network or for selected filter sets. Compare load balances between specific resources. Identify unexpected differences in capacity patterns between similar hosts. Evaluate the top five network errors that New Relic automatically presents for the selected time period. This real-time network data can then help you determine whether to resolve errors by reconfiguring your network, rebalancing the loads, or taking other preventative maintenance actions before needing to make a purchase decision. From the Network tab you can view bandwidth and error data about your network interfaces. The Network page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Network page chart, see NetworkSample attributes. Network tab functions Here are some of the things you can do from the Network tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings, including: Received Bytes Received Dropped Received Errors Received Packets Transmitted Bytes Transmitted Dropped Transmitted Errors Transmitted Packets Search and filter the list Type in the Search interfaces search bar to filter the list to only those items containing the text you've typed. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add items to chart The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item from a chart, select its name below the chart. Set an alert condition for a metric Mouse over a chart, select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Processes tab Important By default, the infrastructure agent doesn't send data about the operating system's processes unless you use guided install. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Use the Processes tab to get information about processes running on your hosts, and to set alerts on process metrics. The Processes tab shows data such as CPU percentage, I/O bytes, and memory usage for individual processes or groupings of processes. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Pinpoint processes that are causing performance issues. Create alerts for conditions such as CPU percentage and memory usage. On the Processes page, CPU percent is scoped to individual processes, rather than hosts. Because of this, the CPU percent metric does not take into account the resources of the entire system. Instead, it shows how much of a single CPU core each process is taking. Example Here's an example of how to pinpoint an issue and set an alert: You notice on the Hosts page that a cluster has a CPU percentage much higher than normal. You go to the Processes page and filter down to that cluster's processes. You notice that several instances of the same process have excessive CPU percentage. After fixing the issue, you decide to create an alert condition that triggers when the CPU percentage for that process type exceeds a certain threshold. For a technical explanation of the attributes used to populate the Processes page chart, see ProcessSample attributes. Tip You cannot start, stop, or restart processes from the UI. Instead, follow standard procedures to start, stop, check, or restart the infrastructure agent manually. Processes tab functions Here are some of the things you can do from the Processes tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as hostID and entityName. If you are monitoring AWS EC2 instances, EC2-related attributes such as awsRegion will be available. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker metrics To view process usage by Docker containers, see Docker instrumentation. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: Memory: Resident or virtual size CPU percentage Disk I/O: Read or write Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Storage tab The Storage page allows you to monitor your resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations. This can help you to: Examine unexpected patterns; for example, a cluster of mirrored machines that do not process I/O tasks uniformly. Monitor usage levels before disk space completely runs out. Set alert conditions to notify you about problems with one or more hosts; for example, long processing times for read or write operations, disk availability or utilization based on percentage or bytes, etc. Make informed decisions about where to redistribute hosts with higher or lower than normal processing requests. Use data to help plan for additions or changes to your infrastructure budget before an emergency arises. The Storage page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Storage page chart, see StorageSample attributes. Storage tab functions Here are some of the things you can do from the Storage tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker on the upper right to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings. Choices include: Total Utilization % Read Utilization % Write Utilization % Disk Used Bytes Disk Free Bytes I/O Read Operations I/O Write Operations Search and filter the list Type in the Search devices search bar to filter the list. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add/remove chart items The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item, select its name below the chart. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Docker containers tab Use the Docker containers tab to get information about the containers running on your hosts, and to set alerts on container metrics. The Docker containers tab shows data such as CPU percentage, I/O bytes, and memory usage for individual containers or groupings of containers. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Identify containers that are experiencing performance issues. Create alerts for conditions such as CPU percentage and memory usage. Docker containers tab functions Here are some of the things you can do from the Docker containers tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as image and operatingSystem. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker integration dashboard To open the Docker integration dashboard, click the Dashboard link above the data table. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: CPU: Used cores, kernel percentage Memory: Size limit, cache bytes I/O: Write count per second, total bytes Network: Errors per second, packets Process: Process count, restart count Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. View host's alert threshold violation Select the host's Critical icon or Warning icon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.56989,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "sections": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": "-related charts. Important APM charts in <em>infrastructure</em> <em>monitoring</em> do not have View query or Create alert options like the other <em>infrastructure</em> charts do. For more about using APM and <em>infrastructure</em> <em>monitoring</em> together, see APM data in <em>infrastructure</em>. Network tab The Network page provides real-time"
      },
      "id": "60440a6d196a675f6c960f58"
    },
    {
      "sections": [
        "Infrastructure Inventory page: Search your entire infrastructure",
        "Inventory item naming",
        "Tip",
        "Page functions",
        "Filter the data",
        "Search inventory",
        "View inventory item details",
        "View host's alert threshold violations",
        "Inventory data collection",
        "Linux built-in agent data",
        "Windows built-in agent data",
        "Amazon AWS cloud integrations inventory",
        "Inventory data retention",
        "Chart data attributes"
      ],
      "title": "Infrastructure Inventory page: Search your entire infrastructure",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "64aef10b24b74ac3c0f070358d37f3cab099e5b2",
      "image": "https://docs.newrelic.com/static/2d17c192725956ff09b5e987be5b997b/747d8/inventory-name-source-path.jpg",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure/",
      "published_at": "2021-10-01T12:35:21Z",
      "updated_at": "2021-03-11T12:47:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can collect detailed information about a system's configuration per host, including system modules, configuration files, metadata, packages, services, user sessions, etc. The Inventory page provides a real-time, filterable, searchable view into each host's configuration. Use the Inventory page to: Ensure a version update was applied successfully across all your hosts. Audit version discrepancies across your hosts. Quickly identify which hosts require an update to fix a security vulnerability. To view and search your inventory data: Go to one.newrelic.com > Infrastructure > Inventory. Inventory item naming The infrastructure inventory is a qualified namespace (structured like a directory) that organizes inventory items into names that resemble a source path. The inventory item name is comprised of three elements: Element Description Category Basic, top level type of data source, typically based on its role in the system. Common examples include config, package, kernel, user session, services, and modules. Source The specific data source for the inventory item. Label The name of the specific inventory item; for example, the filename, package name, or system setting name. Tip For detailed metadata and other information about your hosts, use tagging with New Relic One. Page functions Use Inventory page functions to find information about a particular item on your hosts: Filter the data Use Filter Sets to show only hosts matching certain criteria. Search inventory Search for an inventory item using the search function. For example, if you want to find information related to OpenSSL, search openssl. The search term is matched again the inventory item name. View inventory item details Inventory item details provide host and system information for each host it resides on according to the New Relic inventory item name. If you have different versions of the same item on other hosts, New Relic detects that and flags them on the Inventory page with the variant hosts label and lists each host running each version. Item details are attributes (key/value pairs) that are dictated by their source. Specific attributes are generally stable over time, but new ones may be added and others could be deprecated. Attributes carry the critical metadata that are at the heart of each inventory item. Common inventory item attributes include: Variant hosts (hostname) Architecture Description Essential Priority Status Version View host's alert threshold violations To view one or more host's alert threshold violations, select the host's Critical icon or Warning icon. Inventory data collection Inventory is collected from the infrastructure agent's built-in data collectors, Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the Infrastructure monitoring's user interface. Linux built-in agent data The infrastructure agent collects this data for Linux systems. Category Source Data collected using... applications apm APM Language Agent metadata config selinux sestatus -b, semodule -l selinux-policies sestatus -b, semodule -l selinux-modules sestatus -b, semodule -l sshd /etc/sshd_config (PermitRootLogin, PermitEmptyPasswords, PasswordAuthentication, and ChallengeResponseAuthentication only) kernel modules /sbin/modinfo, /sbin/lsmod, /proc/modules sysctl /proc/sys metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), hostname -f, hostname cloud_security_groups Cloud provider security-groups system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name facter facter -p -j services daemontool ps -e, svstat systemd initctl list upstart systemctl -l, systemctl show, modinfo, lsmod supervisord /var/run/supervisor.sock unix socket connection, supervisor.getAllProcessInfo pidfile var/run, find -L -name, /proc/N/status, /proc/N/stat sessions users who system network_interfaces net.Interfaces() packages dpkg dpkg-query -W -f rpm rpm -qa Windows built-in agent data The infrastructure agent collects this data for Windows systems. Category Source Data collected using... applications apm APM language agent metadata metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), Registry (SYSTEM \\ CurrentControlSet \\ Services \\ Tcpip \\ Parameters (Domain, DhcpDomain, Hostname) system kernel32.dll (GetPhysicallyInstalledSystemMemory), WMI (Win32_OperatingSystem, Win32_Processor), os.Hostname() services windows_services WMI (Win32_Service WHERE State = \"Running\" AND StartMode = \"Auto\") system network_interfaces net.Interfaces() packages windows_programs Registry (SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\, SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\) windows_updates WMI (Win32_QuickFixEngineering) (off by default) Amazon AWS cloud integrations inventory Data collected varies by Amazon Elastic Compute Cloud (EC2) integration. For more information, see New Relic's individual Amazon Integrations documentation. Inventory data retention Inventory data is real-time. If a host stops reporting, its inventory data still displays for up to 24 hours. Chart data attributes For a technical explanation about attributes used to populate the Inventory page, see Default infrastructure attributes and events. This includes a summary of common events by operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.51697,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "sections": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": ", Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the <em>Infrastructure</em> <em>monitoring</em>&#x27;s user interface. Linux built-in agent data The <em>infrastructure</em> agent collects"
      },
      "id": "60440a6d64441fdf50378ee7"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-there-are-no-logs": [
    {
      "sections": [
        "Infrastructure agent logging behavior",
        "Logging severity levels",
        "Important",
        "Log formatting",
        "Log rotation",
        "Logrotate config file sample",
        "Tip",
        "Smart verbose mode",
        "Logging before Infrastructure agent v1.4.9",
        "Integration log management",
        "Integration STDERR expected format"
      ],
      "title": "Infrastructure agent logging behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "0dc6570e893e47c4d5b5c4232283432926c6476a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/infrastructure-agent-logging-behavior/",
      "published_at": "2021-09-30T23:01:43Z",
      "updated_at": "2021-03-16T07:31:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure agent gathers its own data as well as integrations's logs and consolidates them in a single source. By default, logs appear in standard-output and are added to a log file. To disable logs in standard output, see the agent's config options. Logging severity levels Infrastructure uses a subset of the standard Syslog severity levels: ERROR: Error conditions met WARN: Warning conditions met INFO: Informational messages DEBUG: Contains debug-level messages (useful when troubleshooting) Important DEBUG level is only shown when the verbose mode is enabled. Log formatting For infrastructure agent v1.4.9 or higher, log messages are inlined with context values. This offers better grouping and filtering; for example: containerized agent found in container containerID: VALUE Copy By default, Infrastructure logs are formatted as text: In foreground mode, log output is colored, without a timestamp: DEBUG Sending deltas divided in blocks component=PatchSender mentityKey=ohaimaci mnumberOfBlocks=1 Copy In background mode, logs are timestamped output, used when running as a service or dumping logs to a file: time=\"2019-07-12T09:54:15+02:00\" level=info msg=\"Agent service manager shutdown completed successfully.\" component=AgentService service=newrelic-infra Copy Alternatively, logs can be formatted as a JSON file: {\"context\":{},\"level\":\"info\",\"msg\":\"upstart_interval_sec: 0\",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} {\"context\":{},\"level\":\"info\",\"msg\":\"plugin_dir: \",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} Copy To change the log format, see the agent configuration settings. Log rotation The infrastructure agent does not provide any native log rotation or compression mechanism. Instead, we encourage you to use consolidated log rotation tools, such as the Linux logrotate tool, which is usually installed by default in most Linux distributions. Logrotate can be configured as an entry in /etc/logrotate.conf, or as a file in the /etc/logrotate.d directory. Logrotate config file sample A sample logrotate config file looks like this: /var/log/newrelic-infra/newrelic-infra.log { copytruncate compress daily dateext maxage 7 } Copy Where: /var/log/newrelic-infra/newrelic-infra.log: The Infrastructure agent log file. It must match the log_file configuration parameter in the /etc/newrelic-infra.yml file. copytruncate: Indicates that the log file is truncated but not deleted when it is rotated. This configuration option is mandatory, otherwise the log file will be deleted and won’t be recreated. compress: Compresses (usually in Gzip format) the rotated log files. daily: The agent rotates logs daily. dateext: Appends a date (by default, in the format YYYYMMDD) to the rotated log file (e.g. newrelic-infra.log-20190708.gz) maxage 7: Makes logrotate remove rotated files after 7 days. Tip For a complete description of the logrotate configuration options, see the Linux Logrotate documentation. Since logrotate is usually executed automatically as a cron job, verify that there is a logrotate entry in cron (for example, /etc/cron.daily/logrotate) similar to: #!/bin/sh /usr/sbin/logrotate -s /var/lib/logrotate/logrotate.status /etc/logrotate.conf EXITVALUE=$? if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\" fi exit 0 Copy Smart verbose mode For infrastructure agent versions 1.9.0 or higher, you can enable smart verbose mode for logs. Smart verbose mode prevents debug messages being logged until an error message is logged. Once an error has been logged, the cached debug messages are logged, but only the most recent number of configured debug messages. For example, if you have a configured limit of 10, after an error is logged, only the 10 most recent debug messages are logged, and older logs are discarded. For more information on how to enable smart verbose mode and the debug message limit, see Infrastructure configuration settings. Logging before Infrastructure agent v1.4.9 Here is a comparison of functionality for Infrastructure agent versions before and after v1.4.9: Agent v1.4.9 and higher Before v1.4.9 Foreground mode logged. The agent couldn't log some entries in foreground mode because the logging service wasn't able to write data until the agent was completely configured. Logs in text and JSON formats. Logs in text only. Logs displayed as inline text. Logs displayed as static literals in a single, decontextualized line. Integration log management Integrations write JSON payloads into STDOUT and plain-text (JSON structured in the future) logs into STDERR. The infrastructure agent handles integration STDERR lines and forward this output into the agent one, usually the service log. Agent handles each STDERR line as follows: when agent runs in verbose mode: it just forwards the full STDERR line as a DEBUG agent log entry placing integration line contexts within the ` msg ` field. otherwise: it parses the line against the expected format (see below) and only logs as agent ERROR level, entries produced by integrations with ` fatal ` or ` error ` severity levels. In this case fields are extracted and forwarded in structured manner (therefore if JSON output is enabled for the agent fields become queryable. Integration STDERR expected format A line is expected to be a list of key-value pairs separated by an equal character. Keys can contain any character, whereas values can have three different formats: string: < quote>any character including escaped quotes \\ \" < quote> map: & { any character} word: any character except spaces Internally agent used this regex to extract the fields: ([^\\s]*?)=(\".*?[^\\\\]\"|&{.*?}|[^\\s]*) Copy For instance, this line: time=\"2015-03-26T01:27:38-04:00\" level=error msg=\"Foo bar baz\" foo=bar Copy Will generate a structured agent log line with these fields: - \"time\": \"2015-03-26T01:27:38-04:00\" - \"level\": \"error\" - \"msg\": \"Foo bar baz\" - \"foo\": \"bar\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.01999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "sections": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "New Relic&#x27;s <em>infrastructure</em> agent gathers its own data as well as integrations&#x27;s <em>logs</em> and consolidates them in a single source. By default, <em>logs</em> appear in standard-output and are added to a <em>log</em> file. To disable <em>logs</em> in standard output, see the agent&#x27;s config options. Logging severity levels"
      },
      "id": "603eb3a228ccbc6badeba7a5"
    },
    {
      "sections": [
        "Generate logs for troubleshooting the infrastructure agent",
        "Problem",
        "Important",
        "Solution",
        "Smart verbose mode",
        "Forward the agent logs to New Relic Logs",
        "Notes for specific systems",
        "Containerized agent on CoreOS"
      ],
      "title": "Generate logs for troubleshooting the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "a0c2ca22e3fca2b3add8c94d211adffce686661c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/generate-logs-troubleshooting-infrastructure/",
      "published_at": "2021-10-01T08:29:57Z",
      "updated_at": "2021-03-16T06:35:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting your infrastructure agent, generate verbose logs for a few minutes to find and investigate errors. This can be useful for your own troubleshooting or when working with New Relic Support. Important Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. If you have New Relic infrastructure agent 1.4.0 or higher, you can automate this process by using the newrelic-infra-ctl command. For more information, see the troubleshooting binary documentation. Solution Generating verbose log files requires editing your configuration file. For a sample config file that includes all applicable settings, see the example template. To generate detailed logs: Step Procedures Edit your newrelic-infra.yml file: Enable verbose logging: verbose: 1. (If you use a containerized infrastructure agent on CoreOS, see system-specific notes.) Set log_file to a convenient log file location. Restart the agent so the agent notices the new settings. Let your host run at normal load for about three minutes to generate sufficient logging data. Return your settings to default: Disable verbose logging by setting verbose: 0 in newrelic-infra.yml. Optional: Disable logging to a custom file by removing the log_file line from newrelic-infra.yml. Restart the agent so the agent notices the new settings. Examine the log file for errors. If you need to send your log file to New Relic Support: Include the line in your log file that contains the agent version: New Relic infrastructure agent version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your newrelic-infra.yml. Smart verbose mode Sometimes errors don't occur until after quite some time has passed. This makes debugging difficult, because typically verbose logs are only enabled for a short period time; otherwise there will be many debug logs. For example, if an error occurs one hour after the infrastructure agent has started, getting debug logs around the time of the error can be tricky or impractical. As of infrastructure agent v1.9.0 or higher, you can use smart verbose mode for logs. Smart verbose mode only logs the most recent debug messages after an error has been logged. This allows you to leave smart verbose mode running until an error occurs, without logging lots of irrelevant debug messages, and only logging the most recent debug messages. (The number of messages is determined by your configuration.) For more information on smart verbose mode, see the Infrastructure agent logging behavior docs, and use the Infrastructure configuration settings documentation for details on how to enable smart verbose mode. Forward the agent logs to New Relic Logs The Infrastructure agent can be configured to send its own logs to New Relic Logs. This can be useful for troubleshooting issues with log forwarding, the Infrastructure agent, or when contacting support. For details on how to enable log forwarding for the Infrastructure agent, see Troubleshoot log forwarding. Notes for specific systems These are some additional notes and requirements for specific systems, used to supplement the general logging instructions: Containerized agent on CoreOS If you are using a containerized infrastructure agent on CoreOS: Choose one of these options to change the log level to verbose: Recommended: Set the environment variable NRIA_VERBOSE to 1. Running this on the command line would look like: -e NRIA_VERBOSE=1 Copy OR Edit the config file to set verbose: 1. (Editing the config file in a container is not recommended, because it requires rebuilding the image twice: once to add verbose logging and once to remove it.) Use journalctl to collect the logs: journalctl -u newrelic-infra > newrelic-infra.log Copy Set the verbose logging level back to 0 after collecting logs for a few minutes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.01839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "sections": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " verbose mode. Forward the agent <em>logs</em> to New Relic <em>Logs</em> The <em>Infrastructure</em> agent can be configured to send its own <em>logs</em> to New Relic <em>Logs</em>. This can be useful for <em>troubleshooting</em> issues with <em>log</em> forwarding, the <em>Infrastructure</em> agent, or when contacting support. For details on how to enable <em>log</em> forwarding"
      },
      "id": "603e910028ccbc6304eba76d"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-09-30T23:10:13Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.9364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-09-30T23:10:13Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.49744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-01T12:59:41Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.3382,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-09-30T23:11:19Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.34015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure": [
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-01T12:59:41Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.33817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-09-30T23:10:12Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.68286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-09-30T23:11:19Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.34013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/https-proxy-configuration-missing": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-09-30T23:10:13Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.4974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-01T12:59:41Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.33817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-09-30T23:10:12Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.68286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-09-30T23:10:13Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.49738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-01T12:59:41Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.33813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-09-30T23:10:12Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.68286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/reduce-infrastructure-agents-cpu-footprint": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-09-30T23:10:13Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.49738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-01T12:59:41Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.33813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-09-30T23:10:12Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.68286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/time-gaps-missing-data": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-09-30T23:10:13Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.49738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-01T12:59:41Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.33813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-09-30T23:10:12Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.68286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    }
  ],
  "/docs/instrumentation-editor-instrument-net-ui": [
    {
      "sections": [
        "OpenTelemetry quick start",
        "Step 1. Prerequisites",
        "Step 2. Instrument your service with OpenTelemetry",
        "Step 3. Export your telemetry data to New Relic",
        "Review New Relic settings for exports",
        "Important",
        "Complete the export configuration steps",
        "Export data to an OpenTelemetry Collector (optional)",
        "Step 4. View your data in the New Relic UI",
        "What's next?"
      ],
      "title": "OpenTelemetry quick start",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "1b846417a2958b61b047c838db49aea06f09a2a8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start/",
      "published_at": "2021-10-01T21:42:35Z",
      "updated_at": "2021-09-27T14:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up OpenTelemetry with New Relic. Here's an overview of the process, followed by details for each step. Prerequisites Instrument your service with OpenTelemetry Export your telemetry data to New Relic View your data in the New Relic UI Step 1. Prerequisites First things first: If we don’t already know you, sign up for a free New Relic account. Copy your account license key. Step 2. Instrument your service with OpenTelemetry To get started, you instrument your service with OpenTelemetry. OpenTelemetry has language-specific products and SDKs to help you. Many languages offer out-the-box instrumentation for common libraries and frameworks. Each language also provides an API for further instrumenting your service manually. Go to the repository for your language and follow the instructions to instrument your service. When you're done, return here to complete Step 3. Export your telemetry data to New Relic. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...See a complete list of languages in GitHub Step 3. Export your telemetry data to New Relic The OpenTelemetry Protocol, or OTLP for short, is a general purpose telemetry data delivery protocol designed for the OpenTelemetry project. This protocol describes how to encode and transmit telemetry data, which makes it a natural choice for data transport. Each language SDK provides an OTLP exporter you can configure to export data over OTLP. In this step, we focus on how to configure an OTLP exporter in your service to export data directly to New Relic. If you prefer to export your data first to an OpenTelemetry collector, we have separate instructions. Here's an example of sending data from your service directly to New Relic. To complete this third step, first familiarize yourself with some required New Relic settings, and then complete the steps in the OTLP exporter documentation for your language. Review New Relic settings for exports Before you go to the external OTLP exporter documentation, consult the table below so you're ready to do the following: Configure the OTLP exporter to add a header ( api-key ) whose value is your account license key. Based on your region, configure the endpoint where the exporter sends data to New Relic. Region gRPC HTTP/1.1 Endpoint API Header Name API Header Value TLS encryption required US ✅ ❌ https://otlp.nr-data.net:4317 api-key License Key ✅ EU ✅ ❌ https://otlp.eu01.nr-data.net:4317 api-key License Key ✅ If you have FedRamp compliance constraints, see FedRAMP-compliant endpoints. Important In Node.js, the opentelemetry-collector-grpc library requires additional options to enable TLS. Complete the export configuration steps Click on the link below for your language and complete the configuration steps. When you're done, return here to complete Step 4. View your data in the New Relic UI. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...Find additional OTLP language support in GitHub Export data to an OpenTelemetry Collector (optional) The OpenTelemetry Collector is a configurable and extensible software component to receive, process, and export telemetry data. When you set up a collector, it can operate as a gateway or as an agent: Gateway: The collector receives data from a variety of sources and applies standard processing before exporting to some backend. Agent: The collector is deployed on each host in an environment and can collect telemetry data about the host and processes running on it. When you use a collector, you start by following the same routine as above for setting up OTLP in your service. In this case, instead of exporting data directly to New Relic, you export through a collector that you set up. In the collector, you configure the OTLP exporter to export data to New Relic. When your data goes through a collector, the transport looks like this: Here's a Docker example of how to set up and run an OpenTelemetry collector with the collector YAML: Save the following as otel-config.yaml: receivers: otlp: protocols: grpc: http: processors: batch: exporters: otlp: endpoint: ${OTEL_EXPORTER_OTLP_ENDPOINT} headers: api-key: ${NEW_RELIC_LICENSE_KEY} service: pipelines: traces: receivers: [otlp] processors: [batch] exporters: [otlp] metrics: receivers: [otlp] processors: [batch] exporters: [otlp] logs: receivers: [otlp] processors: [batch] exporters: [otlp] Copy Run the OpenTelemetry collector, making sure you replace OTLP_ENDPOINT_HERE with the appropriate endpoint and replace YOUR_KEY_HERE with your Account License Key: export OTEL_EXPORTER_OTLP_ENDPOINT=OTLP_ENDPOINT_HERE export NEW_RELIC_LICENSE_KEY=YOUR_KEY_HERE docker run --rm \\ -e OTEL_EXPORTER_OTLP_ENDPOINT \\ -e NEW_RELIC_LICENSE_KEY \\ -p 4317:4317 \\ -v \"${PWD}/otel-config.yaml\":/otel-config.yaml \\ --config otel-config.yaml \\ --name otelcol \\ otel/opentelemetry-collector Copy Step 4. View your data in the New Relic UI Once you’ve instrumented your service and configured it to export its data to New Relic, watch the New Relic One user interface for your traces, metrics, and logs! The UI for OpenTelemetry has some similarities to the APM agent UI, so if you are familiar with that, you can go right to the UI. If you need help understanding your OpenTelemetry UI options or how to make sure your data appears in the UI, see View your OpenTelemetry data in New Relic. What's next? After you do your initial setup, check out our best-practices guide for tips about various configurations to improve your use of OpenTelemetry and New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.55437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 2. <em>Instrument</em> your service with OpenTelemetry",
        "body": " your telemetry data to New Relic View your data in the New Relic <em>UI</em> Step 1. Prerequisites First things first: If we don’t already know you, sign up for a free New Relic account. Copy your account license key. Step 2. <em>Instrument</em> your service with OpenTelemetry To get started, you <em>instrument</em> your"
      },
      "id": "6044e5dfe7b9d2aadc5799d4"
    },
    {
      "sections": [
        "Enable configurable security policies",
        "Important",
        "Compatibility and requirements",
        "Caution",
        "Example configuration",
        "Java agent: YAML example",
        ".NET agent: XML example",
        "Ruby agent: YAML example",
        "Available policy options",
        "For more help"
      ],
      "title": "Enable configurable security policies",
      "type": "docs",
      "tags": [
        "Agents",
        "Manage APM agents",
        "Configuration"
      ],
      "external_id": "1f645201e6e79a35f84334b11415e8a2a0edf665",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/manage-apm-agents/configuration/enable-configurable-security-policies/",
      "published_at": "2021-10-01T15:41:37Z",
      "updated_at": "2021-09-14T14:49:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important APM's configurable security policies is available in limited release for approved New Relic accounts. APM's configurable security policies gives you granular control over configuration options related to your account's data security. This document explains how to enable account-wide security policies and the options available. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. Compatibility and requirements APM agent versions that support this feature include: C SDK: not available Go: 2.1 or higher Java: 4.1 or higher .NET: 8.1 or higher Node.js: 4.1 or higher PHP: 8.1 or higher Python: not available Ruby: 5.2 or higher Enable configurable security policies Caution Security policies apply account-wide. Once enabled, they can only be edited or disabled with the help of New Relic support. If high security mode is enabled for the account(s), do not disable it. Account-level high security mode differs from your APM agent's high security mode, which is set in the configuration file. High security mode and configurable security policies do not apply to Lambda monitoring or use of the New Relic Event API. For the limited release, there is no UI component. If you are participating in the limited release, follow this procedure to set up your accounts: Choose the accounts on which to enable configurable security policies. Choose the configurable security policies options that you want for those accounts. Inform your New Relic sales rep of the options that you have chosen. Ensure your agent versions support this feature. Update agents if necessary. When you receive the security token based on the security policies options that you chose, insert the security token into the agent configuration file(s). See examples. Delete the high security mode enabled flag from your config file(s). High security mode (HSM) at the agent level is different than high security mode at the account level. Be sure to disable HSM in the agent's config file, as explained in this procedure. Having both the security token and the HSM flag will result in the agent disconnecting. Example configuration Here are some example configuration examples for enabling the configurable security policies: Java agent: YAML example The Java agent uses a YAML file for configuration. Here is an example snippet enabling security policies: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'YOUR_APPLICATION_NAME' security_policies_token: 'YOUR_TOKEN' production: <<: *default_settings log_level: info Copy .NET agent: XML example The .NET agent uses a XML file for configuration. Here is an example snippet enabling security policies: ... <configuration agentenabled=\"true\" xmlns=\"urn:newrelic-config\"> <service licensekey=\"YOUR_LICENSE_KEY\"> <application> <name>YOUR_APPLICATION_NAME</name> </application> <securityPoliciesToken>YOUR_TOKEN</securityPoliciesToken> <log level=\"info\"> </log></service></configuration> ... Copy If you prefer to use an environment variable, it would look like this: NEW_RELIC_SECURITY_POLICIES_TOKEN=YOUR_TOKEN Copy Ruby agent: YAML example The Ruby agent uses a YAML file for configuration. Here is an example snippet enabling security policies: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'YOUR_APPLICATION_NAME' security_policies_token: 'YOUR_TOKEN' production: <<: *default_settings log_level: info Copy Available policy options Here are the settings you can choose when creating your policies. Some of these options will not be available for some agents. Setting Effect Database query collection Options: Enabled: Collects obfuscated database query data. Obfuscated queries generally appear along with slow query details in the APM or New Relic One UI. Disabled: Prevents the collection of obfuscated database query data. Raw query data is not collected once configurable security policies is enabled. attributes.include list Go, Java, .NET, Node.js, Ruby only Options: Enabled: attributes.include list functions normally; attribute keys found in the attributes.include list are recorded. Disabled: Ignores the list of allowed attributes listed in the attributes.include property in agent configuration; no intrinsic request parameter attributes will be collected. Whitelisting attributes at the account level is not supported. Raw exception messages Options: Enabled: Allows recording of all raw exception messages. Disabled: Prevents recording of all raw exception messages. The messages may be either obfuscated or completely removed, depending on the agent. Custom events Options: Enabled: Allows the recording of custom events that are created and sent up via an agent API. Disabled: Prevents recording of any custom events collect by an agent API. Custom attributes Options: Enabled: Allows for the collection of custom attributes passed in by the New Relic agent. Disabled: Prevents collection of custom attributes that are collected by the New Relic agent. Custom instrumentation editor Java only Options: Enabled: Allows custom instrumentation of the agent, using the custom instrumentation editor. Disabled: Prevents custom instrumentation of the agent using the custom instrumentation editor. Instrumentation previously done via the editor is also disabled. Access to the custom instrumentation editor is only available to New Relic account Owners and Admins. Message parameters Java and Ruby only Options: Enabled: Allows the collection of message parameters (message.parameters.*). Disabled: Prevents collection of message parameters. Job arguments Ruby only Options: Enabled: Allows the collection of job arguments (job.(type).args.*). Disabled: Prevents the collection of job arguments. For more help For more information about configuration file settings, refer to your specific agent's documentation. If you are a New Relic customer and interested in the limited release of configurable security policies, contact your New Relic sales rep.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.93011,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": ".<em>NET</em> agent: XML example",
        "body": " collect by an agent API. Custom attributes Options: Enabled: Allows for the collection of custom attributes passed in by the New Relic agent. Disabled: Prevents collection of custom attributes that are collected by the New Relic agent. Custom <em>instrumentation</em> <em>editor</em> Java only Options: Enabled: Allows"
      },
      "id": "6043d4a8196a6773a1960f68"
    },
    {
      "sections": [
        "Custom instrumentation editor: Instrument from UI",
        "Requirements",
        "Define custom instrumentation",
        "Caution",
        "Manual instrumentation using the editor",
        "Important",
        "Deploy changes manually",
        "Page functions",
        "Instrumentation options",
        "Results with \"start\" option"
      ],
      "title": "Custom instrumentation editor: Instrument from UI",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Custom instrumentation"
      ],
      "external_id": "979a3d068ba665b13e8e9e18c432356286d61248",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/custom-instrumentation/custom-instrumentation-editor-instrument-ui/",
      "published_at": "2021-10-01T13:43:27Z",
      "updated_at": "2021-03-16T02:40:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's custom instrumentation editor allows Java app users to implement custom instrumentation via the New Relic user interface. The editor is the preferred choice when you cannot modify your application code and don't have that many methods to instrument. See Java custom instrumentation for other instrumentation options and the reasons for using each. To use the custom instrumentation editor: Go to one.newrelic.com > APM > (select a Java app) > Settings > Instrumentation. Use the custom instrumentation editor to: Instrument an unsupported framework. Gain additional insight into uninstrumented methods. Ignore particular transactions. Requirements To use the custom instrumentation editor, you must meet the following requirements: Requirement Comments Agent Java agent version 3.17.0 or higher Security Users of high security mode must export their instrumentation and manually import it to their app server. Define custom instrumentation To define custom instrumentation from the New Relic user interface, use a thread profiling session to collect detailed stack traces of each thread in your application. If possible, test your custom instrumentation in a pre-production environment before changing the instrumentation rules in your production app. In either environment, use the custom instrumentation editor to define the methods you want instrumented, and apply your changes: Create a new thread profiler session. To ensure you collect sufficient data, set the length of the session to at least two minutes. Go to one.newrelic.com > APM > (select an app) > Settings > Instrumentation. Scroll down to the bottom of the page until you see the Recently collected thread profiles list, then select the most recent thread profile. Expand individual methods to locate uninstrumented methods. To define instrumentation rules for particular nodes, select Instrument or Ignore, and customize the rules if necessary. To save your settings, select Confirm instrumentation changes. Deploy your changes from the Instrumentation page: To deploy your changes automatically, select Deploy instrumentation changes. To deploy your changes manually, select Export XML, and see exporting your instrumentation. Caution Avoid over-instrumenting whenever possible. With each additional method that is instrumented, the agent will be using more resources and your application will incur more overhead. In addition, deploying your instrumentation will cause a brief period of higher overhead. This can noticeably slow application requests for several seconds. If you applied your changes from the UI, the agent will begin instrumenting your methods within a few harvest cycles (typically a few minutes). Manual instrumentation using the editor You can also create instrumentation points directly in the editor without using a thread profile: From the custom instrumentation editor, select Add manual instrumentation to manually enter a class and method to be instrumented or ignored. Follow the custom instrumentation by XML rules when defining your instrumentation points. Deploy your changes from the instrumentation editor. Using this method to add instrumentation exposes additional functionality beyond what is available from a thread profile. In addition to matching methods by signature, you can also instrument methods by return type, methods on interfaces, and by Java annotation. These more complex instrumentation types can be created and deleted in the editor, but not edited. Important If a method is marked Instrumentation not allowed, follow New Relic's troubleshooting procedures for custom instrumentation. Deploy changes manually You can also use the custom instrumentation editor to build a custom instrumentation set, then export an instrumentation file and manually import it to your app server. This is required for users of high security mode. To export your instrumentation, define custom instrumentation via the UI. Then select Export xml from the Instrumentation page, and import the file on your app server. Page functions The Instrumentation page supports the following features: If you want to... Do this... Pause or disable custom instrumentation Select Disable instrumentation to temporarily disable all UI-defined custom instrumentation. Select Enable instrumentation to re-enable your instrumentation settings. Import existing instrumentation You can import an existing custom instrumentation xml file by selecting Import xml. You can also Export xml if you do not want to deploy your changes automatically. Edit or delete instrumentation points You cannot edit manual instrumentation, only delete it. Select Remove to stop instrumenting a particular method. Select Edit to change the instrumentation rules. View instrumentation history You can view each previous iteration of your custom instrumentation from the Instrumentation history tab, including who deployed changes and when. You can restore an old version by selecting export to download a copy of the custom instrumentation file, then importing it to the instrumentation editor. Instrumentation options You can define the following options with the custom instrumentation editor: Instrumentation options Comments Instrument methods Begin instrumenting the selected method. Instrumented methods will be visible in the New Relic UI. Instrument supports the following child options: Name the transaction (transaction name): Override the standard transaction name, defined by the automatic naming rules. The UI will instead use the listed name. Start the transaction when this method executes: Rather than including metrics from this metric inside its parent transaction, create a new transaction for this method. Agent behavior with this option depends on whether there is a pre-existing transaction on the thread. Report custom attributes Method parameters can be captured as attributes on a transaction. New Relic reports these attributes to transaction traces, traced errors, and New Relic One Transaction events. For security reasons, capturing custom attributes using the Custom Instrumentation Editor is disabled by default and cannot be enabled while you are using high security mode. If you want to report custom attributes using the custom instrumentation editor and you do not want the Java agent to be in High security mode, disable High security mode and then add the following text in the common: block of your newrelic.yml: reinstrument: attributes_enabled: true Copy Ignore transactions Ignore this method entirely. The agent will not report metrics from this method, and the method will not contribute to Apdex calculations. Results with \"start\" option If you select Instrument methods > Start the transaction when this method executes, agent behavior depends on whether there is a pre-existing transaction on the thread. When the class or method is instrumented: Is the \"Start the transaction\" flag checked? Yes No If a pre-existing transaction is on that thread and the Start the transaction flag is checked: The agent ignores the Start the transaction flag. The agent includes the class/method into the pre-existing transaction. If a pre-existing transaction is on that thread and the Start the transaction flag is not checked, the agent includes the class/method into the pre-existing transaction. If a transaction is not on that thread and the Start the transaction flag is checked: The agent discovers there is no current transaction. The agent creates a new transaction starting with the class/method you have instrumented. If a transaction is not on that thread and the Start the transaction flag is not checked: The agent looks for a transaction on that thread and does not find one. The metric is dropped.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.84009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Custom <em>instrumentation</em> <em>editor</em>: <em>Instrument</em> <em>from</em> <em>UI</em>",
        "sections": "Custom <em>instrumentation</em> <em>editor</em>: <em>Instrument</em> <em>from</em> <em>UI</em>",
        "tags": "Custom <em>instrumentation</em>",
        "body": " define the following options with the custom <em>instrumentation</em> <em>editor</em>: <em>Instrumentation</em> options Comments <em>Instrument</em> methods Begin instrumenting the selected method. Instrumented methods will be visible in the New Relic <em>UI</em>. <em>Instrument</em> supports the following child options: Name the transaction (transaction"
      },
      "id": "603ed428e7b9d2b9b52a07e6"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/amazon-cognito-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/amazon-sqs-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/amazon-transit-gateway-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85739,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-albnlb-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85739,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85739,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82849,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-athena-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82849,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-auto-scaling-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "Amazon VPC monitoring integration",
        "Features",
        "Activate",
        "Configuration and polling",
        "Find and use data",
        "Important",
        "Metric data",
        "VPC NAT Gateway data",
        "Tip",
        "VPC VPN Tunnel",
        "Inventory data"
      ],
      "title": "Amazon VPC monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "8b5f98e1853d95d8f563d8910d02abac829976cd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration/",
      "published_at": "2021-10-01T19:42:45Z",
      "updated_at": "2021-07-09T10:28:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The Amazon Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable infrastructure of Amazon Web Services (AWS). With New Relic's VPC integration, you can gain visibility into configuration event changes that are overlaid across your Amazon services. The Amazon VPC integration generates a feed of configuration/inventory changes that occur in your VPC. VPC data is available in pre-built dashboards, and you can create custom queries and charts in New Relic One. You can also create alert conditions to notify you about changes in the VPC. Additionally, Enhanced Amazon VPC Flow Logs enables you to capture information about IP traffic to and from network interfaces in your VPC. Activate To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon VPC integration: Default New Relic polling interval: 15 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the VPC integration links. You can query and explore your data using the PrivateNetworkSample event type, with provider values of: VpcNatGateway VpcVpnTunnel Important By default, collection of VpcNatGateway, VpcVpnTunnel, and VpcVpnConnection data is disabled. This is because if you have many NAT gateways or many VPNs (connections and tunnels), it might lead to an increase on your CloudWatch bill. For this reason, the integration provides configuration settings to set whether you want to fetch that data. For more on how to use your data, see Understand integration data. Metric data VPC NAT Gateway data This integration collects the following data from PrivateNetworkSample with a provider value of VpcNatGateway: Tip For full descriptions, see Amazon VPC NAT Gateway Metrics and Dimensions. Name Description activeConnectionCount The total number of concurrent active TCP connections through the NAT gateway. bytesInFromDestination The number of bytes received by the NAT gateway from the destination. bytesInFromSource The number of bytes received by the NAT gateway from clients in your VPC. bytesOutToDestination The number of bytes sent out through the NAT gateway to the destination. bytesOutToSource The number of bytes sent through the NAT gateway to the clients in your VPC. connectionAttemptCount The number of connection attempts made through the NAT gateway. connectionEstablishedCount The number of connections established through the NAT gateway. errorPortAllocation The number of times the NAT gateway could not allocate a source port. idleTimeoutCount The number of connections that transitioned from the active state to the idle state. An active connection transitions to idle if it was not closed gracefully and there was no activity for the last 350 seconds. packetsDropCount The number of packets dropped by the NAT gateway. packetsInFromDestination The number of packets received by the NAT gateway from the destination. packetsInFromSource The number of packets received by the NAT gateway from clients in your VPC. packetsOutToDestination The number of packets sent out through the NAT gateway to the destination. packetsOutToSource The number of packets sent through the NAT gateway to the clients in your VPC. VPC VPN Tunnel This integration collects the following data from PrivateNetworkSample with a provider value of VpcVpnTunnel: Tip For full descriptions, see Amazon VPC VPN Metrics and Dimensions. Name Description tunnelState The state of the tunnel. 0 indicates DOWN and 1 indicates UP. tunnelDataIn The bytes received through the VPN tunnel. Each metric data point represents the number of bytes received after the previous data point. Use the Sum statistic to show the total number of bytes received during the period. tunnelDataOut The bytes sent through the VPN tunnel. Each metric data point represents the number of bytes sent after the previous data point. Use the Sum statistic to show the total number of bytes sent during the period. Inventory data This integration reports the following VPC configuration options and metadata as inventory data. For more about inventory data, see Understand integration data. Tip Tags (indicated with an *) are only fetched when tags collection is on. Inventory category Data aws/vpc/network-interface awsRegion subnetId status sourceDestCheck requesterManaged requesterId privateIpAddress privateDnsName networkInterfaceId macAddress ipv6Addresses securityGroups description availabilityZone attachmentInstanceId attachmentDeleteOnTermination attachmentStatus attachmentInstanceOwnerId publicIp publicDnsName tags * aws/vpc/endpoint awsRegion creationTimestamp policyDocumentMd5 routeTableIds serviceName state vpcId vpcEndpointId aws/vpc/nat-gateway awsRegion natGatewayId createTime natGatewayAddresses state subnetId vpcId aws/vpc/peering-connection awsRegion vpcPeeringConnectionId accepterVpcInfo requesterVpcInfo tags * aws/vpc/vpn/connection awsRegion vpnId state type category customerGatewayConfiguration vpnGatewayId customerGatewayId staticRoutesOnly tags * aws/vpc/vpn/tunnel awsRegion acceptedRouteCount outsideIpAddress status statusChange statusMessage aws/vpc/internet-gateway region internetGatewayId attachments tags * aws/vpc/network-acl region networkAclId associations entries isDefault vpcId tags * aws/vpc/route-table region routeTableId associations propagatingVgws routes vpcId tags * aws/vpc/security-group region description groupName groupId ipPermissions ipPermissionsEgress ownerId vpcId tags * aws/vpc/subnet region availabilityZone cidrBlock defaultForAz mapPublicIpOnLaunch subnetId state vpcId tags * aws/vpc/vpc region cidrBlock dhcpOptionsId enableDnsHostname enableDnsSupport instanceTenancy isDefault state vpcId tags *",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.74543,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The <em>Amazon</em> Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable"
      },
      "id": "60450763196a678c49960f68"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-cloudformation-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-cloudfront-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-connect-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-direct-connect-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-documentdb-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-dynamodb-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.733574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-ebs-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.733574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.733574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82773,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.8572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.733574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-efs-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82773,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.8572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.733574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elastic-beanstalk-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.733574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticache-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.733574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.733574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elb-classic-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.733574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elemental-mediaconvert-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.733574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elemental-mediapackage-vod-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.733574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-emr-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-fsx-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-glue-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-iam-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-iot-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85703,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-kinesis-data-analytics-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85703,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-kinesis-data-firehose-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85703,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-kinesis-data-streams-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    },
    {
      "sections": [
        "Amazon VPC monitoring integration",
        "Features",
        "Activate",
        "Configuration and polling",
        "Find and use data",
        "Important",
        "Metric data",
        "VPC NAT Gateway data",
        "Tip",
        "VPC VPN Tunnel",
        "Inventory data"
      ],
      "title": "Amazon VPC monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "8b5f98e1853d95d8f563d8910d02abac829976cd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration/",
      "published_at": "2021-10-01T19:42:45Z",
      "updated_at": "2021-07-09T10:28:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The Amazon Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable infrastructure of Amazon Web Services (AWS). With New Relic's VPC integration, you can gain visibility into configuration event changes that are overlaid across your Amazon services. The Amazon VPC integration generates a feed of configuration/inventory changes that occur in your VPC. VPC data is available in pre-built dashboards, and you can create custom queries and charts in New Relic One. You can also create alert conditions to notify you about changes in the VPC. Additionally, Enhanced Amazon VPC Flow Logs enables you to capture information about IP traffic to and from network interfaces in your VPC. Activate To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon VPC integration: Default New Relic polling interval: 15 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the VPC integration links. You can query and explore your data using the PrivateNetworkSample event type, with provider values of: VpcNatGateway VpcVpnTunnel Important By default, collection of VpcNatGateway, VpcVpnTunnel, and VpcVpnConnection data is disabled. This is because if you have many NAT gateways or many VPNs (connections and tunnels), it might lead to an increase on your CloudWatch bill. For this reason, the integration provides configuration settings to set whether you want to fetch that data. For more on how to use your data, see Understand integration data. Metric data VPC NAT Gateway data This integration collects the following data from PrivateNetworkSample with a provider value of VpcNatGateway: Tip For full descriptions, see Amazon VPC NAT Gateway Metrics and Dimensions. Name Description activeConnectionCount The total number of concurrent active TCP connections through the NAT gateway. bytesInFromDestination The number of bytes received by the NAT gateway from the destination. bytesInFromSource The number of bytes received by the NAT gateway from clients in your VPC. bytesOutToDestination The number of bytes sent out through the NAT gateway to the destination. bytesOutToSource The number of bytes sent through the NAT gateway to the clients in your VPC. connectionAttemptCount The number of connection attempts made through the NAT gateway. connectionEstablishedCount The number of connections established through the NAT gateway. errorPortAllocation The number of times the NAT gateway could not allocate a source port. idleTimeoutCount The number of connections that transitioned from the active state to the idle state. An active connection transitions to idle if it was not closed gracefully and there was no activity for the last 350 seconds. packetsDropCount The number of packets dropped by the NAT gateway. packetsInFromDestination The number of packets received by the NAT gateway from the destination. packetsInFromSource The number of packets received by the NAT gateway from clients in your VPC. packetsOutToDestination The number of packets sent out through the NAT gateway to the destination. packetsOutToSource The number of packets sent through the NAT gateway to the clients in your VPC. VPC VPN Tunnel This integration collects the following data from PrivateNetworkSample with a provider value of VpcVpnTunnel: Tip For full descriptions, see Amazon VPC VPN Metrics and Dimensions. Name Description tunnelState The state of the tunnel. 0 indicates DOWN and 1 indicates UP. tunnelDataIn The bytes received through the VPN tunnel. Each metric data point represents the number of bytes received after the previous data point. Use the Sum statistic to show the total number of bytes received during the period. tunnelDataOut The bytes sent through the VPN tunnel. Each metric data point represents the number of bytes sent after the previous data point. Use the Sum statistic to show the total number of bytes sent during the period. Inventory data This integration reports the following VPC configuration options and metadata as inventory data. For more about inventory data, see Understand integration data. Tip Tags (indicated with an *) are only fetched when tags collection is on. Inventory category Data aws/vpc/network-interface awsRegion subnetId status sourceDestCheck requesterManaged requesterId privateIpAddress privateDnsName networkInterfaceId macAddress ipv6Addresses securityGroups description availabilityZone attachmentInstanceId attachmentDeleteOnTermination attachmentStatus attachmentInstanceOwnerId publicIp publicDnsName tags * aws/vpc/endpoint awsRegion creationTimestamp policyDocumentMd5 routeTableIds serviceName state vpcId vpcEndpointId aws/vpc/nat-gateway awsRegion natGatewayId createTime natGatewayAddresses state subnetId vpcId aws/vpc/peering-connection awsRegion vpcPeeringConnectionId accepterVpcInfo requesterVpcInfo tags * aws/vpc/vpn/connection awsRegion vpnId state type category customerGatewayConfiguration vpnGatewayId customerGatewayId staticRoutesOnly tags * aws/vpc/vpn/tunnel awsRegion acceptedRouteCount outsideIpAddress status statusChange statusMessage aws/vpc/internet-gateway region internetGatewayId attachments tags * aws/vpc/network-acl region networkAclId associations entries isDefault vpcId tags * aws/vpc/route-table region routeTableId associations propagatingVgws routes vpcId tags * aws/vpc/security-group region description groupName groupId ipPermissions ipPermissionsEgress ownerId vpcId tags * aws/vpc/subnet region availabilityZone cidrBlock defaultForAz mapPublicIpOnLaunch subnetId state vpcId tags * aws/vpc/vpc region cidrBlock dhcpOptionsId enableDnsHostname enableDnsSupport instanceTenancy isDefault state vpcId tags *",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.745415,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The <em>Amazon</em> Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable"
      },
      "id": "60450763196a678c49960f68"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-managed-kafka-msk-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82663,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    },
    {
      "sections": [
        "Amazon VPC monitoring integration",
        "Features",
        "Activate",
        "Configuration and polling",
        "Find and use data",
        "Important",
        "Metric data",
        "VPC NAT Gateway data",
        "Tip",
        "VPC VPN Tunnel",
        "Inventory data"
      ],
      "title": "Amazon VPC monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "8b5f98e1853d95d8f563d8910d02abac829976cd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration/",
      "published_at": "2021-10-01T19:42:45Z",
      "updated_at": "2021-07-09T10:28:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The Amazon Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable infrastructure of Amazon Web Services (AWS). With New Relic's VPC integration, you can gain visibility into configuration event changes that are overlaid across your Amazon services. The Amazon VPC integration generates a feed of configuration/inventory changes that occur in your VPC. VPC data is available in pre-built dashboards, and you can create custom queries and charts in New Relic One. You can also create alert conditions to notify you about changes in the VPC. Additionally, Enhanced Amazon VPC Flow Logs enables you to capture information about IP traffic to and from network interfaces in your VPC. Activate To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon VPC integration: Default New Relic polling interval: 15 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the VPC integration links. You can query and explore your data using the PrivateNetworkSample event type, with provider values of: VpcNatGateway VpcVpnTunnel Important By default, collection of VpcNatGateway, VpcVpnTunnel, and VpcVpnConnection data is disabled. This is because if you have many NAT gateways or many VPNs (connections and tunnels), it might lead to an increase on your CloudWatch bill. For this reason, the integration provides configuration settings to set whether you want to fetch that data. For more on how to use your data, see Understand integration data. Metric data VPC NAT Gateway data This integration collects the following data from PrivateNetworkSample with a provider value of VpcNatGateway: Tip For full descriptions, see Amazon VPC NAT Gateway Metrics and Dimensions. Name Description activeConnectionCount The total number of concurrent active TCP connections through the NAT gateway. bytesInFromDestination The number of bytes received by the NAT gateway from the destination. bytesInFromSource The number of bytes received by the NAT gateway from clients in your VPC. bytesOutToDestination The number of bytes sent out through the NAT gateway to the destination. bytesOutToSource The number of bytes sent through the NAT gateway to the clients in your VPC. connectionAttemptCount The number of connection attempts made through the NAT gateway. connectionEstablishedCount The number of connections established through the NAT gateway. errorPortAllocation The number of times the NAT gateway could not allocate a source port. idleTimeoutCount The number of connections that transitioned from the active state to the idle state. An active connection transitions to idle if it was not closed gracefully and there was no activity for the last 350 seconds. packetsDropCount The number of packets dropped by the NAT gateway. packetsInFromDestination The number of packets received by the NAT gateway from the destination. packetsInFromSource The number of packets received by the NAT gateway from clients in your VPC. packetsOutToDestination The number of packets sent out through the NAT gateway to the destination. packetsOutToSource The number of packets sent through the NAT gateway to the clients in your VPC. VPC VPN Tunnel This integration collects the following data from PrivateNetworkSample with a provider value of VpcVpnTunnel: Tip For full descriptions, see Amazon VPC VPN Metrics and Dimensions. Name Description tunnelState The state of the tunnel. 0 indicates DOWN and 1 indicates UP. tunnelDataIn The bytes received through the VPN tunnel. Each metric data point represents the number of bytes received after the previous data point. Use the Sum statistic to show the total number of bytes received during the period. tunnelDataOut The bytes sent through the VPN tunnel. Each metric data point represents the number of bytes sent after the previous data point. Use the Sum statistic to show the total number of bytes sent during the period. Inventory data This integration reports the following VPC configuration options and metadata as inventory data. For more about inventory data, see Understand integration data. Tip Tags (indicated with an *) are only fetched when tags collection is on. Inventory category Data aws/vpc/network-interface awsRegion subnetId status sourceDestCheck requesterManaged requesterId privateIpAddress privateDnsName networkInterfaceId macAddress ipv6Addresses securityGroups description availabilityZone attachmentInstanceId attachmentDeleteOnTermination attachmentStatus attachmentInstanceOwnerId publicIp publicDnsName tags * aws/vpc/endpoint awsRegion creationTimestamp policyDocumentMd5 routeTableIds serviceName state vpcId vpcEndpointId aws/vpc/nat-gateway awsRegion natGatewayId createTime natGatewayAddresses state subnetId vpcId aws/vpc/peering-connection awsRegion vpcPeeringConnectionId accepterVpcInfo requesterVpcInfo tags * aws/vpc/vpn/connection awsRegion vpnId state type category customerGatewayConfiguration vpnGatewayId customerGatewayId staticRoutesOnly tags * aws/vpc/vpn/tunnel awsRegion acceptedRouteCount outsideIpAddress status statusChange statusMessage aws/vpc/internet-gateway region internetGatewayId attachments tags * aws/vpc/network-acl region networkAclId associations entries isDefault vpcId tags * aws/vpc/route-table region routeTableId associations propagatingVgws routes vpcId tags * aws/vpc/security-group region description groupName groupId ipPermissions ipPermissionsEgress ownerId vpcId tags * aws/vpc/subnet region availabilityZone cidrBlock defaultForAz mapPublicIpOnLaunch subnetId state vpcId tags * aws/vpc/vpc region cidrBlock dhcpOptionsId enableDnsHostname enableDnsSupport instanceTenancy isDefault state vpcId tags *",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.745415,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The <em>Amazon</em> Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable"
      },
      "id": "60450763196a678c49960f68"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-mq-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82663,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-neptune-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-qldb-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-rds-enhanced-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-rds-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-redshift-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-route-53-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-route53-resolver-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85684,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85684,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-simple-email-service-ses-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85681,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-sns-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85681,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-step-functions-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85681,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-trusted-advisor-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82584,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-flow-logs-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82584,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-waf-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-x-ray-monitoring-integration": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.82568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.85675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-01T23:39:12Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.73355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/rate-limit-alerts-amazon": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-01T19:01:58Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.08403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.10683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda monitoring <em>integration</em>",
        "sections": "AWS Lambda monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with “eu” then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure there’s no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.91982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/aws-integrations-metrics": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-01T19:45:16Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.01376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-01T19:43:58Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.60727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "ab6a129f8c50643b9af1c135863572d1ab595e30",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-10-01T19:43:56Z",
      "updated_at": "2021-09-20T19:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.09161,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "603e85bc196a675469a83dcd"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/connect-aws-govcloud-new-relic": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-01T19:45:16Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.01376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-01T19:43:58Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.60727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by CloudWatch metric streams and all API polling integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "80e215e7b2ba382de1b7ea758ee1b1f0a1e3c7df",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-10-01T19:45:16Z",
      "updated_at": "2021-09-20T19:30:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by CloudWatch metric streams and all API polling integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.80154,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "6045079fe7b9d27db95799d9"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-01T19:45:16Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.01372,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "ab6a129f8c50643b9af1c135863572d1ab595e30",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-10-01T19:43:56Z",
      "updated_at": "2021-09-20T19:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.09158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "603e85bc196a675469a83dcd"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by CloudWatch metric streams and all API polling integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "80e215e7b2ba382de1b7ea758ee1b1f0a1e3c7df",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-10-01T19:45:16Z",
      "updated_at": "2021-09-20T19:30:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by CloudWatch metric streams and all API polling integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.80151,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "6045079fe7b9d27db95799d9"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/integrations-managed-policies": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-01T19:45:16Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.01372,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-01T19:43:58Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.60724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "ab6a129f8c50643b9af1c135863572d1ab595e30",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-10-01T19:43:56Z",
      "updated_at": "2021-09-20T19:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.09158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "603e85bc196a675469a83dcd"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations": [
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-01T19:43:58Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.60724,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "ab6a129f8c50643b9af1c135863572d1ab595e30",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-10-01T19:43:56Z",
      "updated_at": "2021-09-20T19:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.09158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "603e85bc196a675469a83dcd"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by CloudWatch metric streams and all API polling integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "80e215e7b2ba382de1b7ea758ee1b1f0a1e3c7df",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-10-01T19:45:16Z",
      "updated_at": "2021-09-20T19:30:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by CloudWatch metric streams and all API polling integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.80151,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "6045079fe7b9d27db95799d9"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/polling-intervals-aws-integrations": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-01T19:45:16Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.01369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-01T19:43:58Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.60721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "ab6a129f8c50643b9af1c135863572d1ab595e30",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-10-01T19:43:56Z",
      "updated_at": "2021-09-20T19:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.09155,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "603e85bc196a675469a83dcd"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/authentication-issues": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-01T19:01:58Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.08398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.10667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda monitoring <em>integration</em>",
        "sections": "AWS Lambda monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with “eu” then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure there’s no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.919785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-01T19:01:58Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.08398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.10667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda monitoring <em>integration</em>",
        "sections": "AWS Lambda monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with “eu” then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure there’s no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.919785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/cannot-create-alert-condition-infrastructure-integration": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-01T19:01:58Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.08395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.10658,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda monitoring <em>integration</em>",
        "sections": "AWS Lambda monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with “eu” then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure there’s no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.91977,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/cloudwatch-billing-increase": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-01T19:01:58Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.08395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.10658,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda monitoring <em>integration</em>",
        "sections": "AWS Lambda monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with “eu” then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure there’s no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.91977,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/invalid-principal-error-unsupported-aws-regions": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-01T19:01:58Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.08395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.10658,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda monitoring <em>integration</em>",
        "sections": "AWS Lambda monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with “eu” then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure there’s no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.91977,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-01T19:01:58Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.08392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.10651,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda monitoring <em>integration</em>",
        "sections": "AWS Lambda monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with “eu” then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure there’s no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.91975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.10651,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda monitoring <em>integration</em>",
        "sections": "AWS Lambda monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with “eu” then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure there’s no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.91975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-01T19:45:16Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 99.973694,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-01T19:45:16Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 347.5127,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> integration is the recommended solution to monitor all <em>CloudWatch</em> metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-01T19:43:58Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.24927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To start receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS <em>CloudWatch</em> <em>metric</em> <em>streams</em> is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, and alert considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-01T18:31:18Z",
      "updated_at": "2021-09-20T19:29:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.94632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "sections": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS <em>Metric</em> <em>Streams</em> integration, you only need a single service, AWS <em>CloudWatch</em>, to gather all AWS metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/partial-or-missing-logs-rds-vpc-aws-lambda": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-01T19:01:58Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.08391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-01T18:15:26Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.10643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Lambda monitoring <em>integration</em>",
        "sections": "AWS Lambda monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with “eu” then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure there’s no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.91972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration": [
    {
      "sections": [
        "Recommended ECS alert conditions",
        "Recommended alert conditions"
      ],
      "title": "Recommended ECS alert conditions",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "334d80a75b3ef0a7b6125bf2a15f643ea46d7282",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-10-01T19:05:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go to the Alerts UI and add the following NRQL alert conditions to an existing or new alert policy: High CPU usage NRQL: FROM ContainerSample SELECT cpuUsedCoresPercent Critical: > 90% for 5 minutes High memory usage NRQL: FROM ContainerSample SELECT memoryUsageBytes / memorySizeLimitBytes Critical: > 80% for 5 minutes Restart count NRQL: FROM ContainerSample SELECT max(restartCount) - min(restartCount) Critical: > 5 for 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.72925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go"
      },
      "id": "603e7eee64441f0f674e889f"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "Fargate launch type",
        "Install with automatic script",
        "Manual install",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "857b78b6e7de76449f3f9569cee4700705b7d7fe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-09-27T15:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for both EC2 and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every container instance, deploy this stack. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy For EC2 launch type, this is also done: Registers the newrelic-infra ECS task definition. Creates the service newrelic-infra for the registered task using a daemon scheduling strategy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.49863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". For EC2 launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every <em>container</em> instance, deploy this stack. Fargate launch type"
      },
      "id": "603e9e76196a676684a83de9"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "a86730dfe4c4cfdb6d293675c2c97e7393939331",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-10-01T19:04:33Z",
      "updated_at": "2021-03-30T12:41:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.34929,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No data appears",
        "sections": "ECS <em>integration</em> troubleshooting: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "60450883196a671c8c960f27"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration": [
    {
      "sections": [
        "Recommended ECS alert conditions",
        "Recommended alert conditions"
      ],
      "title": "Recommended ECS alert conditions",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "334d80a75b3ef0a7b6125bf2a15f643ea46d7282",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-10-01T19:05:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go to the Alerts UI and add the following NRQL alert conditions to an existing or new alert policy: High CPU usage NRQL: FROM ContainerSample SELECT cpuUsedCoresPercent Critical: > 90% for 5 minutes High memory usage NRQL: FROM ContainerSample SELECT memoryUsageBytes / memorySizeLimitBytes Critical: > 80% for 5 minutes Restart count NRQL: FROM ContainerSample SELECT max(restartCount) - min(restartCount) Critical: > 5 for 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.72906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go"
      },
      "id": "603e7eee64441f0f674e889f"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "78bfa3ecb2059e2641be8e22cd8ebb025da625a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-10-01T19:07:29Z",
      "updated_at": "2021-03-16T05:40:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 launch type, and not Fargate: Delete the service: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.86674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "603e9e7464441fd9cf4e885b"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "a2af5484b25f8595032cc1937210c9a41024a138",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "603eb04b196a6752b5a83dc8"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/installation/uninstall-ecs-integration": [
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "Fargate launch type",
        "Install with automatic script",
        "Manual install",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "857b78b6e7de76449f3f9569cee4700705b7d7fe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-09-27T15:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for both EC2 and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every container instance, deploy this stack. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy For EC2 launch type, this is also done: Registers the newrelic-infra ECS task definition. Creates the service newrelic-infra for the registered task using a daemon scheduling strategy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.6541,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the ECS <em>integration</em>",
        "sections": "<em>Install</em> the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". For EC2 launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every <em>container</em> instance, deploy this stack. Fargate launch type"
      },
      "id": "603e9e76196a676684a83de9"
    },
    {
      "sections": [
        "Recommended ECS alert conditions",
        "Recommended alert conditions"
      ],
      "title": "Recommended ECS alert conditions",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "334d80a75b3ef0a7b6125bf2a15f643ea46d7282",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-10-01T19:05:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go to the Alerts UI and add the following NRQL alert conditions to an existing or new alert policy: High CPU usage NRQL: FROM ContainerSample SELECT cpuUsedCoresPercent Critical: > 90% for 5 minutes High memory usage NRQL: FROM ContainerSample SELECT memoryUsageBytes / memorySizeLimitBytes Critical: > 80% for 5 minutes Restart count NRQL: FROM ContainerSample SELECT max(restartCount) - min(restartCount) Critical: > 5 for 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.72906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go"
      },
      "id": "603e7eee64441f0f674e889f"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "a2af5484b25f8595032cc1937210c9a41024a138",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "603eb04b196a6752b5a83dc8"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs": [
    {
      "sections": [
        "Recommended ECS alert conditions",
        "Recommended alert conditions"
      ],
      "title": "Recommended ECS alert conditions",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "334d80a75b3ef0a7b6125bf2a15f643ea46d7282",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-10-01T19:05:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go to the Alerts UI and add the following NRQL alert conditions to an existing or new alert policy: High CPU usage NRQL: FROM ContainerSample SELECT cpuUsedCoresPercent Critical: > 90% for 5 minutes High memory usage NRQL: FROM ContainerSample SELECT memoryUsageBytes / memorySizeLimitBytes Critical: > 80% for 5 minutes Restart count NRQL: FROM ContainerSample SELECT max(restartCount) - min(restartCount) Critical: > 5 for 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.0169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go"
      },
      "id": "603e7eee64441f0f674e889f"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "Fargate launch type",
        "Install with automatic script",
        "Manual install",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "857b78b6e7de76449f3f9569cee4700705b7d7fe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-09-27T15:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for both EC2 and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every container instance, deploy this stack. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy For EC2 launch type, this is also done: Registers the newrelic-infra ECS task definition. Creates the service newrelic-infra for the registered task using a daemon scheduling strategy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.65292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". For EC2 launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every <em>container</em> instance, deploy this stack. Fargate launch type"
      },
      "id": "603e9e76196a676684a83de9"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "a86730dfe4c4cfdb6d293675c2c97e7393939331",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-10-01T19:04:33Z",
      "updated_at": "2021-03-30T12:41:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.91272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". <em>Troubleshoot</em> in the UI To use the UI to <em>troubleshoot</em>: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "60450883196a671c8c960f27"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears": [
    {
      "sections": [
        "Recommended ECS alert conditions",
        "Recommended alert conditions"
      ],
      "title": "Recommended ECS alert conditions",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "334d80a75b3ef0a7b6125bf2a15f643ea46d7282",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-10-01T19:05:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go to the Alerts UI and add the following NRQL alert conditions to an existing or new alert policy: High CPU usage NRQL: FROM ContainerSample SELECT cpuUsedCoresPercent Critical: > 90% for 5 minutes High memory usage NRQL: FROM ContainerSample SELECT memoryUsageBytes / memorySizeLimitBytes Critical: > 80% for 5 minutes Restart count NRQL: FROM ContainerSample SELECT max(restartCount) - min(restartCount) Critical: > 5 for 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.01674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go"
      },
      "id": "603e7eee64441f0f674e889f"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "Fargate launch type",
        "Install with automatic script",
        "Manual install",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "857b78b6e7de76449f3f9569cee4700705b7d7fe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-09-27T15:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for both EC2 and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every container instance, deploy this stack. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy For EC2 launch type, this is also done: Registers the newrelic-infra ECS task definition. Creates the service newrelic-infra for the registered task using a daemon scheduling strategy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.65283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". For EC2 launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every <em>container</em> instance, deploy this stack. Fargate launch type"
      },
      "id": "603e9e76196a676684a83de9"
    },
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "06198f1b2e0faa69bd8a7dfb93f18c8955fea83b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-10-01T19:04:34Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.73544,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec <em>INTEGRATION_CONTAINER</em>_ID &#x2F;usr&#x2F;bin&#x2F;newrelic-infra-ctl Copy For more details, see <em>Troubleshoot</em> the agent. Save"
      },
      "id": "604507f9196a67c1ae960f5e"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions": [
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "Fargate launch type",
        "Install with automatic script",
        "Manual install",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "857b78b6e7de76449f3f9569cee4700705b7d7fe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-09-27T15:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for both EC2 and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every container instance, deploy this stack. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy For EC2 launch type, this is also done: Registers the newrelic-infra ECS task definition. Creates the service newrelic-infra for the registered task using a daemon scheduling strategy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.49844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " <em>data</em>, including information about clusters and services. See recommended alert conditions. <em>Understand</em> the AWS resources created by this process. Install with automatic script One install option is using our install script. To <em>use</em> the automatic install script: Download the ECS <em>integration</em> installer"
      },
      "id": "603e9e76196a676684a83de9"
    },
    {
      "sections": [
        "Understand and use ECS data",
        "View data",
        "Query your data"
      ],
      "title": "Understand and use ECS data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "16689cc080d4a8482e802b404df9ae45c4283db2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/understand-use-data/understand-use-ecs-data/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-03-29T20:30:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Here we explain how to find, understand, and use the data reported by this integration. View data To view the ECS integration dashboard: Go to one.newrelic.com and select Explorer. On the left, search for ECS clusters, or type the name of your ECS cluster in the search bar. To view a dashboard, select the entity name corresponding to your ECS cluster. In addition to the pre-built dashboards, you can also create your own custom queries and charts using the query builder. To learn how to query this data, see Understand data. Query your data Data reported by this integration is displayed in its dashboards and is also available for querying and the creation of custom charts and dashboards. This integration reports an EcsClusterSample event, with attributes clusterName and arn. Other types of data that may be available for querying: Infrastructure agent-reported events, including Docker All the events reported from an ECS cluster contain the attributes ecsClusterName and ecsClusterArn. Here's an example NRQL query that returns the count of containers associated with each Docker image in an ECS cluster named MyClusterName created in us-east-1: SELECT uniqueCount(containerId) FROM ContainerSample WHERE awsRegion = 'us-east-1' AND ecsClusterName = 'MyClusterName' FACET imageName SINCE 1 HOUR AGO Copy To learn more about creating custom queries and charts: How to query New Relic data Introduction to NRQL",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.13354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "sections": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Here we explain how to find, <em>understand</em>, and <em>use</em> the <em>data</em> reported by this <em>integration</em>. View <em>data</em> To view the ECS <em>integration</em> dashboard: Go to one.newrelic.com and select Explorer"
      },
      "id": "603e9eb664441fbaad4e889f"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "a2af5484b25f8595032cc1937210c9a41024a138",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "603eb04b196a6752b5a83dc8"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/understand-use-data/understand-use-ecs-data": [
    {
      "sections": [
        "Recommended ECS alert conditions",
        "Recommended alert conditions"
      ],
      "title": "Recommended ECS alert conditions",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "334d80a75b3ef0a7b6125bf2a15f643ea46d7282",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-10-01T19:05:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go to the Alerts UI and add the following NRQL alert conditions to an existing or new alert policy: High CPU usage NRQL: FROM ContainerSample SELECT cpuUsedCoresPercent Critical: > 90% for 5 minutes High memory usage NRQL: FROM ContainerSample SELECT memoryUsageBytes / memorySizeLimitBytes Critical: > 80% for 5 minutes Restart count NRQL: FROM ContainerSample SELECT max(restartCount) - min(restartCount) Critical: > 5 for 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 405.8033,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go"
      },
      "id": "603e7eee64441f0f674e889f"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "Fargate launch type",
        "Install with automatic script",
        "Manual install",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "857b78b6e7de76449f3f9569cee4700705b7d7fe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-10-01T19:05:49Z",
      "updated_at": "2021-09-27T15:24:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for both EC2 and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every container instance, deploy this stack. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy For EC2 launch type, this is also done: Registers the newrelic-infra ECS task definition. Creates the service newrelic-infra for the registered task using a daemon scheduling strategy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.49844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " <em>data</em>, including information about clusters and services. See recommended alert conditions. <em>Understand</em> the AWS resources created by this process. Install with automatic script One install option is using our install script. To <em>use</em> the automatic install script: Download the ECS <em>integration</em> installer"
      },
      "id": "603e9e76196a676684a83de9"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "a2af5484b25f8595032cc1937210c9a41024a138",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-10-01T19:02:55Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "603eb04b196a6752b5a83dc8"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-app-engine-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Redis",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Redis RedisInstance data"
      ],
      "title": "Google Memorystore for Redis",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "17f2891f284704c51e4e6cdac2c1b1de4b3aaf6a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-redis/",
      "published_at": "2021-10-01T19:17:20Z",
      "updated_at": "2021-09-14T20:40:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Redis data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Redis integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider RedisInstance GcpRedisInstanceSample GcpRedisInstance For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Redis data for RedisInstance. Redis RedisInstance data Metric Unit Description clients.Blocked Count Number of blocked clients. clients.Connected Count Number of client connections. commands.Calls Count Total number of calls for this command in one minute. commands.TotalTime Microseconds The amount of time in microseconds that this command took in the last second. commands.UsecPerCall Count Average time per call over 1 minute by command. keyspace.AvgTtl Milliseconds Average TTL for keys in this database. keyspace.Keys Count Number of keys stored in this database. keyspace.KeysWithExpiration Count Number of keys with an expiration in this database. replication.master.slaves.Lag Bytes The number of bytes that replica is behind. replication.master.slaves.Offset Bytes The number of bytes that have been acknowledged by replicas. replication.MasterReplOffset Bytes The number of bytes that master has produced and sent to replicas. To be compared with replication byte offset of replica. replication.OffsetDiff Bytes The number of bytes that have not been replicated to the replica. This is the difference between replication byte offset (master) and replication byte offset (replica). replication.Role Count Returns a value indicating the node role. 1 indicates master and 0 indicates replica. server.Uptime Seconds Uptime in seconds. stats.CacheHitRatio Count Cache Hit ratio as a fraction. stats.connections.Total Count Total number of connections accepted by the server. stats.CpuUtilization s { CPU} CPU-seconds consumed by the Redis server, broken down by system/user space and parent/child relationship. stats.EvictedKeys Count Number of evicted keys due to maxmemory limit. stats.ExpiredKeys Count Total number of key expiration events. stats.KeyspaceHits Count Number of successful lookup of keys in the main dictionary. stats.KeyspaceMisses Count Number of failed lookup of keys in the main dictionary. stats.memory.Maxmemory Bytes Maximum amount of memory Redis can consume. stats.memory.SystemMemoryOverloadDuration Microseconds The amount of time in microseconds the instance is in system memory overload mode. stats.memory.SystemMemoryUsageRatio Count Memory usage as a ratio of maximum system memory. stats.memory.Usage Bytes Total number of bytes allocated by Redis. stats.memory.UsageRatio Count Memory usage as a ratio of maximum memory. stats.NetworkTraffic Bytes Total number of bytes sent to/from redis (includes bytes from commands themselves, payload data, and delimiters). stats.pubsub.Channels Count Global number of pub/sub channels with client subscriptions. stats.pubsub.Patterns Count Global number of pub/sub pattern with client subscriptions. stats.RejectConnections Count Number of connections rejected because of maxclients limit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77513,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Redis",
        "sections": "<em>Google</em> Memorystore for Redis",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Redis data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f27bd378ee1"
    },
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "faf3c02773c3bb62ebd194ec0e6227e83ce910ea",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-10-01T19:49:00Z",
      "updated_at": "2021-09-14T20:39:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (e.g. hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f1644378ef0"
    },
    {
      "sections": [
        "Google Cloud Composer monitoring integration",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Composer Environment data",
        "Composer Workflow data"
      ],
      "title": "Google Cloud Composer monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a2cbc05bfa686de458fed2748ed111064b903ad4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration/",
      "published_at": "2021-10-01T19:08:43Z",
      "updated_at": "2021-09-14T20:39:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Composer data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Composer integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider Environment GcpComposerEnvironmentSample GcpComposerEnvironment Workflow GcpComposerWorkflowSample GcpComposerWorkflow For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Composer data for Environment and Workflow. Composer Environment data Metric Unit Description environment.api.Request Count Number of Composer API requests seen so far. environment.api.RequestLatencies Milliseconds Distribution of Composer API call latencies. environment.dag_processing.ParseError Count Number of errors raised during parsing DAG files. environment.dag_processing.Processes Count Number of currently running DAG parsing processes. environment.dag_processing.ProcessorTimeout Count Number of file processors terminated due to processing timeout. environment.dag_processing.TotalParseTime Seconds Number of seconds taken to scan and import all DAG files once. environment.DagbagSize Count The current dag bag size. environment.database.cpu.ReservedCores Count Number of cores reserved for the database instance. environment.database.cpu.UsageTime Seconds CPU usage time of the database instance. environment.database.cpu.Utilization Count CPU utilization ratio (from 0.0 to 1.0) of the database instance. environment.database.disk.BytesUsed Bytes Used disk space in bytes on the database instance. environment.database.disk.Quota Bytes Maximum data disk size in bytes of the database instance. environment.database.disk.Utilization Count Disk quota usage ratio (from 0.0 to 1.0) of the database instance. environment.database.memory.BytesUsed Bytes Memory usage of the database instance in bytes. environment.database.memory.Quota Bytes Maximum RAM size in bytes of the database instance. environment.database.memory.Utilization Count Memory utilization ratio (from 0.0 to 1.0) of the database instance. environment.executor.OpenSlots Count Number of open slots on executor. environment.executor.RunningTasks Count Number of running tasks on executor. environment.FinishedTaskInstance Count Overall task instances. environment.NumCeleryWorkers Count Number of Celery workers. environment.SchedulerHeartbeat Count Scheduler heartbeats. environment.TaskQueueLength Count Number of tasks in queue. environment.worker.PodEviction Count The number of Airflow worker pods evictions. environment.ZombieTaskKilled Count Number of zombie tasks killed. Composer Workflow data Metric Unit Description workflow.Run Count Number of workflow runs completed so far. workflow.RunDuration Seconds Duration of workflow run completion. workflow.task.Run Count Number of workflow tasks completed so far. workflow.task.RunDuration Seconds Duration of task completion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Composer monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Composer monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Composer data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "60450ccd196a67293b960f66"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-bigquery-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Redis",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Redis RedisInstance data"
      ],
      "title": "Google Memorystore for Redis",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "17f2891f284704c51e4e6cdac2c1b1de4b3aaf6a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-redis/",
      "published_at": "2021-10-01T19:17:20Z",
      "updated_at": "2021-09-14T20:40:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Redis data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Redis integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider RedisInstance GcpRedisInstanceSample GcpRedisInstance For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Redis data for RedisInstance. Redis RedisInstance data Metric Unit Description clients.Blocked Count Number of blocked clients. clients.Connected Count Number of client connections. commands.Calls Count Total number of calls for this command in one minute. commands.TotalTime Microseconds The amount of time in microseconds that this command took in the last second. commands.UsecPerCall Count Average time per call over 1 minute by command. keyspace.AvgTtl Milliseconds Average TTL for keys in this database. keyspace.Keys Count Number of keys stored in this database. keyspace.KeysWithExpiration Count Number of keys with an expiration in this database. replication.master.slaves.Lag Bytes The number of bytes that replica is behind. replication.master.slaves.Offset Bytes The number of bytes that have been acknowledged by replicas. replication.MasterReplOffset Bytes The number of bytes that master has produced and sent to replicas. To be compared with replication byte offset of replica. replication.OffsetDiff Bytes The number of bytes that have not been replicated to the replica. This is the difference between replication byte offset (master) and replication byte offset (replica). replication.Role Count Returns a value indicating the node role. 1 indicates master and 0 indicates replica. server.Uptime Seconds Uptime in seconds. stats.CacheHitRatio Count Cache Hit ratio as a fraction. stats.connections.Total Count Total number of connections accepted by the server. stats.CpuUtilization s { CPU} CPU-seconds consumed by the Redis server, broken down by system/user space and parent/child relationship. stats.EvictedKeys Count Number of evicted keys due to maxmemory limit. stats.ExpiredKeys Count Total number of key expiration events. stats.KeyspaceHits Count Number of successful lookup of keys in the main dictionary. stats.KeyspaceMisses Count Number of failed lookup of keys in the main dictionary. stats.memory.Maxmemory Bytes Maximum amount of memory Redis can consume. stats.memory.SystemMemoryOverloadDuration Microseconds The amount of time in microseconds the instance is in system memory overload mode. stats.memory.SystemMemoryUsageRatio Count Memory usage as a ratio of maximum system memory. stats.memory.Usage Bytes Total number of bytes allocated by Redis. stats.memory.UsageRatio Count Memory usage as a ratio of maximum memory. stats.NetworkTraffic Bytes Total number of bytes sent to/from redis (includes bytes from commands themselves, payload data, and delimiters). stats.pubsub.Channels Count Global number of pub/sub channels with client subscriptions. stats.pubsub.Patterns Count Global number of pub/sub pattern with client subscriptions. stats.RejectConnections Count Number of connections rejected because of maxclients limit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77513,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Redis",
        "sections": "<em>Google</em> Memorystore for Redis",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Redis data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f27bd378ee1"
    },
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "faf3c02773c3bb62ebd194ec0e6227e83ce910ea",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-10-01T19:49:00Z",
      "updated_at": "2021-09-14T20:39:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (e.g. hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f1644378ef0"
    },
    {
      "sections": [
        "Google Cloud Composer monitoring integration",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Composer Environment data",
        "Composer Workflow data"
      ],
      "title": "Google Cloud Composer monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a2cbc05bfa686de458fed2748ed111064b903ad4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration/",
      "published_at": "2021-10-01T19:08:43Z",
      "updated_at": "2021-09-14T20:39:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Composer data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Composer integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider Environment GcpComposerEnvironmentSample GcpComposerEnvironment Workflow GcpComposerWorkflowSample GcpComposerWorkflow For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Composer data for Environment and Workflow. Composer Environment data Metric Unit Description environment.api.Request Count Number of Composer API requests seen so far. environment.api.RequestLatencies Milliseconds Distribution of Composer API call latencies. environment.dag_processing.ParseError Count Number of errors raised during parsing DAG files. environment.dag_processing.Processes Count Number of currently running DAG parsing processes. environment.dag_processing.ProcessorTimeout Count Number of file processors terminated due to processing timeout. environment.dag_processing.TotalParseTime Seconds Number of seconds taken to scan and import all DAG files once. environment.DagbagSize Count The current dag bag size. environment.database.cpu.ReservedCores Count Number of cores reserved for the database instance. environment.database.cpu.UsageTime Seconds CPU usage time of the database instance. environment.database.cpu.Utilization Count CPU utilization ratio (from 0.0 to 1.0) of the database instance. environment.database.disk.BytesUsed Bytes Used disk space in bytes on the database instance. environment.database.disk.Quota Bytes Maximum data disk size in bytes of the database instance. environment.database.disk.Utilization Count Disk quota usage ratio (from 0.0 to 1.0) of the database instance. environment.database.memory.BytesUsed Bytes Memory usage of the database instance in bytes. environment.database.memory.Quota Bytes Maximum RAM size in bytes of the database instance. environment.database.memory.Utilization Count Memory utilization ratio (from 0.0 to 1.0) of the database instance. environment.executor.OpenSlots Count Number of open slots on executor. environment.executor.RunningTasks Count Number of running tasks on executor. environment.FinishedTaskInstance Count Overall task instances. environment.NumCeleryWorkers Count Number of Celery workers. environment.SchedulerHeartbeat Count Scheduler heartbeats. environment.TaskQueueLength Count Number of tasks in queue. environment.worker.PodEviction Count The number of Airflow worker pods evictions. environment.ZombieTaskKilled Count Number of zombie tasks killed. Composer Workflow data Metric Unit Description workflow.Run Count Number of workflow runs completed so far. workflow.RunDuration Seconds Duration of workflow run completion. workflow.task.Run Count Number of workflow tasks completed so far. workflow.task.RunDuration Seconds Duration of task completion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Composer monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Composer monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Composer data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "60450ccd196a67293b960f66"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-bigtable-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Redis",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Redis RedisInstance data"
      ],
      "title": "Google Memorystore for Redis",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "17f2891f284704c51e4e6cdac2c1b1de4b3aaf6a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-redis/",
      "published_at": "2021-10-01T19:17:20Z",
      "updated_at": "2021-09-14T20:40:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Redis data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Redis integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider RedisInstance GcpRedisInstanceSample GcpRedisInstance For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Redis data for RedisInstance. Redis RedisInstance data Metric Unit Description clients.Blocked Count Number of blocked clients. clients.Connected Count Number of client connections. commands.Calls Count Total number of calls for this command in one minute. commands.TotalTime Microseconds The amount of time in microseconds that this command took in the last second. commands.UsecPerCall Count Average time per call over 1 minute by command. keyspace.AvgTtl Milliseconds Average TTL for keys in this database. keyspace.Keys Count Number of keys stored in this database. keyspace.KeysWithExpiration Count Number of keys with an expiration in this database. replication.master.slaves.Lag Bytes The number of bytes that replica is behind. replication.master.slaves.Offset Bytes The number of bytes that have been acknowledged by replicas. replication.MasterReplOffset Bytes The number of bytes that master has produced and sent to replicas. To be compared with replication byte offset of replica. replication.OffsetDiff Bytes The number of bytes that have not been replicated to the replica. This is the difference between replication byte offset (master) and replication byte offset (replica). replication.Role Count Returns a value indicating the node role. 1 indicates master and 0 indicates replica. server.Uptime Seconds Uptime in seconds. stats.CacheHitRatio Count Cache Hit ratio as a fraction. stats.connections.Total Count Total number of connections accepted by the server. stats.CpuUtilization s { CPU} CPU-seconds consumed by the Redis server, broken down by system/user space and parent/child relationship. stats.EvictedKeys Count Number of evicted keys due to maxmemory limit. stats.ExpiredKeys Count Total number of key expiration events. stats.KeyspaceHits Count Number of successful lookup of keys in the main dictionary. stats.KeyspaceMisses Count Number of failed lookup of keys in the main dictionary. stats.memory.Maxmemory Bytes Maximum amount of memory Redis can consume. stats.memory.SystemMemoryOverloadDuration Microseconds The amount of time in microseconds the instance is in system memory overload mode. stats.memory.SystemMemoryUsageRatio Count Memory usage as a ratio of maximum system memory. stats.memory.Usage Bytes Total number of bytes allocated by Redis. stats.memory.UsageRatio Count Memory usage as a ratio of maximum memory. stats.NetworkTraffic Bytes Total number of bytes sent to/from redis (includes bytes from commands themselves, payload data, and delimiters). stats.pubsub.Channels Count Global number of pub/sub channels with client subscriptions. stats.pubsub.Patterns Count Global number of pub/sub pattern with client subscriptions. stats.RejectConnections Count Number of connections rejected because of maxclients limit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77513,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Redis",
        "sections": "<em>Google</em> Memorystore for Redis",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Redis data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f27bd378ee1"
    },
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "faf3c02773c3bb62ebd194ec0e6227e83ce910ea",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-10-01T19:49:00Z",
      "updated_at": "2021-09-14T20:39:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (e.g. hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f1644378ef0"
    },
    {
      "sections": [
        "Google Cloud Composer monitoring integration",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Composer Environment data",
        "Composer Workflow data"
      ],
      "title": "Google Cloud Composer monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a2cbc05bfa686de458fed2748ed111064b903ad4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration/",
      "published_at": "2021-10-01T19:08:43Z",
      "updated_at": "2021-09-14T20:39:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Composer data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Composer integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider Environment GcpComposerEnvironmentSample GcpComposerEnvironment Workflow GcpComposerWorkflowSample GcpComposerWorkflow For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Composer data for Environment and Workflow. Composer Environment data Metric Unit Description environment.api.Request Count Number of Composer API requests seen so far. environment.api.RequestLatencies Milliseconds Distribution of Composer API call latencies. environment.dag_processing.ParseError Count Number of errors raised during parsing DAG files. environment.dag_processing.Processes Count Number of currently running DAG parsing processes. environment.dag_processing.ProcessorTimeout Count Number of file processors terminated due to processing timeout. environment.dag_processing.TotalParseTime Seconds Number of seconds taken to scan and import all DAG files once. environment.DagbagSize Count The current dag bag size. environment.database.cpu.ReservedCores Count Number of cores reserved for the database instance. environment.database.cpu.UsageTime Seconds CPU usage time of the database instance. environment.database.cpu.Utilization Count CPU utilization ratio (from 0.0 to 1.0) of the database instance. environment.database.disk.BytesUsed Bytes Used disk space in bytes on the database instance. environment.database.disk.Quota Bytes Maximum data disk size in bytes of the database instance. environment.database.disk.Utilization Count Disk quota usage ratio (from 0.0 to 1.0) of the database instance. environment.database.memory.BytesUsed Bytes Memory usage of the database instance in bytes. environment.database.memory.Quota Bytes Maximum RAM size in bytes of the database instance. environment.database.memory.Utilization Count Memory utilization ratio (from 0.0 to 1.0) of the database instance. environment.executor.OpenSlots Count Number of open slots on executor. environment.executor.RunningTasks Count Number of running tasks on executor. environment.FinishedTaskInstance Count Overall task instances. environment.NumCeleryWorkers Count Number of Celery workers. environment.SchedulerHeartbeat Count Scheduler heartbeats. environment.TaskQueueLength Count Number of tasks in queue. environment.worker.PodEviction Count The number of Airflow worker pods evictions. environment.ZombieTaskKilled Count Number of zombie tasks killed. Composer Workflow data Metric Unit Description workflow.Run Count Number of workflow runs completed so far. workflow.RunDuration Seconds Duration of workflow run completion. workflow.task.Run Count Number of workflow tasks completed so far. workflow.task.RunDuration Seconds Duration of task completion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Composer monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Composer monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Composer data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "60450ccd196a67293b960f66"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Redis",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Redis RedisInstance data"
      ],
      "title": "Google Memorystore for Redis",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "17f2891f284704c51e4e6cdac2c1b1de4b3aaf6a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-redis/",
      "published_at": "2021-10-01T19:17:20Z",
      "updated_at": "2021-09-14T20:40:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Redis data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Redis integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider RedisInstance GcpRedisInstanceSample GcpRedisInstance For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Redis data for RedisInstance. Redis RedisInstance data Metric Unit Description clients.Blocked Count Number of blocked clients. clients.Connected Count Number of client connections. commands.Calls Count Total number of calls for this command in one minute. commands.TotalTime Microseconds The amount of time in microseconds that this command took in the last second. commands.UsecPerCall Count Average time per call over 1 minute by command. keyspace.AvgTtl Milliseconds Average TTL for keys in this database. keyspace.Keys Count Number of keys stored in this database. keyspace.KeysWithExpiration Count Number of keys with an expiration in this database. replication.master.slaves.Lag Bytes The number of bytes that replica is behind. replication.master.slaves.Offset Bytes The number of bytes that have been acknowledged by replicas. replication.MasterReplOffset Bytes The number of bytes that master has produced and sent to replicas. To be compared with replication byte offset of replica. replication.OffsetDiff Bytes The number of bytes that have not been replicated to the replica. This is the difference between replication byte offset (master) and replication byte offset (replica). replication.Role Count Returns a value indicating the node role. 1 indicates master and 0 indicates replica. server.Uptime Seconds Uptime in seconds. stats.CacheHitRatio Count Cache Hit ratio as a fraction. stats.connections.Total Count Total number of connections accepted by the server. stats.CpuUtilization s { CPU} CPU-seconds consumed by the Redis server, broken down by system/user space and parent/child relationship. stats.EvictedKeys Count Number of evicted keys due to maxmemory limit. stats.ExpiredKeys Count Total number of key expiration events. stats.KeyspaceHits Count Number of successful lookup of keys in the main dictionary. stats.KeyspaceMisses Count Number of failed lookup of keys in the main dictionary. stats.memory.Maxmemory Bytes Maximum amount of memory Redis can consume. stats.memory.SystemMemoryOverloadDuration Microseconds The amount of time in microseconds the instance is in system memory overload mode. stats.memory.SystemMemoryUsageRatio Count Memory usage as a ratio of maximum system memory. stats.memory.Usage Bytes Total number of bytes allocated by Redis. stats.memory.UsageRatio Count Memory usage as a ratio of maximum memory. stats.NetworkTraffic Bytes Total number of bytes sent to/from redis (includes bytes from commands themselves, payload data, and delimiters). stats.pubsub.Channels Count Global number of pub/sub channels with client subscriptions. stats.pubsub.Patterns Count Global number of pub/sub pattern with client subscriptions. stats.RejectConnections Count Number of connections rejected because of maxclients limit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77512,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Redis",
        "sections": "<em>Google</em> Memorystore for Redis",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Redis data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f27bd378ee1"
    },
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "faf3c02773c3bb62ebd194ec0e6227e83ce910ea",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-10-01T19:49:00Z",
      "updated_at": "2021-09-14T20:39:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (e.g. hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.7736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f1644378ef0"
    },
    {
      "sections": [
        "Google Cloud Bigtable monitoring integration",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Bigtable Cluster data",
        "Bigtable Table data"
      ],
      "title": "Google Cloud Bigtable monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a7cd3b2dca9763ad525a473fb8a9ed19d60d0875",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-bigtable-monitoring-integration/",
      "published_at": "2021-10-01T19:08:43Z",
      "updated_at": "2021-09-14T20:39:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Bigtable data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Bigtable integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider Cluster GcpBigtableClusterSample GcpBigtableCluster Table GcpBigtableTableSample GcpBigtableTable For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Bigtable data for Cluster and Table. Bigtable Cluster data Metric Unit Description cluster.CpuLoad Count CPU load of a cluster. cluster.CpuLoadHottestNode Count CPU load of the busiest node in a cluster. cluster.DiskLoad Count Utilization of HDD disks in a cluster. cluster.Node Count Number of nodes in a cluster. cluster.StorageUtilization Count Storage used as a fraction of total storage capacity. disk.BytesUsed Bytes Amount of compressed data for tables stored in a cluster. disk.StorageCapacity Bytes Capacity of compressed data for tables that can be stored in a cluster. Bigtable Table data Metric Unit Description replication.Latency Milliseconds Distribution of replication request latencies for a table. Includes only requests that have been received by the destination cluster. replication.MaxDelay Seconds Upper bound for replication delay between clusters of a table. Indicates the time frame during which latency information may not be accurate. server.Error Count Number of server requests for a table that failed with an error. server.Latencies Milliseconds Distribution of server request latencies for a table, measured when calls reach Cloud Bigtable. server.ModifiedRows Count Number of rows modified by server requests for a table. server.MultiClusterFailovers Count Number of failovers during multi-cluster requests. server.ReceivedBytes Bytes Number of uncompressed bytes of request data received by servers for a table. server.Request Count Number of server requests for a table. server.ReturnedRows Count Number of rows returned by server requests for a table. server.SentBytes Bytes Number of uncompressed bytes of response data sent by servers for a table. table.BytesUsed Bytes Amount of compressed data stored in a table.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.7733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Bigtable monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Bigtable monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Bigtable data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "6045082f196a67af34960f20"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataflow-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Redis",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Redis RedisInstance data"
      ],
      "title": "Google Memorystore for Redis",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "17f2891f284704c51e4e6cdac2c1b1de4b3aaf6a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-redis/",
      "published_at": "2021-10-01T19:17:20Z",
      "updated_at": "2021-09-14T20:40:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Redis data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Redis integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider RedisInstance GcpRedisInstanceSample GcpRedisInstance For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Redis data for RedisInstance. Redis RedisInstance data Metric Unit Description clients.Blocked Count Number of blocked clients. clients.Connected Count Number of client connections. commands.Calls Count Total number of calls for this command in one minute. commands.TotalTime Microseconds The amount of time in microseconds that this command took in the last second. commands.UsecPerCall Count Average time per call over 1 minute by command. keyspace.AvgTtl Milliseconds Average TTL for keys in this database. keyspace.Keys Count Number of keys stored in this database. keyspace.KeysWithExpiration Count Number of keys with an expiration in this database. replication.master.slaves.Lag Bytes The number of bytes that replica is behind. replication.master.slaves.Offset Bytes The number of bytes that have been acknowledged by replicas. replication.MasterReplOffset Bytes The number of bytes that master has produced and sent to replicas. To be compared with replication byte offset of replica. replication.OffsetDiff Bytes The number of bytes that have not been replicated to the replica. This is the difference between replication byte offset (master) and replication byte offset (replica). replication.Role Count Returns a value indicating the node role. 1 indicates master and 0 indicates replica. server.Uptime Seconds Uptime in seconds. stats.CacheHitRatio Count Cache Hit ratio as a fraction. stats.connections.Total Count Total number of connections accepted by the server. stats.CpuUtilization s { CPU} CPU-seconds consumed by the Redis server, broken down by system/user space and parent/child relationship. stats.EvictedKeys Count Number of evicted keys due to maxmemory limit. stats.ExpiredKeys Count Total number of key expiration events. stats.KeyspaceHits Count Number of successful lookup of keys in the main dictionary. stats.KeyspaceMisses Count Number of failed lookup of keys in the main dictionary. stats.memory.Maxmemory Bytes Maximum amount of memory Redis can consume. stats.memory.SystemMemoryOverloadDuration Microseconds The amount of time in microseconds the instance is in system memory overload mode. stats.memory.SystemMemoryUsageRatio Count Memory usage as a ratio of maximum system memory. stats.memory.Usage Bytes Total number of bytes allocated by Redis. stats.memory.UsageRatio Count Memory usage as a ratio of maximum memory. stats.NetworkTraffic Bytes Total number of bytes sent to/from redis (includes bytes from commands themselves, payload data, and delimiters). stats.pubsub.Channels Count Global number of pub/sub channels with client subscriptions. stats.pubsub.Patterns Count Global number of pub/sub pattern with client subscriptions. stats.RejectConnections Count Number of connections rejected because of maxclients limit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77512,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Redis",
        "sections": "<em>Google</em> Memorystore for Redis",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Redis data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f27bd378ee1"
    },
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "faf3c02773c3bb62ebd194ec0e6227e83ce910ea",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-10-01T19:49:00Z",
      "updated_at": "2021-09-14T20:39:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (e.g. hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.7736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f1644378ef0"
    },
    {
      "sections": [
        "Google Cloud Composer monitoring integration",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Composer Environment data",
        "Composer Workflow data"
      ],
      "title": "Google Cloud Composer monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a2cbc05bfa686de458fed2748ed111064b903ad4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration/",
      "published_at": "2021-10-01T19:08:43Z",
      "updated_at": "2021-09-14T20:39:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Composer data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Composer integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider Environment GcpComposerEnvironmentSample GcpComposerEnvironment Workflow GcpComposerWorkflowSample GcpComposerWorkflow For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Composer data for Environment and Workflow. Composer Environment data Metric Unit Description environment.api.Request Count Number of Composer API requests seen so far. environment.api.RequestLatencies Milliseconds Distribution of Composer API call latencies. environment.dag_processing.ParseError Count Number of errors raised during parsing DAG files. environment.dag_processing.Processes Count Number of currently running DAG parsing processes. environment.dag_processing.ProcessorTimeout Count Number of file processors terminated due to processing timeout. environment.dag_processing.TotalParseTime Seconds Number of seconds taken to scan and import all DAG files once. environment.DagbagSize Count The current dag bag size. environment.database.cpu.ReservedCores Count Number of cores reserved for the database instance. environment.database.cpu.UsageTime Seconds CPU usage time of the database instance. environment.database.cpu.Utilization Count CPU utilization ratio (from 0.0 to 1.0) of the database instance. environment.database.disk.BytesUsed Bytes Used disk space in bytes on the database instance. environment.database.disk.Quota Bytes Maximum data disk size in bytes of the database instance. environment.database.disk.Utilization Count Disk quota usage ratio (from 0.0 to 1.0) of the database instance. environment.database.memory.BytesUsed Bytes Memory usage of the database instance in bytes. environment.database.memory.Quota Bytes Maximum RAM size in bytes of the database instance. environment.database.memory.Utilization Count Memory utilization ratio (from 0.0 to 1.0) of the database instance. environment.executor.OpenSlots Count Number of open slots on executor. environment.executor.RunningTasks Count Number of running tasks on executor. environment.FinishedTaskInstance Count Overall task instances. environment.NumCeleryWorkers Count Number of Celery workers. environment.SchedulerHeartbeat Count Scheduler heartbeats. environment.TaskQueueLength Count Number of tasks in queue. environment.worker.PodEviction Count The number of Airflow worker pods evictions. environment.ZombieTaskKilled Count Number of zombie tasks killed. Composer Workflow data Metric Unit Description workflow.Run Count Number of workflow runs completed so far. workflow.RunDuration Seconds Duration of workflow run completion. workflow.task.Run Count Number of workflow tasks completed so far. workflow.task.RunDuration Seconds Duration of task completion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.7733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Composer monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Composer monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Composer data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "60450ccd196a67293b960f66"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataproc-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Redis",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Redis RedisInstance data"
      ],
      "title": "Google Memorystore for Redis",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "17f2891f284704c51e4e6cdac2c1b1de4b3aaf6a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-redis/",
      "published_at": "2021-10-01T19:17:20Z",
      "updated_at": "2021-09-14T20:40:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Redis data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Redis integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider RedisInstance GcpRedisInstanceSample GcpRedisInstance For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Redis data for RedisInstance. Redis RedisInstance data Metric Unit Description clients.Blocked Count Number of blocked clients. clients.Connected Count Number of client connections. commands.Calls Count Total number of calls for this command in one minute. commands.TotalTime Microseconds The amount of time in microseconds that this command took in the last second. commands.UsecPerCall Count Average time per call over 1 minute by command. keyspace.AvgTtl Milliseconds Average TTL for keys in this database. keyspace.Keys Count Number of keys stored in this database. keyspace.KeysWithExpiration Count Number of keys with an expiration in this database. replication.master.slaves.Lag Bytes The number of bytes that replica is behind. replication.master.slaves.Offset Bytes The number of bytes that have been acknowledged by replicas. replication.MasterReplOffset Bytes The number of bytes that master has produced and sent to replicas. To be compared with replication byte offset of replica. replication.OffsetDiff Bytes The number of bytes that have not been replicated to the replica. This is the difference between replication byte offset (master) and replication byte offset (replica). replication.Role Count Returns a value indicating the node role. 1 indicates master and 0 indicates replica. server.Uptime Seconds Uptime in seconds. stats.CacheHitRatio Count Cache Hit ratio as a fraction. stats.connections.Total Count Total number of connections accepted by the server. stats.CpuUtilization s { CPU} CPU-seconds consumed by the Redis server, broken down by system/user space and parent/child relationship. stats.EvictedKeys Count Number of evicted keys due to maxmemory limit. stats.ExpiredKeys Count Total number of key expiration events. stats.KeyspaceHits Count Number of successful lookup of keys in the main dictionary. stats.KeyspaceMisses Count Number of failed lookup of keys in the main dictionary. stats.memory.Maxmemory Bytes Maximum amount of memory Redis can consume. stats.memory.SystemMemoryOverloadDuration Microseconds The amount of time in microseconds the instance is in system memory overload mode. stats.memory.SystemMemoryUsageRatio Count Memory usage as a ratio of maximum system memory. stats.memory.Usage Bytes Total number of bytes allocated by Redis. stats.memory.UsageRatio Count Memory usage as a ratio of maximum memory. stats.NetworkTraffic Bytes Total number of bytes sent to/from redis (includes bytes from commands themselves, payload data, and delimiters). stats.pubsub.Channels Count Global number of pub/sub channels with client subscriptions. stats.pubsub.Patterns Count Global number of pub/sub pattern with client subscriptions. stats.RejectConnections Count Number of connections rejected because of maxclients limit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.77512,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Redis",
        "sections": "<em>Google</em> Memorystore for Redis",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Redis data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f27bd378ee1"
    },
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "faf3c02773c3bb62ebd194ec0e6227e83ce910ea",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-10-01T19:49:00Z",
      "updated_at": "2021-09-14T20:39:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (e.g. hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.7736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "604508a864441f1644378ef0"
    },
    {
      "sections": [
        "Google Cloud Composer monitoring integration",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Composer Environment data",
        "Composer Workflow data"
      ],
      "title": "Google Cloud Composer monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a2cbc05bfa686de458fed2748ed111064b903ad4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration/",
      "published_at": "2021-10-01T19:08:43Z",
      "updated_at": "2021-09-14T20:39:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Composer data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Composer integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider Environment GcpComposerEnvironmentSample GcpComposerEnvironment Workflow GcpComposerWorkflowSample GcpComposerWorkflow For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Composer data for Environment and Workflow. Composer Environment data Metric Unit Description environment.api.Request Count Number of Composer API requests seen so far. environment.api.RequestLatencies Milliseconds Distribution of Composer API call latencies. environment.dag_processing.ParseError Count Number of errors raised during parsing DAG files. environment.dag_processing.Processes Count Number of currently running DAG parsing processes. environment.dag_processing.ProcessorTimeout Count Number of file processors terminated due to processing timeout. environment.dag_processing.TotalParseTime Seconds Number of seconds taken to scan and import all DAG files once. environment.DagbagSize Count The current dag bag size. environment.database.cpu.ReservedCores Count Number of cores reserved for the database instance. environment.database.cpu.UsageTime Seconds CPU usage time of the database instance. environment.database.cpu.Utilization Count CPU utilization ratio (from 0.0 to 1.0) of the database instance. environment.database.disk.BytesUsed Bytes Used disk space in bytes on the database instance. environment.database.disk.Quota Bytes Maximum data disk size in bytes of the database instance. environment.database.disk.Utilization Count Disk quota usage ratio (from 0.0 to 1.0) of the database instance. environment.database.memory.BytesUsed Bytes Memory usage of the database instance in bytes. environment.database.memory.Quota Bytes Maximum RAM size in bytes of the database instance. environment.database.memory.Utilization Count Memory utilization ratio (from 0.0 to 1.0) of the database instance. environment.executor.OpenSlots Count Number of open slots on executor. environment.executor.RunningTasks Count Number of running tasks on executor. environment.FinishedTaskInstance Count Overall task instances. environment.NumCeleryWorkers Count Number of Celery workers. environment.SchedulerHeartbeat Count Scheduler heartbeats. environment.TaskQueueLength Count Number of tasks in queue. environment.worker.PodEviction Count The number of Airflow worker pods evictions. environment.ZombieTaskKilled Count Number of zombie tasks killed. Composer Workflow data Metric Unit Description workflow.Run Count Number of workflow runs completed so far. workflow.RunDuration Seconds Duration of workflow run completion. workflow.task.Run Count Number of workflow tasks completed so far. workflow.task.RunDuration Seconds Duration of task completion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.7733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Composer monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Composer monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Composer data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "60450ccd196a67293b960f66"
    }
  ]
}