{
  "/docs/distributed-tracing/trace-api/introduction-trace-api": [
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2022-01-12T08:26:17Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.40027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2022-01-12T08:25:34Z",
      "updated_at": "2022-01-08T03:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See the setup options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.58841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete <em>trace</em> even when calls cross an organization&#x27;s account boundaries. See Introduction to <em>distributed</em> <em>tracing</em> for more features. Enabling <em>distributed</em> <em>tracing</em> may affect some APM features you"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2022-01-12T06:21:31Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to the advanced Infinite Tracing feature. If you are just getting started with distributed tracing, see our setup options. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.39853,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Infinite <em>Tracing</em> feature. If you are just getting started with <em>distributed</em> <em>tracing</em>, see our setup options. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api": [
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2022-01-12T08:26:17Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.40027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2022-01-12T08:25:34Z",
      "updated_at": "2022-01-08T03:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See the setup options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.58841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete <em>trace</em> even when calls cross an organization&#x27;s account boundaries. See Introduction to <em>distributed</em> <em>tracing</em> for more features. Enabling <em>distributed</em> <em>tracing</em> may affect some APM features you"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2022-01-12T06:21:31Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to the advanced Infinite Tracing feature. If you are just getting started with distributed tracing, see our setup options. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.39853,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Infinite <em>Tracing</em> feature. If you are just getting started with <em>distributed</em> <em>tracing</em>, see our setup options. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api": [
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2022-01-12T08:25:34Z",
      "updated_at": "2022-01-08T03:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See the setup options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.58832,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete <em>trace</em> even when calls cross an organization&#x27;s account boundaries. See Introduction to <em>distributed</em> <em>tracing</em> for more features. Enabling <em>distributed</em> <em>tracing</em> may affect some APM features you"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2022-01-12T06:21:31Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to the advanced Infinite Tracing feature. If you are just getting started with distributed tracing, see our setup options. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.39844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Infinite <em>Tracing</em> feature. If you are just getting started with <em>distributed</em> <em>tracing</em>, see our setup options. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Want to get started right away?",
        "Want to learn more before getting started?"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/2878076657e1173d9f8c92a6e7547a9f/83b75/intro-DT.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2022-01-12T06:19:55Z",
      "updated_at": "2022-01-05T01:43:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. Requests might pass through various services to reach completion, and these services could be in a variety of places: containers, serverless environments, virtual machines, different cloud providers, or on-premises. When you can see the path of an entire request across different services, you can quickly pinpoint failures or performance issues. Distributed tracing collects data as requests travel from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are eventually combined into one trace. The completed trace gives you a picture of the entire request. Here is an example of a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans, and the spans are combined into one distributed trace. Want to get started right away? If you are familiar with distributed tracing and want to jump right in, check out the setup options. Want to learn more before getting started? See these distributed tracing topics: How does distributed tracing work, and what types of distributed tracing are available? How can I troubleshoot requests using the distributed tracing UI? How should I plan my rollout of distributed tracing? What is the advanced feature called Infinite Tracing?",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.97687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Relic as spans, and the spans are combined into one <em>distributed</em> <em>trace</em>. Want to get started right away? If you are familiar with <em>distributed</em> <em>tracing</em> and want to jump right in, check out the setup options. Want to learn more before getting started? See these <em>distributed</em> <em>tracing</em> topics: How does"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-decorate-spans-attributes": [
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2022-01-12T08:26:17Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.40015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2022-01-12T08:25:34Z",
      "updated_at": "2022-01-08T03:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See the setup options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.58832,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete <em>trace</em> even when calls cross an organization&#x27;s account boundaries. See Introduction to <em>distributed</em> <em>tracing</em> for more features. Enabling <em>distributed</em> <em>tracing</em> may affect some APM features you"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2022-01-12T06:21:31Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to the advanced Infinite Tracing feature. If you are just getting started with distributed tracing, see our setup options. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.39844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Infinite <em>Tracing</em> feature. If you are just getting started with <em>distributed</em> <em>tracing</em>, see our setup options. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits": [
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2022-01-12T08:26:17Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.40002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2022-01-12T08:25:34Z",
      "updated_at": "2022-01-08T03:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See the setup options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.58821,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete <em>trace</em> even when calls cross an organization&#x27;s account boundaries. See Introduction to <em>distributed</em> <em>tracing</em> for more features. Enabling <em>distributed</em> <em>tracing</em> may affect some APM features you"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2022-01-12T06:21:31Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to the advanced Infinite Tracing feature. If you are just getting started with distributed tracing, see our setup options. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.39835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Infinite <em>Tracing</em> feature. If you are just getting started with <em>distributed</em> <em>tracing</em>, see our setup options. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts": [
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2022-01-12T08:25:34Z",
      "updated_at": "2022-01-08T03:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See the setup options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.57469,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete <em>trace</em> even when calls cross an organization&#x27;s account boundaries. See Introduction to <em>distributed</em> <em>tracing</em> for more features. Enabling <em>distributed</em> <em>tracing</em> may affect some APM features you"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2022-01-12T08:26:17Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.1578,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> API",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-api.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2022-01-12T06:21:31Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to the advanced Infinite Tracing feature. If you are just getting started with distributed tracing, see our setup options. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.52122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Infinite <em>Tracing</em> feature. If you are just getting started with <em>distributed</em> <em>tracing</em>, see our setup options. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/missing-trace-data": [
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2022-01-12T08:25:34Z",
      "updated_at": "2022-01-08T03:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See the setup options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.57458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete <em>trace</em> even when calls cross an organization&#x27;s account boundaries. See Introduction to <em>distributed</em> <em>tracing</em> for more features. Enabling <em>distributed</em> <em>tracing</em> may affect some APM features you"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2022-01-12T08:26:17Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.15768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> API",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-api.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in our <em>distributed</em> <em>tracing</em> UI. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2022-01-12T06:21:31Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to the advanced Infinite Tracing feature. If you are just getting started with distributed tracing, see our setup options. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.52112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Infinite <em>Tracing</em> feature. If you are just getting started with <em>distributed</em> <em>tracing</em>, see our setup options. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/ui-data/query-distributed-trace-data": [
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2022-01-12T08:26:17Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> API",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-api.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in our <em>distributed</em> <em>tracing</em> <em>UI</em>. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2022-01-12T08:25:34Z",
      "updated_at": "2022-01-08T03:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See the setup options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.40744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " that information, you would instead go to the <em>Distributed</em> <em>tracing</em> <em>UI</em> page, find the external call URLs, and see what their child spans are. Transaction <em>trace</em> <em>UI</em> displays service URLs, not transaction links When <em>distributed</em> <em>tracing</em> is enabled for an application, the transaction <em>trace</em> <em>UI</em>"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2022-01-12T06:21:31Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to the advanced Infinite Tracing feature. If you are just getting started with distributed tracing, see our setup options. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.52112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Infinite <em>Tracing</em> feature. If you are just getting started with <em>distributed</em> <em>tracing</em>, see our setup options. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> <em>data</em> to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/ui-data/span-attributes": [
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2022-01-12T08:26:17Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.38287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> API",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-api.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in our <em>distributed</em> <em>tracing</em> <em>UI</em>. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2022-01-12T08:25:34Z",
      "updated_at": "2022-01-08T03:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See the setup options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.40733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " that information, you would instead go to the <em>Distributed</em> <em>tracing</em> <em>UI</em> page, find the external call URLs, and see what their child spans are. Transaction <em>trace</em> <em>UI</em> displays service URLs, not transaction links When <em>distributed</em> <em>tracing</em> is enabled for an application, the transaction <em>trace</em> <em>UI</em>"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2022-01-12T06:21:31Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to the advanced Infinite Tracing feature. If you are just getting started with distributed tracing, see our setup options. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.52103,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Infinite <em>Tracing</em> feature. If you are just getting started with <em>distributed</em> <em>tracing</em>, see our setup options. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> <em>data</em> to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui": [
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2022-01-12T08:26:17Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get the license key for the account you want to report data to. You'll be executing a curl request, below. Notes on this: Replace the license key placeholder with your license key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_LICENSE_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.38287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> API",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> API",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-api.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in our <em>distributed</em> <em>tracing</em> <em>UI</em>. To find it, run a query for the <em>trace</em>.id. In this example, it was test-zipkin-<em>trace</em>-id-1. Note that you search by the transformed"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2022-01-12T08:25:34Z",
      "updated_at": "2022-01-08T03:46:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross an organization's account boundaries. See Introduction to distributed tracing for more features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See the setup options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.40733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " that information, you would instead go to the <em>Distributed</em> <em>tracing</em> <em>UI</em> page, find the external call URLs, and see what their child spans are. Transaction <em>trace</em> <em>UI</em> displays service URLs, not transaction links When <em>distributed</em> <em>tracing</em> is enabled for an application, the transaction <em>trace</em> <em>UI</em>"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2022-01-12T06:21:31Z",
      "updated_at": "2022-01-08T03:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to the advanced Infinite Tracing feature. If you are just getting started with distributed tracing, see our setup options. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.52103,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " Infinite <em>Tracing</em> feature. If you are just getting started with <em>distributed</em> <em>tracing</em>, see our setup options. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> <em>data</em> to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/errors-inbox/error-limiting": [
    {
      "sections": [
        "Introduction to notifications",
        "Early access",
        "Destinations",
        "Message templates"
      ],
      "title": "Introduction to notifications",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Notifications",
        "Workflows",
        "Error Inbox"
      ],
      "external_id": "f623ca3e096307c13e6e9214cc2fa6908707d101",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/intro-notifications/",
      "published_at": "2022-01-12T08:12:33Z",
      "updated_at": "2021-11-25T00:02:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Notifications are a consolidation of the different ways to send notification-events to third-party services, such as Slack, Jira, ServiceNow, and email. You can also use webhooks to send your data to any compatible third-party service. Integrate with your systems by configuring destinations and message templates. Destinations Destinations are unique identifiers and connection details for third-party systems. Use destinations to integrate, send notifications and share data between New Relic and your third-party systems. Message templates Configure the eventual notification events and map New Relic One data to your third-party services using message-templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.29456,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Error</em> <em>Inbox</em>"
      },
      "id": "6190270f64441f165fe9d12b"
    },
    {
      "sections": [
        "Python agent configuration",
        "Configuration methods and precedence",
        "Agent configuration file",
        "Tip",
        "Server-side configuration",
        "Important",
        "Environment variables",
        "Per-request configuration",
        "Example: Apache/mod_wsgi app name",
        "newrelic.set_background_task",
        "newrelic.ignore_transaction",
        "newrelic.suppress_apdex_metric",
        "newrelic.suppress_transaction_trace",
        "newrelic.disable_browser_autorum",
        "Multiple environment configuration",
        "General configuration settings",
        "license_key (REQUIRED)",
        "app_name (HIGHLY RECOMMENDED)",
        "monitor_mode",
        "developer_mode",
        "log_file",
        "log_level",
        "high_security",
        "proxy_scheme, proxy_host, proxy_port, proxy_user, proxy_pass",
        "audit_log_file",
        "Caution",
        "labels (tags)",
        "Two tags",
        "process_host.display_name",
        "api_key",
        "ca_bundle_path",
        "apdex_t",
        "Attributes",
        "attributes.enabled",
        "attributes.include",
        "attributes.exclude",
        "Transaction tracer configuration",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.attributes.enabled",
        "transaction_tracer.attributes.include",
        "transaction_tracer.attributes.exclude",
        "transaction_tracer.function_trace",
        "Transaction segment configuration",
        "transaction_segments.attributes.enabled",
        "transaction_segments.attributes.include",
        "transaction_segments.attributes.exclude",
        "Error collector configuration",
        "error_collector.enabled",
        "error_collector.ignore_classes",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_status_codes",
        "error_collector.attributes.enabled",
        "error_collector.attributes.include",
        "error_collector.attributes.exclude",
        "error_collector.capture_events",
        "Browser monitoring settings",
        "browser_monitoring.enabled",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.content_type",
        "Instrument xhtml+xml page responses",
        "browser_monitoring.attributes.enabled",
        "browser_monitoring.attributes.include",
        "browser_monitoring.attributes.exclude",
        "Transaction events settings",
        "transaction_events.enabled",
        "transaction_events.attributes.enabled",
        "transaction_events.attributes.include",
        "transaction_events.attributes.exclude",
        "Custom events settings",
        "custom_insights_events.enabled",
        "Datastore tracer settings",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "Distributed tracing settings",
        "distributed_tracing.enabled",
        "Span event configuration",
        "span_events.enabled",
        "span_events.attributes.enabled",
        "span_events.attributes.include",
        "span_events.attributes.exclude",
        "Event harvest configuration",
        "Usage example",
        "event_harvest_config.harvest_limits.analytic_event_data",
        "event_harvest_config.harvest_limits.custom_event_data",
        "event_harvest_config.harvest_limits.span_event_data",
        "event_harvest_config.harvest_limits.error_event_data",
        "Event loop visibility settings",
        "event_loop_visibility.enabled",
        "event_loop_visibility.blocking_threshold",
        "Garbage collection runtime metrics settings",
        "gc_runtime_metrics.enabled",
        "gc_runtime_metrics.top_object_count_limit",
        "Other configuration settings",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "slow_sql.enabled",
        "thread_profiler.enabled",
        "cross_application_tracer.enabled",
        "strip_exception_messages.enabled",
        "strip_exception_messages.whitelist",
        "startup_timeout",
        "shutdown_timeout",
        "compressed_content_encoding",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Built-in instrumentation",
        "Example: Disabling MySQLdb database query instrumentation"
      ],
      "title": "Python agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Python agent",
        "Configuration"
      ],
      "external_id": "923b7c4b9b48b55402bc7793ef3e12b0bdcfa8dc",
      "image": "https://docs.newrelic.com/static/0bbb623699fa652795cba242b01caa6b/8c557/diagram-python-config-precedence_0.png",
      "url": "https://docs.newrelic.com/docs/apm/agents/python-agent/configuration/python-agent-configuration/",
      "published_at": "2022-01-12T11:33:43Z",
      "updated_at": "2022-01-12T11:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Python agent lets you change the default agent behavior agent using configuration options. The only required Python agent configuration setting is the license key. The license key identifies the account where the agent reports application data. Depending on how you are hosting your application, the license key can be provided via a configuration file or an environment variable. Configuration methods and precedence The primary way to configure the Python agent is via the configuration file, which is generated as part of the standard install process. It is also possible to set a limited number of configuration options using server-side configuration in the UI or by using environment variables. You can also specify some settings on a per-request basis by passing settings with the WSGI request environ dictionary. The Python agent follows this order of precedence for configuration: With the Python agent, per-request options override server-side config. If enabled, server-side config overrides all corresponding values in the agent config file, even if the server-side values are left blank. The agent config file overrides environment variables. Environment variables override the agent defaults. Here are detailed descriptions of each configuration method: Agent configuration file Typically you configure your Python agent from a local configuration file on the agent's host system. Supply the path to the config file at startup using one of these methods: When you call newrelic.agent.initialize(), provide the path to the config file as the first argument. OR Set the NEW_RELIC_CONFIG_FILE environment variable. If you use the newrelic-admin wrapper script, you must use the environment variable because the wrapper script calls the agent automatically. The configuration file uses a structure similar to Microsoft Windows .ini files. For more information, see the Python ConfigParser module's file format documentation. Tip A sample configuration file is included with the Python agent as newrelic/newrelic.ini. You can also generate one from the newrelic-admin script using the generate-config command, or download a copy from our download repo. Server-side configuration Server-side configuration allows you to configure certain settings in the New Relic One UI. This applies your changes automatically to all agents even if they run across multiple hosts. Where available, this document includes the UI labels for server-side config under individual config options as the Server-side label. Important If server-side config is enabled, the agent ignores any value in the config file that could be set in the UI. Even if the UI value is empty, the agent treats this as an empty string and does not use the agent config file. Environment variables Environment variables allow you to override the defaults for certain core settings. If the equivalent setting is explicitly listed in the agent config file, the config file settings take precedence over the environment variable. Where available, environment variables are documented below under individual config options as the Environ variable. For simple configurations, you can use the environment variables in conjunction with server-side configuration and avoid the agent config file altogether. This is the default setup with Heroku, where installing the New Relic add-on automatically populates the necessary environment variables. If you're using New Relic APM and CodeStream, see how to associate repositories and how to associate build SHAs or release tags with errors inbox. Environment variable Configuration setting NEW_RELIC_LICENSE_KEY license_key NEW_RELIC_APP_NAME app_name NEW_RELIC_MONITOR_MODE monitor_mode NEW_RELIC_DEVELOPER_MODE developer_mode NEW_RELIC_LOG log_file NEW_RELIC_LOG_LEVEL log_level NEW_RELIC_HIGH_SECURITY high_security NEW_RELIC_PROXY_SCHEME proxy_scheme NEW_RELIC_PROXY_HOST proxy_host NEW_RELIC_PROXY_PORT proxy_port NEW_RELIC_PROXY_USER proxy_user NEW_RELIC_PROXY_PASS proxy_pass NEW_RELIC_AUDIT_LOG audit_log_file NEW_RELIC_STARTUP_TIMEOUT startup_timeout NEW_RELIC_SHUTDOWN_TIMEOUT shutdown_timeout NEW_RELIC_LABELS labels NEW_RELIC_PROCESS_HOST_DISPLAY_NAME process_host.display_name NEW_RELIC_API_KEY api_key NEW_RELIC_CA_BUNDLE_PATH ca_bundle_path NEW_RELIC_DISTRIBUTED_TRACING_ENABLED distributed_tracing.enabled NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED event_harvest_config.harvest_limits.analytic_event_data NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED event_harvest_config.harvest_limits.custom_event_data NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED event_harvest_config.harvest_limits.span_event_data NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED event_harvest_config.harvest_limits.error_event_data NEW_RELIC_FEATURE_FLAG feature_flag Per-request configuration For certain WSGI servers, you can override the app name and capture attributes settings on a per-request basis. This is possible with WSGI servers where you can define additional key/value pairs that are passed into the per-request WSGI environ dictionary. Set these values with the strings on, off, true, false, 1 and 0. If set from a configuration mechanism implemented using Python code, Python objects evaluating to True or False will also be accepted. Example: Apache/mod_wsgi app name In the Apache/mod_wsgi server, you can use the SetEnv directive to override config settings (optionally inside a Location or Directory block). For example, you could override the app name for a complete virtual host, or for a subset of URLs handled by the WSGI application for that virtual host. In addition to being able to override certain agent configuration settings, you can set other per-request configuration settings with their WSGI environment key: newrelic.set_background_task If set to true, this web transaction will instead be reported as a non-web transaction. newrelic.ignore_transaction If set to true, this web transaction will not be reported. newrelic.suppress_apdex_metric If set to true, no Apdex metric will be generated for this web transaction. newrelic.suppress_transaction_trace If set to true, this web transaction cannot be recorded in a transaction trace. newrelic.disable_browser_autorum If set to true, this disables automatic insertion of the JavaScript header/footer for page load timing (sometimes referred to as real user monitoring or RUM). Only applicable if auto-insertion is available for your web framework. Important Using a WSGI middleware to set these values will not work where the Python agent's own WSGI application wrapper was applied at an outer scope. In these cases you must make calls to the agent API to achieve the same outcome. Multiple environment configuration The agent reads its primary configuration from an agent config section called newrelic. You can provide overrides for specific deployment environments (for example, Development, Staging, Production) in additional sections. Preface these sections with [newrelic:environment], where environment is replaced with the name of your environment. To specify that the agent should use an environment-based configuration, use one of these methods: When you call newrelic.agent.initialize(), provide the environment name as the second argument. OR Set the NEW_RELIC_ENVIRONMENT environment variable to the environment name. If no environment is specified, the agent will use the default settings as specified in the newrelic agent config section. The basic structure of the configuration file is: [newrelic] ... default settings [newrelic:development] ... override settings [newrelic:staging] ... override settings [newrelic:production] ... override settings Copy General configuration settings These settings are available in the agent configuration file. license_key (REQUIRED) Type String Default (none) Set in Config file, environment variable Environ variable NEW_RELIC_LICENSE_KEY Specifies the license key of your New Relic account. This key associates your app's metrics with your New Relic account. app_name (HIGHLY RECOMMENDED) Type String Default Python Application Set in Per-request option, config file, environment variable Per-request option newrelic.app_name Environ variable NEW_RELIC_APP_NAME The application name used to aggregate data in the New Relic One UI. To report data to multiple apps at the same time, specify a list of names separated with a semicolon ;. Do not put a space before the semicolon, which causes the Python config parser to interpret the name as an embedded comment. monitor_mode Type Boolean Default true Set in Config file, environment variable Environ variable NEW_RELIC_MONITOR_MODE When true, the agent collects performance data about your app and reports this data to our data collector. developer_mode Type Boolean Default false Set in Config file, environment variable Environ variable NEW_RELIC_DEVELOPER_MODE When true, the agent will instrument your web app, but will not send any actual data. In this offline mode, you will not be billed for an active agent. Use developer mode to test new versions of the agent, or test the agent against third-party packages in a developer environment. Offline mode is not a way of running the APM locally, because the metrics the agent collects are not reported anywhere. log_file Type String Default (none) Set in Config file, environment variable Environ variable NEW_RELIC_LOG Sets the name of a log file, which is useful for debugging issues with the agent. This is not set by default, since the agent does not know your web app process's parent user or what directories that process has permission to write to. For detailed information, see Python agent logging. Whatever you set this to, ensure the permissions for the containing directory and the file itself are correct, and that the user that your web application runs as can write to the file. Tip Use an absolute path unless you are sure what the working directory of your application will be at startup. If you can't write out a log file, you can also use stderr and output to standard error output. This would normally result in output appearing in your web server log. log_level Type String Default info Set in Config file, environment variable Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages, if you've set the log file location. This log_level will not affect the Python logging module log level. Possible values, in increasing order of detail, are critical, error, warning, info, and debug. To report agent issues, the most useful setting is debug. However, debug generates a lot of information very quickly, so do not keep the agent at this level for longer than it takes to reproduce your problem. high_security Type Boolean Default false Set in Config file, environment variable Environ variable NEW_RELIC_HIGH_SECURITY High security mode enforces certain security settings and prevents them from being overridden, so that no sensitive data is sent to us. Enabling high security mode means that request parameters are not collected, and you cannot send raw SQL. To activate high security mode, set it to true in the local .ini configuration file and activate it in the Account Settings in the UI. For more information, see High security. proxy_scheme, proxy_host, proxy_port, proxy_user, proxy_pass Type Strings Default (none) Set in Config file, environment variable Environ variables NEW_RELIC_PROXY_SCHEME NEW_RELIC_PROXY_HOST NEW_RELIC_PROXY_PORT NEW_RELIC_PROXY_USER NEW_RELIC_PROXY_PASS By default, the Python agent attempts to directly connect to our servers. If there is a firewall between your host and the our collector that requires you to use an HTTP proxy, set proxy_host and proxy_port to the required values for your HTTP proxy. If proxy authentication is implemented by the HTTP proxy, also set proxy_user and proxy_pass. The proxy_scheme setting dictates what protocol scheme is used to talk to the HTTP proxy. When set to http, the agent uses a SSL tunnel through the HTTP proxy for end-to-end encryption. Instead of setting the proxy_scheme, proxy_host and proxy_port settings, you can also set the proxy_host setting to a valid URI for the proxy. Include the scheme, host, and port; for example, http://proxy-host:8000. This also works if you set the details of the HTTP proxy with the NEW_RELIC_PROXY_HOST environment variable. Tip Python agent versions 2.0.0 or earlier do not provide the proxy_scheme setting, and the protocol scheme defaults to http or https depending whether ssl is disabled or enabled. If you are upgrading from an older agent version and your config file doesn't include proxy_scheme, ensure you add the setting and set it appropriately. If you don't, the agent will continue to base the protocol scheme on the ssl setting for backwards compatibility. As proxies are usually only configured to accept proxy requests via the http protocol scheme, not setting proxy_scheme may result in a failure. audit_log_file Type String Default (none) Set in Config file, environment variable Environ variable NEW_RELIC_AUDIT_LOG Sets the name of the audit log file. If set, the agent logs details of messages passed back and forth between the monitored process and the collector. This allows you to evaluate the security of the Python agent. Use an absolute path unless you are sure what your app's working directory will be at startup. Whatever you set this to, ensure the permissions for the containing directory and the file itself are correct. Also ensure your web app's parent user can write to the file. Caution Do not use audit logging on an ongoing basis, especially in a production environment. Because the agent does not truncate or rotate the log file, the log file can grow very quickly. labels (tags) Type String Default (none) Set in Config file, environment variable Environ variable NEW_RELIC_LABELS Adds tags. Specify name:value separated by a colon :, and separate additional tags with semicolons ;. Two tags Server:One;Data Center:Primary Copy process_host.display_name Type String Default (none) Set in Config file, environment variable Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Sets the hostname to be displayed in the APM UI. If set, this overrides the default hostname that the agent captures automatically. api_key Type String Default (none) Set in Config file, environment variable Environ variable NEW_RELIC_API_KEY Sets the api_key to be used with newrelic-admin record-deploy. ca_bundle_path Type String Default (none) Set in Config file, environment variable Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by our data collection service. Tip This configuration option is only available in Python agent versions 4.2.0 and newer. apdex_t Type Float Default 0.5 Set in Config file, environment variable Environ variable NEW_RELIC_APDEX_T We'll record transaction traces when they exceed this threshold. The format is a number of seconds (decimal points allowed). See our glossary entry for apdex_t Attributes Attributes are key-value pairs that provide information for transaction traces, traced errors, browser monitoring, and transaction events. In addition to configuring attributes for all four destinations with the general attribute settings below, they can also be configured on a per-destination basis. For more information, see Python agent attributes, Enabling and disabling attributes, and Attribute examples. attributes.enabled Type Boolean Default true Set in Config file This setting can be used to turn on or off all attributes. attributes.include Type List of Strings Default (none) Set in Config file If attributes are enabled, attribute keys found in this list will be sent to us. Keys in the list should be space-separated as shown below: key1 key2 key3 Copy Rules for attributes can be found on the agent attributes page. attributes.exclude Type List of Strings Default (none) Set in Config file All attribute keys found in this list will not be sent to us. Keys in the list should be space-separated as shown below: key1 key2 key3 Copy Rules for attributes can be found on the agent attributes page. Transaction tracer configuration Important Do not use brackets [suffix] at the end of your transaction name. The agent automatically strips brackets from the name. Instead, use parentheses (suffix) or other symbols if needed. For more information about transaction traces, see Transaction traces. transaction_tracer.enabled Type Boolean Default true Set in Server-side config, config file Server-side label Enable transaction tracing? If enabled, the transaction tracer captures deep information about slow transactions. transaction_tracer.transaction_threshold Type Positive float or string (apdex_f) Default apdex_f Set in Server-side config, config file Server-side label Threshold Threshold in seconds for when to collect a transaction trace. When the response time of a controller action exceeds this threshold, the agent records a transaction trace. Valid values are any positive float, or apdex_f (four times apdex_t). transaction_tracer.record_sql Type String Default obfuscated Set in Server-side config, config file Server-side label Record SQL? When the transaction tracer is enabled, the agent can record SQL statements. The recorder has three modes: off (sends no SQL), raw (sends the SQL statement in its original form), and obfuscated (strips out numeric and string literals). Most web frameworks (including Django) parameterize SQL queries so they do not actually contain the values used to fill out the query. If you use raw mode with one of these frameworks, the Python agent will only see the SQL prior to insertion of values. The parametrized SQL will look much like obfuscated mode. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Set in Server-side config, config file Server-side label Stack trace threshold Threshold in seconds for when to collect stack traces from SQL calls. When SQL statements exceed this threshold, the agent captures the current stack trace. This is helpful for pinpointing where long SQL calls originate in an application. transaction_tracer.explain_enabled Type Boolean Default true Set in Server-side config, config file Server-side label Enable SQL query plans? Determines whether the Python agent will capture query plans for slow SQL queries. Only supported in MySQL and PostgreSQL. transaction_tracer.explain_threshold Type Float Default 0.5 Set in Server-side config, config file Server-side label Query plan threshold Queries in transaction traces that exceed this threshold will report slow query data and any available explain plans. Explain plan collection will not happen if transaction_tracer.explain_enabled is false. transaction_tracer.attributes.enabled Type Boolean Default true Set in Config file This setting can be used to turn on or off all attributes for transaction traces. If attributes.enabled at the root level is false, no attributes will be sent to transaction traces regardless on how this configuration setting (transaction_tracer.attributes.enabled) is set. transaction_tracer.attributes.include Type List of strings Default (none) Set in Config file If attributes are enabled for transaction traces, all attribute keys found in this list will be sent to us in transaction traces. For more information, see the agent attribute rules. transaction_tracer.attributes.exclude Type List of Strings Default (none) Set in Config file All attribute keys found in this list will not be sent in transaction traces. For more information, see the agent attribute rules. transaction_tracer.function_trace Type String Default (none) Set in Config file For the specified functions or methods, the agent will capture additional function timing instrumentation. Specify these names in the form module:function or module:class.function. Wildcarding (globbing) for function and class names is possible using patterns supported by the fnmatch module. Module paths are not supported by wildcards. Specify the patterns in the form module:function* or module:class.*. For example, if you want to add function tracing to all validation functions in the below file: my-app/common/utils.py def validate_credentials(): … def validate_status(): … def format_message(): … Copy Add the following line to the agent config file to include function tracing to all validation functions in my-app/common/utils.py by using wildcarding. my-app/newrelic.ini [newrelic] ... transaction_tracer.function_trace = common.utils:validate* Copy Important Wilcarding requires Python agent version 6.4.4.161 or higher. Transaction segment configuration Here are Transaction segment settings available via the agent configuration file. transaction_segments.attributes.enabled Type Boolean Default true Set in Config file This setting can be used to turn on or off all attributes for segments of transaction traces. If attributes.enabled at the root level is false, no attributes will be sent to segments of transaction traces regardless on how this configuration setting (transaction_segments.attributes.enabled) is set. transaction_segments.attributes.include Type List of strings Default (none) Set in Config file If attributes are enabled for segments of transaction traces, all attribute keys found in this list will be sent in segments of transaction traces. For more information, see the agent attribute rules. transaction_segments.attributes.exclude Type List of Strings Default (none) Set in Config file All attribute keys found in this list will not be sent in segments of transaction traces. For more information, see the agent attribute rules. Error collector configuration Here are error collector settings available via the agent configuration file. Tip For an overview of error configuration in APM, see Manage errors in APM. error_collector.enabled Type Boolean Default true Set in Server-side config, config file Server-side label Enable error collection? If enabled, the error collector captures information about uncaught exceptions. error_collector.ignore_classes Type String Default (none) Set in Server-side config, config file Server-side label Ignore these errors To stop collecting specific errors, set this to a space-separated list of the Python exception type names to ignore. Use the form module:class for the exception name. Tip Before version 6.4.0 of the agent, this setting was named error_collector.ignore_errors. If your configuration file still uses ignore_errors, update your agent to use ignore_classes. error_collector.ignore_status_codes Type String Default 100-102 200-208 226 300-308 404 Set in Server-side config, config file Server-side label Ignore these status codes Lists HTTP status codes which the agent should ignore rather than record as errors. List additional status codes as integers separated by spaces, and specify ranges with a hyphen - separator between the start and end values. To add one of the default codes to your allow list, preface the code with an exclamation point !. This setting is only compatible with some web frameworks, as some frameworks do not use exceptions to return HTTP responses. Tip This configuration option can only be set in server-side configuration in Python agent versions 6.4.0 and newer. error_collector.expected_classes Type String Default (none) Set in Server-side config, config file Server-side label Expect these error class names Prevents specified exception classes from affecting error rate or Apdex score while still reporting the errors to APM. Set this to a space-separated list of the Python exception type names to be expected. Use the form module:class for the exception name. Tip This configuration option is only available in Python agent versions 6.4.0 and newer. error_collector.expected_status_codes Type String Default (none) Set in Server-side config, config file Server-side label Expect these status codes Prevents specified HTTP status codes from affecting error rate or Apdex score while still reporting the errors to APM. List status codes as integers separated by spaces and specify ranges with a hyphen - separator between the start and end values. To negate one of the codes in your list, preface the code with an exclamation point !. This setting is only compatible with some web frameworks, as some frameworks do not use exceptions to return HTTP responses. Tip This configuration option is only available in Python Agent versions 6.4.0 and newer. error_collector.attributes.enabled Type Boolean Default true Set in Config file This setting can be used to turn on or off all attributes for traced errors. If attributes.enabled is false at the root level, then no attributes will be sent to traced errors regardless on how this configuration setting (error_collector.attributes.enabled) is set. error_collector.attributes.include Type List of strings Default (none) Set in Config file If attributes are enabled for traced errors, all attribute keys found in this list will be sent to in traced errors. For more information, see the agent attribute rules. error_collector.attributes.exclude Type List of strings Default (none) Set in Config file Attribute keys found in this list will not be sent to in traced errors. For more information, see the agent attribute rules. error_collector.capture_events Type Boolean Default true Set in Config file If enabled, the error collector captures event data for advanced analytics. For more information, see APM Errors. Browser monitoring settings Here are browser monitoring settings available via the agent configuration file. browser_monitoring.enabled Type Boolean Default true Set in Config file Enables browser monitoring. For more information, see Page load timing in Python. Important Before enabling browser monitoring in the config file, enable it in the application settings in the browser monitoring UI. browser_monitoring.auto_instrument Type Boolean Default true Set in Config file For supported Python web frameworks, this setting enables auto-insertion of the browser monitoring JavaScript fragments. browser_monitoring.content_type Type String Default text/html Set in Config file Specify the HTML Content-Type(s) that our browser monitoring agent should auto-instrument. Add additional entries in a space-separated list. Instrument xhtml+xml page responses If you are generating HTML page responses and using the Content-Type of application/xhtml+xml, you can override the allowed content types to list both this content type and the default text/html by using: browser_monitoring.content_type = text/html application/xhtml+xml Copy Important The browser monitoring JavaScript snippet prevents the page from validating as application/xhtml+xml, although the page should load and render in end-user browsers. browser_monitoring.attributes.enabled Type Boolean Default false Set in Config file This setting can be used to turn on or off all attributes for browser monitoring. This is the data which gets sent to page view events. If attributes.enabled is false at the root level, no attributes will be sent up in browser monitoring regardless on how the configuration setting (browser_monitoring.attributes.enabled) is set. browser_monitoring.attributes.include Type List of Strings Default (none) Set in Config file If attributes are enabled for browser_monitoring, all attribute keys found in this list will be sent in page views. For more information, see the agent attribute rules. browser_monitoring.attributes.exclude Type List of Strings Default (none) Set in Config file All attribute keys found in this list will not be sent in page views. For more information, see the agent attribute rules. Transaction events settings Here are Transaction events settings available via the agent configuration file. Tip These configuration settings used to be called analytic_events. If your configuration file still uses analytic_events, update your agent to use transaction_events. transaction_events.enabled Type Boolean Default true Set in Config file Transaction event data allows the use of additional information such as histograms and percentiles. transaction_events.attributes.enabled Type Boolean Default true Set in Config file This setting can be used to turn on or off all attributes for transaction events. If attributes.enabled is false at the root level, then no attributes will be sent to transaction events regardless on how this configuration setting (transaction_events.attributes.enabled) is set. transaction_events.attributes.include Type List of Strings Default (none) Set in Config file If attributes are enabled for transaction events, all attribute keys found in this list will be sent in transaction events. For more information, see the agent attribute rules. transaction_events.attributes.exclude Type List of Strings Default (none) All attribute keys found in this list will not be sent to in transaction events. Note that excluding attributes from transaction events does not exclude from span events. For more information, see the agent attribute rules. Custom events settings Here are custom events settings available via the agent configuration file. custom_insights_events.enabled Type Boolean Default true Set in Config file Allow recording of events to the Insights custom events API via record_custom_event(). Datastore tracer settings These datastore tracer settings are available via the agent configuration file: datastore_tracer.instance_reporting.enabled Type Boolean Default true Set in Config file When enabled, the agent collects datastore instance metrics (such as host and port) for some database drivers. These are also reported on slow query traces and transaction traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Set in Config file When enabled, the agent collects database name for some database drivers. The database name is reported on slow query traces and transaction traces. Distributed tracing settings Important Starting in Python agent version 7.0.0.166 or higher, distributed tracing is enabled by default. Enabling distributed tracing disables cross application tracing and has other effects on APM features. If migrating from cross application tracing, read the transition guide. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. Settings include: distributed_tracing.enabled Type Boolean Default true Set in Config file, environment variable Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Enables Distributed Tracing Span event configuration Span events are collected for distributed tracing. Distributed tracing must be enabled to report span events. Configuration options include: span_events.enabled Type Boolean Default true Set in Config file This setting can be used to turn on or off whether the Python agent sends spans. span_events.attributes.enabled Type Boolean Default true Set in Config file This setting can be used to turn on or off for all attributes for span events. If attributes.enabled at the root level is false, no attributes will be sent to span events regardless on how this configuration setting (span_events.attributes.enabled) is set. For more information, see the agent attribute rules. span_events.attributes.include Type List of strings Default (none) Set in Config file If attributes are enabled for span events, all attribute keys found in this list will be sent in span events. For more information, see the agent attribute rules. span_events.attributes.exclude Type List of Strings Default (none) Set in Config file All attribute keys found in this list will not be sent in span events. For more information, see the agent attribute rules. Event harvest configuration Event harvest settings limit the amount of event type data sent to New Relic. When you use these settings, consider these important points: Event harvest settings affect the limits for a single instance of the agent, and not across the entire application. See the usage example below for how to set limits across an entire application. Real time streaming sends data every five seconds (12 times per minute), but the event harvest settings still affect the rate in events per minute. Enabling or disabling real time streaming does not require changing these settings. With real time streaming (enabled by default), New Relic will display the event harvest limits for entities in five second intervals. This means, for example, when you set a limit value of 1200 in the config file, you'll see it as 100 in New Relic. Usage example Let's say an application is deployed across 10 hosts, each running four processes per host. To limit the number of span events to 10,000 events per minute for the entire application, divide that number by 10 hosts. Then divide again by four processes per host. 10000 / (10 * 4) = 250 Based on that calculation, the final setting is: event_harvest_config.harvest_limits.span_event_data = 250 Event harvest configuration settings include: event_harvest_config.harvest_limits.analytic_event_data Type Integer Default 1200 Set in Config file Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Limit for analytic events per minute sent by an instance of the Python agent to New Relic. event_harvest_config.harvest_limits.custom_event_data Type Integer Default 1200 Set in Config file Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Limit for custom events per minute sent by an instance of the Python agent to New Relic. Custom events are created through the Python Telemetry SDK. event_harvest_config.harvest_limits.span_event_data Type Integer Default 1000 Set in Config file Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Limit for span events per minute sent by an instance of the Python agent to New Relic. event_harvest_config.harvest_limits.error_event_data Type Integer Default 100 Set in Config file Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Limit for error events per minute sent by an instance of the Python agent to New Relic. Event loop visibility settings Important Requires Python agent version 5.0.0.124 or higher. Event loop visibility surfaces information about transactions that block the event loop. The agent will generate information about transactions that have waited a significant amount of time to acquire control of the event loop. Settings include: event_loop_visibility.enabled Type Boolean Default true Set in Config file Set this to false to disable event loop information. event_loop_visibility.blocking_threshold Type Float Default 0.1 Set in Config file Threshold in seconds for how long a transaction must block the event loop before generating event loop information. Garbage collection runtime metrics settings Important Requires Python agent version 6.2.0.156 or higher. These garbage collection runtime metrics settings are available via the agent configuration file: gc_runtime_metrics.enabled Type Boolean Default false Set in Config file When enabled, the agent will generate and send garbage collection metrics. gc_runtime_metrics.top_object_count_limit Type Integer Default 5 Set in Config file The agent reports object count metrics for the most common object types being collected by the garbage collector. For each object type, this setting allows you to set the maximum number of individual metrics that will be sampled. Other configuration settings Here are assorted other settings available via the agent configuration file. utilization.detect_aws Type Boolean Default true If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true If true, the agent automatically detects that it is running in a Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true If true, the agent automatically detects that it is running in Docker. slow_sql.enabled Type Boolean Default true Set in Server-side config, config file Server-side label Enable Slow SQL? If enabled, the agent captures details from long-running SQL database queries. thread_profiler.enabled Type Boolean Default true Set in Server-side config, config file Server-side label Enable thread profiler? Enables you to schedule thread profiling sessions. The thread profiler will periodically capture a snapshot of the call stack for each active thread in the application to construct a statistically representative call tree. cross_application_tracer.enabled Type Boolean Default false Set in Config file Enables cross application tracing, which connect your apps and services within your service-oriented architecture. strip_exception_messages.enabled Type Boolean Default false Set in Config file If enabled, exception messages will be stripped from error traces before they are sent to the collector, in order to prevent the inadvertent capture of sensitive information. This option is automatically enabled in high security mode. strip_exception_messages.whitelist Type String Default (none) Set in Config file Exceptions listed in your allow list will not have their messages stripped, even if strip_exception_messages.enabled is true. The allow list is a space-separated string of exception types, each in the form of module:exception_name. List built-in exceptions as exception_name; you do not need to prepend module: to them. Example: Built-in exception and user-defined exception KeyError my_module:MyException Copy startup_timeout Type Float Default 0.0 Set in Config file, environment variable Environ variable NEW_RELIC_STARTUP_TIMEOUT By default, the agent starts when it receives the first transaction (either web or non-web). The agent then starts in parallel, ensuring that this initial request is not delayed. However, the agent does not record the details of this initial request because the agent cannot collect data until registration is complete. To override this, you can set a startup timeout in seconds. The agent will then pause the initial transaction and wait for registration to complete. Important Since startup_timeout delays your app start, we recommend only setting a startup timeout for background task queuing systems, not web applications. shutdown_timeout Type Float Default 2.5 Set in Config file, environment variable Environ variable NEW_RELIC_SHUTDOWN_TIMEOUT On process shutdown, the agent attempts one final upload to the collector. To prevent the agent running indefinitely in case of an issue, the process shuts down normally if the shutdown_timeout threshold is reached. This shutdown can result in data loss, but the agent prioritizes key metric data during the upload process. For background task queuing systems, especially those which run a small number of tasks per process, you may want to increase the shutdown timeout to ensure the agent can upload all data on process shutdown. Tip The agent defaults to a 2.5 second timeout because Apache and many other web servers have a 3.0 second process termination timeout. The agent exits at 2.5 seconds to allow atexit cleanup code registered for the process to run. compressed_content_encoding Type String Default gzip Set in Config file If the data compression threshold is reached in the payload, the agent compresses data, using gzip compression by default. The config option compression_content_encoding can be set to deflate to use deflate compression. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Built-in instrumentation The Python agent instruments a range of Python packages/modules. This instrumentation only occurs when the target Python package/module is imported by an application. To disable default instrumentation, provide a special import-hook section corresponding to the name of the module that triggered instrumentation. Then set the enabled setting to false to disable instrumentation of that module. Example: Disabling MySQLdb database query instrumentation Add the following to the configuration file: [import-hook:MySQLdb] enabled = false Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.73117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Error</em> collector configuration",
        "body": ". event_harvest_config.harvest_limits.<em>error</em>_event_data Type Integer Default 100 Set in Config file Environ variable NEW_RELIC_<em>ERROR</em>_COLLECTOR_MAX_EVENT_SAMPLES_STORED <em>Limit</em> for <em>error</em> events per minute sent by an instance of the Python agent to New Relic. Event loop visibility settings Important Requires Python agent version 5.0.0.124 or higher"
      },
      "id": "617dc153196a67cf3df7bf56"
    },
    {
      "image": "https://docs.newrelic.com/static/b437d8747d80db2b7cc2a4ab110a8c70/c1b63/errors-ui.png",
      "url": "https://docs.newrelic.com/docs/errors-inbox/errors-inbox/",
      "sections": [
        "Error tracking with errors inbox",
        "Why it matters",
        "Set up errors inbox",
        "Monitor errors",
        "Error groups",
        "Troubleshooting: similar looking events do not group together",
        "Occurrences",
        "Sort By Filter",
        "Triage errors",
        "Errors status",
        "Error details",
        "Attributes",
        "Activity",
        "Discussions",
        "Assign errors",
        "Important",
        "Connect an inbox to Slack",
        "Connect errors inbox to CodeStream",
        "Connect an inbox to Jira"
      ],
      "published_at": "2022-01-12T05:32:17Z",
      "title": "Error tracking with errors inbox",
      "updated_at": "2022-01-07T01:44:58Z",
      "type": "docs",
      "external_id": "3dbd9bf9bda2abf4f6af60c03dc1f2168dc18f9d",
      "document_type": "page",
      "popularity": 1,
      "body": "Errors inbox is a single place to proactively detect, triage, and take action on all the errors before they impact customers. Receive alerts whenever a critical, customer-impacting error arises via your preferred communication channel, like Slack. Resolve errors faster with errors from across your stack, including all APM, browser (RUM), mobile, and serverless (AWS Lambda) data, displayed on one screen. Errors are grouped to cut down on noise, and collaborating across teams is easy with shared visibility to the same error data. Why it matters Errors inbox provides a unified error tracking experience to detect and triage errors: View and triage issues across applications and services that your team cares about for faster error resolutions. Proactive notifications with detailed error information in Slack. Error profiles to show similarities between error events and surface the root cause by analyzing attributes. Analyze errors in context of the full stack and resolve errors with precision. APM, browser, mobile, and AWS Lambda Functions errors are all captured in the same inbox. Ready to get started? Make sure you have a New Relic account. It's free, forever! Set up errors inbox To enable errors inbox, follow these steps. Afterwards, errors groups should start to appear in your inbox. From one.newrelic.com select Errors inbox from the top nav. If this is your first time accessing errors inbox, you will be prompted to select a workload in the top left. If you have no workloads set up, you will be prompted to create one before you can use errors inbox. Once you select your workload, your inbox should populate with error groups. one.newrelic.com > More > Errors inbox Monitor errors Once you've set up your errors inbox, you can begin proactively monitoring all errors in your stack: Error groups Error groups are sets of events that make up a unique error. Error groups are stored long term and contain metrics, activity log, discussions, and basic information about the unique error. Error groups are tied to the entity, so making a change to the state of an error group in one errors inbox will impact all other inboxes that contain that entity. How error groups work Error events get grouped into an error group when they share the same fingerprint. As events are ingested by New Relic, we run the events through a set of managed rules that output a fingerprint. Every unique fingerprint has a single error group associated with it. The New Relic managed rules normalize the error data, identifying and ignoring unique values such as UUIDs, hex values, email addresses, etc. that would cause grouping “like” errors into unique groups. NR account ID, entity ID, error class, error message, stack trace and exception are all data that can impact a fingerprint. Troubleshooting: similar looking events do not group together If you see “like” error events grouped into different error groups incorrectly, try removing the unique identifier from the error class or message and store those as attributes instead. This will allow you to more easily facet on the attribute values and reduce the number of error groups. If you have a single application reporting as multiple entities in New Relic (i.e. running in different clusters, cells, etc), you might see duplicate error groups, since our grouping logic looks at account and entity IDs as part of the fingerprinting process. You can consider rolling up the multiple entities into a single entity and including only that rolled up entity as part of your errors inbox. You can also use the feedback tool in NR1 to share error groups that could use improved grouping. We’re continually updating our rules to improve the quality of error groups. Occurrences Your errors inbox displays the total number of occurrences of each error group within the selected timeframe. The corresponding sparkline chart displays the total number of occurrences per day over the selected timeframe as you hover over it. Sort By Filter Using the dropdown in the top right, you can sort the list of grouped errors by the number of occurrences or by the error that was last seen (latest first). Triage errors Errors status Errors inbox enables you to triage error groups directly from the main screen or from the error details page. Triaging helps remove the noise from your errors inbox, and lets you focus on the high impact errors that need attention. You can set one of three statuses, and filter your inbox by status. Unresolved: This is the default status of error groups. Resolved: Setting an error as resolved will hide it from the default inbox view unless filters are updated to include resolved errors. If events matching the error group fingerprint occur after marking an error group as resolved, it will automatically reset the status to Unresolved. This can be useful for identifying regressions. Ignored: Ignored will hide the error group from the inbox view unless filters are updated to include ignored errors, or until you stop ignoring the error group. Error details Clicking on a specific error group takes you to the error details page, where you will find full context of the issue. This context can assist in triaging the error and assigning it to the correct team or individual. Occurrences The Occurrences tab includes details like: Related account Stack trace Logs in context Error attributes Number and frequency of occurrences The detailed view also allows you to view specific errors. In the top right, you can navigate between the first instance of the error, the last, and any instance in-between. Attributes The Attributes tab enables you to quickly find commonalities between the related errors for faster resolution. Click on a specific attribute to open a sidebar with specific details. Activity The Activity tab displays a log of the status changes and user assignments of an error group. Discussions The Discussions tab provides room for detailed and organized collaboration. This is key to looping in collaborators and ensuring the entire team has the same context regardless of where they sit. Discussions includes: Threaded conversations: Reply directly to top level comments to tie replies to specific posts. Comment deletion: Delete comments. The content of the post will be removed unless it is the parent of a thread, in which case the box will remain with the message “Comment deleted by user.” Markdown support: Add styling and links to your comments in Markdown. Assign errors You can assign an error group to anyone. Simply select the user from the assign dropdown menu. You may also assign an error to any email address, even if they aren’t a New Relic user. You can update the filter in errors inbox to show only errors assigned to yourself, or a teammate. Important Currently assigning an error group to a user does not send a notification. Notifications of assignment and changes to error groups will be coming soon. Connect an inbox to Slack When connected to Slack, new and resurfaced error groups will be sent to a Slack channel within seconds of them occurring. This enables your team to quickly identify any new errors or regressions, and resolve them quickly with direct links to the stack trace. This short video shows how it works (1:24 minutes): To connect an inbox to Slack: If your Slack workspace does not have the New Relic app installed, do that first. From an inbox, select the Inbox Settings icon (looks like a gear) in the top right corner. Toggle the Slack button to on if it is off. If no workspaces are available, click the plus button to enable Slack with a one click Slack authentication. Once authenticated, you will be able to select a Workspace and specific Channel to send notifications to. Click Test to ensure messages are being sent to the right channel. Connect errors inbox to CodeStream To use CodeStream's Open in IDE integration with your APM stack trace errors, use environment variables to configure your APM agent with your application's commit sha and/or your release tag associated with the running version of your software. Once set up, you can jump from an error group directly to the offending code in your IDE by clicking the Open in IDE button. Learn more here. Connect an inbox to Jira Connect errors inbox to Jira to easily create tickets for your errors, allowing for faster collaboration and resolution. Jira templates allow you to quickly create a ticket containing error details and links directly to the stack trace and APM for quick access and resolution. We store a link to the the ticket alongside the associated error group for a period of time. If the error occurs again within that period, you can easily access associated tickets. Important New Relic currently supports Atlassian-Jira Classic (company-managed) projects. To connect an inbox to Jira: Click on the Jira integration icon on the far right side of the error group you want to connect to Jira. Clicking the Jira integration icon allows you to create a ticket based on a template, or create a template if you don't already have one. If you don’t already have a connection to Jira set up in your account, click Add JIRA Workspace from the dropdown. Fill in all the fields and click Test connection before saving to ensure that your details are correct. Next, set up a template. Templates determine what information will be sent to Jira. Find more information about specific fields here. Errors inbox does not currently support two-way communication with Jira, but you can select this option in case it is supported in the future. Once you have a template, click Send test notification to preview what the ticket looks like in Jira. If the preview looks good, click Update message to save the template. Note that a test notification will create a Jira ticket in your Jira workspace. Now your team can create Jira tickets by clicking the Jira integration icon on the far right side of the error group and selecting a template. Jira settings are associated with the account that owns the error group or entity. If you are using the cross-account errors inbox, you will need to set up a Jira connection multiple times.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 89.45966,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Error</em> tracking with <em>errors</em> <em>inbox</em>",
        "sections": "<em>Error</em> tracking with <em>errors</em> <em>inbox</em>",
        "body": "Errors <em>inbox</em> is a single place to proactively detect, triage, and take action on all the errors before they impact customers. Receive alerts whenever a critical, customer-impacting <em>error</em> arises via your preferred communication channel, like Slack. Resolve errors faster with errors from across your"
      },
      "id": "6174112928ccbc230ac6a4be"
    }
  ],
  "/docs/errors-inbox/errors-inbox": [
    {
      "image": "https://docs.newrelic.com/static/45de34e3a56f26f44cbd62f69d1bb8b6/ae694/error.png",
      "url": "https://docs.newrelic.com/whats-new/2021/06/errors-inbox/",
      "sections": [
        "Errors Inbox: Error tracking across your entire stack"
      ],
      "published_at": "2022-01-12T11:16:25Z",
      "title": "Errors Inbox: Error tracking across your entire stack",
      "updated_at": "2021-06-25T12:10:39Z",
      "type": "docs",
      "external_id": "9ee9b292d1ae812a2b6cff8dbf6f0a2b19a9caa0",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Recently, we launched New Relic Errors Inbox, an error tracking solution that provides you a single place to view, triage and resolve errors across your full application stack. This exciting feature now includes Logs in Context and an integration with Slack. Read more about the latest updates in our blog post and watch a demo in the latest Nerdlog episode here. What’s Included with New Relic Errors Inbox: Errors Inbox. Errors are grouped and displayed on a single screen for visibility and easy triaging. Filter to just the applications and services that you care about. Rich Error Details. Resolve errors faster with context of the full stack, including APM, Browser (RUM), Mobile, and Serverless (AWS Lambda Function) data. Error data persists to provide continued context for recurring errors. Log Data. Logs in Context are provided alongside other error data right in the error group details for even more information to resolve errors faster. Cross Team Collaboration. Work errors as a team with shared error visibility, shared comments, and an integration with Slack. Next Steps New Relic Errors Inbox is available to all New Relic Full-Stack Observability customers in the U.S. datacenter. To enable Errors Inbox, sign up for a free account or log in to your existing account and follow these steps: From one.newrelic.com, select More in the top right and click Errors Inbox. If this is your first time accessing Errors Inbox, you will be prompted to select a workload in the top left.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.41803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Errors</em> <em>Inbox</em>: <em>Error</em> <em>tracking</em> across your entire stack",
        "sections": "<em>Errors</em> <em>Inbox</em>: <em>Error</em> <em>tracking</em> across your entire stack",
        "body": "Recently, we launched New Relic <em>Errors</em> <em>Inbox</em>, an <em>error</em> <em>tracking</em> solution that provides you a single place to view, triage and resolve <em>errors</em> across your full application stack. This exciting feature now includes Logs in Context and an integration with Slack. Read more about the latest updates"
      },
      "id": "60d5c7bfe7b9d208f1d67792"
    },
    {
      "image": "https://docs.newrelic.com/static/cb27400c917f08f6d6fafbc09337440e/432e7/ErrorOnNR1.png",
      "url": "https://docs.newrelic.com/docs/codestream/how-use-codestream/performance-monitoring/",
      "sections": [
        "Performance monitoring with CodeStream",
        "Discover errors on New Relic One",
        "Discover errors via CodeStream",
        "Error details",
        "Collaborate with CodeStream",
        "Use build SHAs or release tags with CodeStream",
        "Other collaboration tools",
        "Associate your repository"
      ],
      "published_at": "2022-01-12T05:42:10Z",
      "title": "Performance monitoring with CodeStream",
      "updated_at": "2022-01-05T01:37:53Z",
      "type": "docs",
      "external_id": "378ad1d91c35b3c33347ee3cf91afb28620b45f7",
      "document_type": "page",
      "popularity": 1,
      "body": "It’s important to know how your code is performing in production and whether or not it’s generating errors. To help you with this, New Relic CodeStream brings performance monitoring right into your IDE. Discover errors on New Relic One Once you’ve connected CodeStream to your New Relic One account, and you've created one or more workloads with errors inbox on New Relic One, use Open in IDE to see APM errors with stack traces directly in your IDE. When you've connected CodeStream to your New Relic One account, in errors inbox click Open in IDE to see the code that caused the error. Once connected, all of your collaboration work in CodeStream (such as the discussion, assignee, and error status) syncs with New Relic One, where you can continue to collaborate. A typical collaboration session could include developers commenting on code in their IDEs, a DevOps engineer assigning errors in errors inbox, and a development manager following along in Slack. By meeting people in the tools they're already using, New Relic CodeStream shortens the amount of time between error discovery and error resolution. Discover errors via CodeStream In addition to errors inbox, discover errors in your IDE in the CodeStream observability section. In addition to recent errors in your repos, see any specific errors assigned to you. Use CodeStream's observability section to keep up to date with recent and assigned stack trace errors. Error details No matter how you've arrived at an error in your IDE, CodeStream presents all of the error’s details, including the stack trace, and you can collaborate with your teammates to resolve the error. Navigate the stack trace to investigate the issue. Click any frame in the stack trace to jump straight to the corresponding file and line number in your IDE. As you navigate the stack trace, if you come across code that seems like the source of your problem, select it and click the comment icon to start collaborating. Collaborate with CodeStream With CodeStream open, once you've identified the problematic code, select it in your editor and click the comment icon that appears next to it in the CodeStream pane. CodeStream automatically mentions the most recent person to touch the code related to the error, making it easy for you to bring the right people into the discussion. Select code in your editor to add a comment. Assign the error and update its status for better tracking an accountability. Once you’ve identified the problem you can assign the error, either to an existing teammate on CodeStream or to a person suggested based on the repository’s Git commit history. You can update the error’s status from unresolved to resolved or ignored. Use build SHAs or release tags with CodeStream You may see this warning if there's no git reference, either a build SHA or release tag, associated with a specific error. CodeStream uses the git reference to match the specific stack trace error with the version of the code running in the environment that triggered the error. The git reference not configured warning message reads: Assocaite a build SHA or release tag with your errors so that CodeStream can help make sure you're looking at the right version of the code. To configure a git reference set the environment variables for your APM agent. Even without the git reference configured, you can still investigate the error, but you may not be looking at the version of the code that caused it. The git reference not found warning message reads: Your version of the code doesn't match the environment that triggered the error. Fetch the following reference to better investigate the error. If you do have git references configured, but the version of the code you're on locally doesn't contain that reference, CodeStream will let you know so that you can more effectively investigate and resolve the error. CodeStream will also let you know if the error doesn’t have a stack trace associated with it. This happens with older errors when the stack trace has aged out on New Relic One. Other collaboration tools In an error discussion, use the ... More actions dropdown to share the discussion on Slack or Microsoft Teams. Associate your repository If there's no repository associated with CodeStream when you click Open in IDE on an error, CodeStream prompts you to do so. All of the repositories you currently have open in your IDE are listed in the select a repo dropdown. If you don’t see the repository you want listed, open it in your IDE and it will automatically get added to the list. If you’re working with a fork, make sure you select the upstream remote. To avoid having to do this manual association every time you open an error, you can make these associations via your APM agent's environment variables.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.84528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Performance monitoring <em>with</em> CodeStream",
        "sections": "Discover <em>errors</em> on New Relic One",
        "body": ", and you&#x27;ve created one or more workloads with <em>errors</em> <em>inbox</em> on New Relic One, use Open in IDE to see APM <em>errors</em> with stack traces directly in your IDE. When you&#x27;ve connected CodeStream to your New Relic One account, in <em>errors</em> <em>inbox</em> click Open in IDE to see the code that caused the <em>error</em>. Once"
      },
      "id": "617cbd54e7b9d28f12c0535e"
    },
    {
      "sections": [
        "Introduction to notifications",
        "Early access",
        "Destinations",
        "Message templates"
      ],
      "title": "Introduction to notifications",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Notifications",
        "Workflows",
        "Error Inbox"
      ],
      "external_id": "f623ca3e096307c13e6e9214cc2fa6908707d101",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/intro-notifications/",
      "published_at": "2022-01-12T08:12:33Z",
      "updated_at": "2021-11-25T00:02:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Notifications are a consolidation of the different ways to send notification-events to third-party services, such as Slack, Jira, ServiceNow, and email. You can also use webhooks to send your data to any compatible third-party service. Integrate with your systems by configuring destinations and message templates. Destinations Destinations are unique identifiers and connection details for third-party systems. Use destinations to integrate, send notifications and share data between New Relic and your third-party systems. Message templates Configure the eventual notification events and map New Relic One data to your third-party services using message-templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.36443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Error</em> <em>Inbox</em>"
      },
      "id": "6190270f64441f165fe9d12b"
    }
  ],
  "/docs/gateway-api-import-data-other-observability-platforms": [
    {
      "sections": [
        "Introduction to automated user management and single-sign on (SSO)",
        "Benefits",
        "Requirements and recommendations",
        "Set up automated user management"
      ],
      "title": "Introduction to automated user management and single-sign on (SSO)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "831a5f1137eccac9540d716302645b4e976a6332",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign/",
      "published_at": "2022-01-12T01:50:24Z",
      "updated_at": "2022-01-08T03:42:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you set up automated user management (AUM), which allows you to import, update, and deactivate your New Relic users from an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started with SAML SSO and SCIM. Benefits of enabling automated user management include: Time and cost efficiency: When you make changes in your identity provider, such as creating, updating, and removing users, these changes are automatically reflected in New Relic. By being able to manage a large set of users from your identity provider, it reduces the workload of your admins who'd otherwise need to do a significant amount of work in New Relic to accomplish the same thing. Increased productivity: By having a more automatic way to set up users and groups, they're enabled and ready to use New Relic more quickly. Enhanced security: SCIM is an industry standard protocol for maintaining groups of users. Use of this feature requires SAML SSO, so once your users are added to New Relic, they can log in using your identity provider. Popular identity providers Azure AD, Okta, and OneLogin have dedicated New Relic apps, improving ease of enablement. Requirements and recommendations Requirements and recommendations: Requires Pro or Enterprise edition. Supports SAML 2.0 standard for single sign on (SSO). Supports SCIM 2.0 standard. User model-related requirements: This feature requires you to be on our New Relic One user model and creates users on that model. If you're on our original user model (or otherwise can't seem to implement this feature), talk to your New Relic account representative. Configuration requires that a user have the Authentication domain manager and the Organization manager role (users in the default group Admin have these). There are three identity providers that have a New Relic app: Azure AD, Okta, and OneLogin. For other identity providers, you can use our SCIM API. Before enabling this, it helps to first set up user groups in your identity provider service and think about which New Relic roles and accounts those groups will have access to. Set up automated user management For an explanation of how your identity provider groups map over to New Relic groups, see Group and role mapping. To use automated user management to import users from your identity provider: It's important to first review the requirements. In the authentication domain UI, create a new authentication domain. If you use Azure AD, Okta, or OneLogin, use the applicable guide: Azure AD | Okta | OneLogin. If you don't use one of the above services, you'll need to: Use the authentication domain UI to enable SCIM as the source of users. Use our SCIM API to integrate with your identity provider service. See the SCIM API tutorial for all the steps involved. Highly recommended: Set a time zone for your users in your identity provider. How you do this will vary by identity provider. If not set in your identity provider, our UI shows UTC time zone dates/times. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (for example, \"America/Los_Angeles\"). If you have issues, contact your account representative. After being provisioned, your users can click on the New Relic SCIM/SSO application tile in their identity provider to be logged into New Relic. To learn more about New Relic's roles and capabilities, see Standard roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 99.38789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "New Relic lets you set up automated user management (AUM), which allows you to <em>import</em>, update, and deactivate your New Relic users <em>from</em> an identity provider, like Azure AD, Okta, or OneLogin. Benefits Before reading the benefits of automated user management, we recommend reading Get started"
      },
      "id": "6043d60e64441ff8f5378f37"
    },
    {
      "sections": [
        "Amazon API Gateway monitoring integration",
        "Features",
        "Requirements",
        "Tip",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Inventory data",
        "Dimensions"
      ],
      "title": "Amazon API Gateway monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "dbeb75bde2ffb29fe6c7eb41b536fa477c2b80ab",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration/",
      "published_at": "2022-01-12T03:46:48Z",
      "updated_at": "2021-10-23T16:39:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon API Gateway data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features Amazon's API Gateway is a fully managed service that allows you to create, publish, maintain, monitor, and secure APIs at any scale. With the New Relic API Gateway integration, you get more data about how your API layer is working behind the scenes. You'll receive metric data about the number of API calls, the requests served, the number of errors, latency counts, and more. You can monitor and alert on your API Gateway data directly from New Relic, and query data and create dashboards. Requirements API Gateway will not send \"Call count by resource\", \"4xx error by resource\" and \"5xx errors by resource\" metrics unless you have explicitly enabled detailed CloudWatch metrics. Tip Enabling these metrics may add additional charges to your Amazon CloudWatch account pricing. To enable CloudWatch metrics, use either of these options: Go to the AWS Management Console, select the Settings option for CloudWatch, then select the option to enable detailed CloudWatch metrics. Call the stage:update action of the Amazon API Gateway REST API to update the metricsEnabled property to true. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon API gateway integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the API Gateway integration links. You can query and explore your data using the ApiGatewaySample event type. For more on how to use your data, see Understand and use integration data. Metric data This New Relic infrastructure integration collects the following Amazon API Gateway data: Metric Description 4XXError The number of client-side errors captured 5XXError The number of server-side errors captured. CacheHitCount The number of requests served from the API cache. CacheMissCount The number of requests served from the back end when API caching is enabled. Count The number of calls to API methods. IntegrationLatency The time in milliseconds between when API Gateway relays a request to the back end and when it receives a response from the back end. Latency The time in milliseconds between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Inventory data Inventory data provides information about the service's state and configuration. API Gateway configuration options are reported as inventory data. For more about inventory data, see Understand and use data. Object Inventory data /aws/apigateway/api apiId apiName awsRegion /aws/apigateway/resource awsRegion methods resource resourceid /aws/apigateway/stage apiName awsRegion cacheClusterEnable cacheClusterSize cacheClusterStatus lastUpdatedDate stageName /aws/apigateway/stage/variables value /aws/apigateway/stage/settings CacheDataEncrypted CacheTtlInSeconds CachingEnabled DataTraceEnabled LoginLevel MetricsEnabled RequireAuthorizationForCacheControl UnauthorizedCacheControlHeaderStrategy ThrottlingBurstLimit ThrottlingRateLimit /aws/apigateway/stage/resource-with-metrics apiName awsRegion method resource stageName Dimensions You can use the dimensions in the following table to filter API Gateway metrics. Dimensions Description ApiName Filters API Gateway metrics for an API of the specified API name. ApiName, Method, Resource, Stage Filters API Gateway metrics for an API method of the specified API, stage, resource, and method. ApiName, Stage Filters API Gateway metrics for an API stage of the specified API and stage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.07982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Amazon <em>API</em> <em>Gateway</em> monitoring integration",
        "sections": "Amazon <em>API</em> <em>Gateway</em> monitoring integration",
        "body": ", and more. You can monitor and alert on your <em>API</em> <em>Gateway</em> <em>data</em> directly <em>from</em> New Relic, and query <em>data</em> and create dashboards. Requirements <em>API</em> <em>Gateway</em> will not send &quot;Call count by resource&quot;, &quot;4xx error by resource&quot; and &quot;5xx errors by resource&quot; metrics unless you have explicitly enabled detailed CloudWatch"
      },
      "id": "617db3a028ccbc92a1801133"
    },
    {
      "sections": [
        "Set up network syslog monitoring",
        "Prerequisites",
        "New Relic One account prerequisites",
        "Linux host prerequisites",
        "Network syslog devices prerequisites",
        "Network security prerequisites",
        "Tip",
        "Set up network syslog monitoring in New Relic One"
      ],
      "title": "Set up network syslog monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Network Performance Monitoring",
        "Installation",
        "Setup",
        "NPM"
      ],
      "external_id": "835cdb37ea4a0497669a79a24ee5fa8904d05ec6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/network-performance-monitoring/setup-performance-monitoring/network-syslog-monitoring/",
      "published_at": "2022-01-12T07:52:53Z",
      "updated_at": "2022-01-08T02:04:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Set up your network devices so they send syslog data to New Relic One. Prerequisites New Relic One account prerequisites A New Relic account. Don't have one? Sign up for free! No credit card required. A New Relic account ID. Learn how to find your account ID. A New Relic license key. Learn how to generate a new License key. Linux host prerequisites Docker installed in a Linux host. SSH access to the Docker host, with the ability to launch new containers. Network syslog devices prerequisites Configured network devices to send syslog to the host running the ktranslate docker container. Here's how to configure network syslog data collection in some devices: Checkpoint - Security Gateway. You must sign in to the User Center/PartnerMAP checkpoint. Cisco - ASA Cisco - IOS Cisco - Meraki Cisco - NX-OS F5 - BIG-IP Fortinet Fortigate Juniper - Junos Palo Alto - PAN-OS Network security prerequisites Direction Source Destination Ports Protocol Outbound Docker host ktranslate image on Docker Hub 443 TCP Outbound Docker host New Relic Log API endpoint: US Endpoint: https://log-api.newrelic.com Copy EU Endpoint: https://log-api.eu.newrelic.com Copy 443 TCP Inbound Source devices for syslog data Docker host 5143 (default) UDP Tip The default listening port for ktranslate is 5143 (TCP/UDP). If you need to use the default syslog port of 514 (or any other port), you can do so by providing a new listening endpoint during Docker runtime. For example: -syslog=\"0.0.0.0:514\". Set up network syslog monitoring in New Relic One From a Linux host with Docker installed, download the ktranslate image from dockerhub by running bash Copy $ docker pull kentik/ktranslate:v2 Copy the snmp-base.yaml file to the local $HOME directory of your Docker user, and discard the container by running bash Copy $ cd . $ id=$(docker create kentik/ktranslate:v2) $ docker cp $id:/etc/ktranslate/snmp-base.yaml . $ docker rm -v $id In the snmp-base.yaml file, add your network syslog devices inside the devices key with the following structure: devices: syslogDevice: device_name: edge-router device_ip: 10.10.1.254 ping_only: true # Optional user tags user_tags: owning_team: net_eng environment: production Copy Tip If you're already monitoring SNMP data devices that send network syslog, you don't need to add them in your snmp-base.yaml file a second time. The ping_only attribute used in the configuration file can optionally be replaced with flow_only to remove response time monitoring and only collect syslog messages from the host. Run ktranslate to listen for network syslog by running: bash Copy $ docker run -d --name ktranslate-syslog --restart unless-stopped --net=host \\ > -v `pwd`/snmp-base.yaml:/snmp-base.yaml \\ > -e NEW_RELIC_API_KEY=$YOUR_NR_LICENSE_KEY \\ > kentik/ktranslate:v2 \\ > -snmp /snmp-base.yaml \\ > -nr_account_id=$YOUR_NR_ACCOUNT_ID \\ > ## If your account is located in Europe, add the following option: $ ## -nr_region=EU \\ $ -metrics=jchf \\ > -tee_logs=true \\ > -service_name=syslog \\ > ## Optional: To override the default listening port of \"0.0.0.0:5143\": $ ## -syslog=\"<ip_address>:<port>\" $ nr1.syslog Tip ktranslate handles syslog in the following formats: RFC3164, RFC5424, and RFC6587. Investigate your device syslog messages in the New Relic One logs UI, using the following query: \"plugin.type\":\"ktranslate-syslog\" Copy To get better visibility into your network device performance, set up SNMP data monitoring. To get better visibility into how your network is being used, set up network flow data monitoring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 86.5998,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "&#x27;s how to configure network syslog <em>data</em> collection in some devices: Checkpoint - Security <em>Gateway</em>. You must sign in to the User Center&#x2F;PartnerMAP checkpoint. Cisco - ASA Cisco - IOS Cisco - Meraki Cisco - NX-OS F5 - BIG-IP Fortinet Fortigate Juniper - Junos Palo Alto - PAN-OS Network security"
      },
      "id": "619e0cec64441f61ed985635"
    }
  ],
  "/docs/glossary/glossary": [
    {
      "sections": [
        "Introduction to New Relic",
        "Get started with New Relic",
        "All the answers in one place",
        "Bring all your data together",
        "Analyze your data",
        "Respond to incidents faster",
        "Troubleshoot from anywhere in your stack"
      ],
      "title": "Introduction to New Relic",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "f47a40a9afd699e69c351f5e87f64ed5dadd7e43",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/intro-new-relic/",
      "published_at": "2022-01-12T18:27:10Z",
      "updated_at": "2022-01-12T18:27:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is an observability platform that helps you build better software. You can bring in data from any digital source so that you can fully understand your system and how to improve it. This short video shows twenty of the most common ways to get your data into New Relic (approx. 5:22 minutes): With New Relic, you can: Bring all your data together: Instrument everything and import data from across your technology stack using our agents, integrations, and APIs, and access it from a single UI. Analyze your data: Get all your data at your fingertips to find the root causes of problems and optimize your systems. Build dashboards and charts or use our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. Get started with New Relic Here's how you can quickly get started capturing and analyzing your data: If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever! Follow the steps in our Add your data UI page to get data flowing in. For your first install, we recommend the Guided install option, which will set up many integrations with a single command. Once you have data coming into New Relic, learn more about the New Relic UI or set up Alerts. All the answers in one place New Relic is built for full stack observability. It links all relevant data so that you get the whole picture of everything that enables your systems to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Monitoring vs. observability: New Relic provides answers to essential questions in one place. As just one example of what you can do with New Relic, imagine you are a Kubernetes administrator overseeing many clusters and pods of software containers. Where do you start troubleshooting? This short video shows how you can locate a problem cluster and use distributed tracing to find relevant logs: Bring all your data together Capture, organize, and make sense of your data in New Relic One, no matter where it comes from. Use our agents and integrations to automatically collect data from common frameworks and tools, or use our APIs for data that’s more specific to your business or technology. If you don't see your technologies or tasks listed here, see a larger list at New Relic Instant Observability. There you will find integrations bundled into quickstarts, providing you instant access to pre-built dashboards and alerts specific to your technology. If you want to... New Relic can help you... Instrument your application Instrument your code: Use our APM agents to automatically instrument your applications in C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Track transactions: Gather distributed tracing details as your transactions cross boundaries between apps and services. Instrument your environment Instrument your infrastructure: Observe your entire environment (including Linux, Windows, AWS, Azure, Google Cloud Platform, Kubernetes, Docker, and more). Collect and centralize logs: See your log data in context with your other application and infrastructure data. Save time switching between tools and reach solutions more quickly. Instrument your digital experiences Enhance browser performance: Decrease page load times, as well as triage and eliminate errors. Monitor mobile apps: Troubleshoot crashes and check the health of your Android and iOS apps with our mobile agents. Simulate user activity: Ensure you’re meeting customer expectations by running automated checks to monitor key user flows and experiences. Send data via APIs or build your own solution Collect data without an agent: Call our APIs directly if you prefer to use OpenTelemetry or other agents. Build your own integration: You can use our Flex tool, or one of language-specific SDKs for creating your own exporters to send data to New Relic. New Relic One gives you access to a wide range of observability tools, including: Application monitoring Browser monitoring Mobile monitoring Synthetic monitoring Serverless monitoring Infrastructure monitoring Log management You can start anywhere, but you'll never get lost. True observability across your entire stack means that you're in control. Analyze your data With your data secure at New Relic, our platform can alert you to problems and help you organize, process, and understand your data, whether it's metrics, events, logs, or traces: Explore your data visually: Jump into our data explorer to navigate all your data and make connections between your entities without any knowledge of query languages. Query and visualize your data: Use our curated dashboard visualizations or create your own. Use NRQL (New Relic Query Language) to slice and dice your data and dig deeper into questions. Query your data programmatically: Access your data through our NerdGraph GraphQL API. Easily prototype queries in our GraphiQL editor. Respond to incidents faster DevOps, site-reliability, and network operation teams need reliable, real-time alerts and anomaly detection to ensure their systems are always up and running efficiently. Let Applied Intelligence, our hybrid machine learning engine, automatically detect anomalies, reduce alert noise, and enrich incidents with context so that you can respond faster to incidents. Proactive detection: Be notified of unusual app behavior and get an analysis of this unusual behavior sent to Slack. Not using Slack? Set up a webhook to deliver messages when you need them. Get notifications: Set up alerts across your data sources and get notified when systems need your attention. Preserve your attention and control how many threshold violations should fire before you're notified. Troubleshoot from anywhere in your stack Being fully connected, the New Relic UI allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but they can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 357.78134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction <em>to</em> <em>New</em> <em>Relic</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " and optimize your systems. Build dashboards and charts or <em>use</em> our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. <em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em> Here&#x27;s how you can quickly <em>get</em> <em>started</em>"
      },
      "id": "619d5b3e196a6705bda0837d"
    },
    {
      "sections": [
        "Choose your data center (US or EU)",
        "Requirements",
        "Regions and availability",
        "Regions and account hierarchy",
        "Hierarchy example for partnership accounts",
        "Create an EU region account",
        "API endpoints for EU region accounts",
        "Access New Relic One",
        "Billing and pricing",
        "Operational access and processing",
        "Verify your account is based in EU region"
      ],
      "title": "Choose your data center (US or EU)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "58aede83cf1625a8a52aaeed540cebfbaa024d61",
      "image": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/choose-your-data-center/images/Eu_account_hierarchy.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/choose-your-data-center/",
      "published_at": "2022-01-12T08:14:28Z",
      "updated_at": "2021-12-14T04:22:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's global data hosting structure consists of two regions: the European Union (EU) region and the United States (US) region. Selecting your preferred region during the account setup process allows you to specify the region where your performance monitoring data will be hosted. You can also create accounts in each region. Requirements Access to the New Relic EU region requires the latest agent version. For new customers: Install the most recent agent version. For existing customers: Update to the most recent agent version. Minimum agent version required: C SDK 1.0.0 or higher Go 2.0.0 or higher Java 4.0.0 or higher .NET 8.0.0 or higher Node.js 3.0.0 or higher PHP 8.0.0.204 or higher Python 3.0.0.89 or higher Ruby 5.0.0.342 or higher Regions and availability Your choice of data center is not limited by your geographic location. You can choose to create an account with data hosted in either the EU or US region, regardless of where you or your systems reside. You can also create accounts in each region. New Relic offers almost all the same active products, features, support offerings, and performance levels in the EU region as what is offered in the US region. Exceptions: The following are not supported with an EU region account: Infinite Tracing is not available. APM's weekly performance reports are not available. Errors inbox is not available. Log patterns Deprecated products and features are not available. New Relic's Incident Intelligence service operates solely in the US whether you store your data in New Relic’s US region data center or New Relic’s EU region data center, by using New Relic Incident Intelligence, you consent that New Relic may move and store your data in the US region. New Relic CodeStream operates solely in the US. Whether you have selected New Relic's US or EU region data center during setup of your New Relic account, when using New Relic CodeStream, you consent that your New Relic CodeStream data will get stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted in the US region, you must create a new account to store data in the EU region. You cannot view EU data from a US account, or US data from an EU account. The data collected remains separate. The data cannot be aggregated or migrated between accounts. For organizations that have a parent/child account structure, you can only have one parent account. For more, see Manage apps or users with child accounts. For partnership accounts, no changes to the partnership owner account are required. However, data cannot be shared across regions, so a partnership requires a parent account for each region. Hierarchy example for partnership accounts With partnership accounts, a new parent account must be created for any data to be host in the EU region. This hierarchy illustrates how global accounts are structured with partnership owner accounts. Data is not aggregated beyond the parent account. Example hierarchy for partnership organizations. Because data cannot be shared across regions, a partnership will require a parent account for each region. Create an EU region account To create a New Relic account in the EU region: Go to the New Relic signup page. OR If you have a specific offer from a New Relic partner, follow that link directly. Follow the online steps to create your account. From the Select your region dropdown, select European Union. Agree to the Terms of Service. When you receive an email confirmation message, select the link to confirm your account and sign in to New Relic. Then install or update to the most recent agent version. API endpoints for EU region accounts If you have an EU region account, use the appropriate endpoints to access the following New Relic APIs: API EU endpoint Browser source maps API sourcemaps.service. eu .newrelic.com Copy Infrastructure Alert API infra-api. eu .newrelic.com Copy Dashboard API rpm. eu .newrelic.com/api/explore/dashboards/list Copy Insert API insights-collector. eu01 .nr-data.net Copy Insights Query API insights-api. eu .newrelic.com Copy Mobile apps rpm. eu .newrelic.com/mobile Copy NerdGraph GraphiQL API api. eu .newrelic.com/graphiql Copy Partner API The partner API is a global API with no regional data differences. Use this endpoint for both EU and US accounts: rpm.newrelic.com/api/v2/partners/ Copy REST API api. eu .newrelic.com Copy Synthetics API synthetics. eu .newrelic.com/synthetics/api Copy Trace API trace-api. eu .newrelic.com/trace/v1 Copy Metric API metric-api. eu .newrelic.com/metric/v1 Copy Log API log-api. eu .newrelic.com/log/v1 Copy Access New Relic One If your accounts report data to the EU data center, use the following link to go to New Relic One: one.eu.newrelic.com. Billing and pricing New Relic's account billing process and pricing options are the same for both the EU and US regions. Operational access and processing Customer Data is hosted in the region selected during account creation. Systems Operations Data is stored in the US region. All other information, including account information (such as license subscription information, billing, and internal monitoring) is hosted in the US region and replicated in the EU region. New Relic may access and process Customer Data in the United States and such other jurisdictions where New Relic has affiliates and subsidiaries, including as may be necessary to maintain, secure, or perform the services, to provide technical support, or as necessary to comply with law or a binding order of a government body. Customer Data from existing New Relic accounts cannot be transferred or shared across regions, and new data generated cannot be shared with existing accounts, even in partnership accounts. Verify your account is based in EU region Use either of these options to verify whether your account data is hosted in the EU region's data center: In APM, mouse over the application name to view the URL. If it begins with rpm.eu.newrelic.com/, it is an EU-based account. Check your New Relic license key. If it begins with EU, it is an EU-based account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.99779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Access <em>New</em> <em>Relic</em> One",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " <em>New</em> <em>Relic</em>&#x27;s US or EU region data center during setup of your <em>New</em> <em>Relic</em> account, when <em>using</em> <em>New</em> <em>Relic</em> CodeStream, you consent that your <em>New</em> <em>Relic</em> CodeStream data will <em>get</em> stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted"
      },
      "id": "61b81bf6e7b9d2a96fef4e3a"
    },
    {
      "sections": [
        "Find help and use the Support portal",
        "Ask in New Relic's Explorers Hub, our free forum",
        "Run the New Relic Diagnostics tool",
        "Find answers in New Relic Docs and New Relic University",
        "Contribute to our documentation",
        "Don't find what you need? File a documentation issue",
        "File a ticket in the support portal",
        "Important",
        "Check the status of our systems",
        "Licenses and security information"
      ],
      "title": "Find help and use the Support portal",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "ce14a732f0aae92aa495e61aac701f6880378a3d",
      "image": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/find-help-use-support-portal/images/new-relic-explorers-hub.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/find-help-use-support-portal/",
      "published_at": "2022-01-12T08:55:05Z",
      "updated_at": "2021-12-14T04:10:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of support options, including online help, a troubleshooting tool, open source documentation with detailed procedures and troubleshooting tips, and support assistance. Ask in New Relic's Explorers Hub. Run the New Relic Diagnostics tool. Find answers in New Relic Docs and New Relic University. Contribute to our documentation. Don't find what you need? File a documentation issue. File a ticket in the support portal. Check the status of our systems. Read about our licenses, data security, and compliance information. Ask in New Relic's Explorers Hub, our free forum New Relic's Explorer Hub is our forum that's free for all users. New Relic users and employees engage every day in conversations to troubleshoot and solve issues, find workarounds, and discuss new features. discuss.newrelic.com: The Explorer Hub is our public forum. Use it to ask questions and find answers. Join our community of users to learn more about New Relic and get some inspiration. Run the New Relic Diagnostics tool New Relic Diagnostics is our automated diagnostic tool for Linux, Windows, and Mac. If it detects a problem with any of our agents, it suggests solutions and saves troubleshooting logs that you can attach to tickets. Find answers in New Relic Docs and New Relic University New Relic's docs site contains helpful installation, configuration, and troubleshooting tips. From the main page, select from frequently-used categories and topics, like release notes. Or, search from any page. For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. Contribute to our documentation Our documentation is open source and available in GitHub, and we encourage you to contribute! We really care about ensuring our docs are helpful, complete, and accurate. To edit a page, click the Edit page button in any document to create a pull request with the edit you think is needed. We don't want you to worry about style. When you edit a file, tech writers on our team review it for style, grammar, and formatting. docs.newrelic.com: At the right-hand side of each page you'll find a feedback widget. Use it to tell us whether a page is helpful, create an issue, or edit the page. Don't find what you need? File a documentation issue If you can't find an answer in the documentation, you can file an issue to ask us for help. When you find places the docs could be better, let us know too! To do it, click the Create issue button in any document and we'll look into your problem to find a solution. docs.newrelic.com: At the right-hand side of each page you'll find a feedback widget. Use it to tell us whether a page is helpful, create an issue, or edit the page. File a ticket in the support portal If none of the above methods worked, go to support.newrelic.com. The Support portal gives you access to unified search across all of New Relic's help resources. If you can't find what you are looking for and your subscription level includes technical support, you can file a support ticket. Important Support for beta or limited release features may not be available. To file a new ticket: Go to support.newrelic.com > Login. From the Support portal, select the area of New Relic where you need help. Select your account. Provide as many details as possible. Include the URL, if applicable, or select Attach file to include a log file, a New Relic Diagnostics file, screenshots, or other useful attachments. Click Submit. Check the status of our systems It's always a good idea to visit status.newrelic.com to check the status of our systems. If there are open incidents, you'll be able to find more information. Licenses and security information Review New Relic's licenses, attributions, and other notices. Read about our data security, privacy, and compliance policies.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.9885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find help and <em>use</em> the Support portal",
        "sections": "Ask in <em>New</em> <em>Relic&#x27;s</em> Explorers Hub, our free forum",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " <em>Relic</em>&#x27;s Explorer Hub is our forum that&#x27;s free for all users. <em>New</em> <em>Relic</em> users and employees engage every day in conversations to troubleshoot and solve issues, find workarounds, and discuss <em>new</em> features. discuss.newrelic.com: The Explorer Hub is our public forum. <em>Use</em> it to ask questions and find"
      },
      "id": "603eb6b5e7b9d299072a07e5"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-cognito-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-sqs-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-transit-gateway-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-albnlb-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.8733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37564,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.8733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37564,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37564,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-athena-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37564,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-auto-scaling-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudfront-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2022-01-12T13:06:14Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.14565,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-connect-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87321,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37561,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-direct-connect-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87321,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37561,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-documentdb-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.8732,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37561,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-dynamodb-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.8732,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37561,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ebs-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37561,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37561,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2022-01-12T13:06:14Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.14565,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-efs-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elastic-beanstalk-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elasticache-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elb-classic-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87311,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elemental-mediaconvert-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87311,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elemental-mediapackage-vod-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.8731,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-emr-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.8731,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-fsx-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87308,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-glue-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87308,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-iam-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-iot-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-analytics-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-firehose-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-streams-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-managed-kafka-msk-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87299,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87299,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2022-01-12T13:06:14Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.14561,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-mq-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-neptune-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-qldb-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87294,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-rds-enhanced-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87294,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-rds-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-redshift-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-route-53-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.8729,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-route53-resolver-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.8729,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.8729,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-simple-email-service-ses-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87288,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-sns-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87288,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-step-functions-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87285,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-trusted-advisor-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87285,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-vpc-flow-logs-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.87283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-waf-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.8728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37549,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-x-ray-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2022-01-12T02:26:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.8728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2022-01-12T02:29:03Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.37549,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/rate-limit-alerts-amazon": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2022-01-12T02:31:56Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.629395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2022-01-12T04:33:51Z",
      "updated_at": "2022-01-12T04:33:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the infrastructure agent and waited a few minutes, but no data appears in the infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Query builder, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.991234,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Verify install for yum (<em>Amazon</em> Linux, CentOS, or RHEL)",
        "tags": "Infrastructure monitoring <em>troubleshooting</em>",
        "body": " the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see <em>troubleshooting</em> procedures for: APM data missing from infrastructure monitoring <em>Amazon</em>&#x2F;AWS <em>integrations</em> On-host <em>integrations</em>"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "3e2a8516fb6173784f4bb0d1dad6672255030d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2022-01-12T11:29:37Z",
      "updated_at": "2022-01-12T11:29:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.9781,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing Infrastructure <em>integration</em> data",
        "sections": "<em>Troubleshoot</em> <em>integration</em> requirements",
        "tags": "Create <em>integrations</em>",
        "body": "Problem You created a custom infrastructure on-host integration using the <em>Integrations</em> SDK, but you&#x27;re not seeing data in the infrastructure UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic Infrastructure&#x27;s integration requirements. After ruling out"
      },
      "id": "617db89228ccbc29ac7fe921"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/aws-integrations-metrics": [
    {
      "sections": [
        "Understand and use data from infrastructure integrations",
        "Explore your infrastructure integration's data",
        "Create alert conditions"
      ],
      "title": "Understand and use data from infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "74fbfa8de2ee02bdf8dd4aad22fab7f654e96904",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/understand-use-data-infrastructure-integrations/",
      "published_at": "2022-01-12T04:31:28Z",
      "updated_at": "2022-01-12T04:31:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With our infrastructure integrations, you can monitor the performance of many popular services. Our infrastructure integrations are separated into two main categories: Cloud integrations: Integrations for cloud platform services, including AWS, Azure, and GCP. On-host integrations: \"On-host\" refers to core services integrations that you can install directly on a host. Examples: MySQL, NGINX, Kubernetes, Redis. Here are some tips on how to find, understand, and use data reported from infrastructure integrations. Explore your infrastructure integration's data The best way to understand infrastructure integrations's data and see what you can do with it is to enable an integration and explore the data in the New Relic UI. Some recommendations for exploring: View dashboards: You can find your dashboards in New Relic One. For details, see Integration dashboards. Query data: You can run custom queries and charts of your integration data. For more information, see Query New Relic data. Create alert conditions: See Alert conditions. Learn more about what metrics and inventory data an integration reports: See an integration's documentation: cloud integrations and on-host integrations. Create alert conditions To create an alert condition for integration data in infrastructure, Go to one.newrelic.com > Infrastructure, choose an integration, and then select an available alert option. For more information, see Infrastructure and alerts. You can also create alert conditions using NRQL queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.14828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and use data from infrastructure <em>integrations</em>",
        "sections": "Understand and use data from infrastructure <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "With our infrastructure <em>integrations</em>, you can monitor the performance of many popular services. Our infrastructure <em>integrations</em> are separated into two main categories: Cloud <em>integrations</em>: <em>Integrations</em> for cloud platform services, including AWS, Azure, and GCP. On-host <em>integrations</em>: &quot;On-host&quot; refers"
      },
      "id": "617dc61d28ccbcceb080096e"
    },
    {
      "sections": [
        "Get started with New Relic observability",
        "Get your data into New Relic with our quickstarts",
        "Some technical detail",
        "Guided install for New Relic",
        "All the answers in one place"
      ],
      "title": "Get started with New Relic observability",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started"
      ],
      "external_id": "30f87d5f702f926efec49b59591679fa93627ad5",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability-2.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability/",
      "published_at": "2022-01-12T18:26:43Z",
      "updated_at": "2022-01-12T18:26:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "True observability is the power of knowing what's happening across your digital system and why it's happening—at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Our platform goes beyond simple monitoring by offering you observability: data insights to help you make proactive and predictive improvements to your environment. A comparison between simple monitoring and observability. Get your data into New Relic with our quickstarts New Relic I/O is a rich catalog of open-source quickstarts that automatically include integrations, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of tools. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edits to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide in GitHub. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process. Guided install for New Relic Alternatively, if you're comfortable with the command line, our guided install discovers the applications, infrastructure, and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. If your account reports data through our EU data center, click EU Guided install. Guided install EU Guided install All the answers in one place Once your data is in New Relic, we give you a UI with tools to cut through the layers of complexity surrounding your systems. This is all in one platform so you don't need to switch between diagnostic applications. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. All our observability tools are interconnected and accessible in New Relic One. Data reported to New Relic can be categorized as metrics, events, logs, and traces. This data feeds our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Our out-of-the-box observability UI experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find useful signals.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.60876,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic observability",
        "sections": "<em>Get</em> <em>started</em> with New Relic observability",
        "tags": "<em>Get</em> <em>started</em>",
        "body": ". <em>Get</em> your data into New Relic with our quickstarts New Relic I&#x2F;O is a rich catalog of open-source quickstarts that automatically include <em>integrations</em>, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while"
      },
      "id": "61743c6764441f60375fd317"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2022-01-12T02:20:41Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.48204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic": [
    {
      "sections": [
        "Understand and use data from infrastructure integrations",
        "Explore your infrastructure integration's data",
        "Create alert conditions"
      ],
      "title": "Understand and use data from infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "74fbfa8de2ee02bdf8dd4aad22fab7f654e96904",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/understand-use-data-infrastructure-integrations/",
      "published_at": "2022-01-12T04:31:28Z",
      "updated_at": "2022-01-12T04:31:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With our infrastructure integrations, you can monitor the performance of many popular services. Our infrastructure integrations are separated into two main categories: Cloud integrations: Integrations for cloud platform services, including AWS, Azure, and GCP. On-host integrations: \"On-host\" refers to core services integrations that you can install directly on a host. Examples: MySQL, NGINX, Kubernetes, Redis. Here are some tips on how to find, understand, and use data reported from infrastructure integrations. Explore your infrastructure integration's data The best way to understand infrastructure integrations's data and see what you can do with it is to enable an integration and explore the data in the New Relic UI. Some recommendations for exploring: View dashboards: You can find your dashboards in New Relic One. For details, see Integration dashboards. Query data: You can run custom queries and charts of your integration data. For more information, see Query New Relic data. Create alert conditions: See Alert conditions. Learn more about what metrics and inventory data an integration reports: See an integration's documentation: cloud integrations and on-host integrations. Create alert conditions To create an alert condition for integration data in infrastructure, Go to one.newrelic.com > Infrastructure, choose an integration, and then select an available alert option. For more information, see Infrastructure and alerts. You can also create alert conditions using NRQL queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.14816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and use data from infrastructure <em>integrations</em>",
        "sections": "Understand and use data from infrastructure <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "With our infrastructure <em>integrations</em>, you can monitor the performance of many popular services. Our infrastructure <em>integrations</em> are separated into two main categories: Cloud <em>integrations</em>: <em>Integrations</em> for cloud platform services, including AWS, Azure, and GCP. On-host <em>integrations</em>: &quot;On-host&quot; refers"
      },
      "id": "617dc61d28ccbcceb080096e"
    },
    {
      "sections": [
        "Get started with New Relic observability",
        "Get your data into New Relic with our quickstarts",
        "Some technical detail",
        "Guided install for New Relic",
        "All the answers in one place"
      ],
      "title": "Get started with New Relic observability",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started"
      ],
      "external_id": "30f87d5f702f926efec49b59591679fa93627ad5",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability-2.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability/",
      "published_at": "2022-01-12T18:26:43Z",
      "updated_at": "2022-01-12T18:26:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "True observability is the power of knowing what's happening across your digital system and why it's happening—at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Our platform goes beyond simple monitoring by offering you observability: data insights to help you make proactive and predictive improvements to your environment. A comparison between simple monitoring and observability. Get your data into New Relic with our quickstarts New Relic I/O is a rich catalog of open-source quickstarts that automatically include integrations, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of tools. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edits to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide in GitHub. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process. Guided install for New Relic Alternatively, if you're comfortable with the command line, our guided install discovers the applications, infrastructure, and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. If your account reports data through our EU data center, click EU Guided install. Guided install EU Guided install All the answers in one place Once your data is in New Relic, we give you a UI with tools to cut through the layers of complexity surrounding your systems. This is all in one platform so you don't need to switch between diagnostic applications. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. All our observability tools are interconnected and accessible in New Relic One. Data reported to New Relic can be categorized as metrics, events, logs, and traces. This data feeds our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Our out-of-the-box observability UI experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find useful signals.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.60864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic observability",
        "sections": "<em>Get</em> <em>started</em> with New Relic observability",
        "tags": "<em>Get</em> <em>started</em>",
        "body": ". <em>Get</em> your data into New Relic with our quickstarts New Relic I&#x2F;O is a rich catalog of open-source quickstarts that automatically include <em>integrations</em>, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while"
      },
      "id": "61743c6764441f60375fd317"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2022-01-12T02:20:41Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.48204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring": [
    {
      "sections": [
        "Understand and use data from infrastructure integrations",
        "Explore your infrastructure integration's data",
        "Create alert conditions"
      ],
      "title": "Understand and use data from infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "74fbfa8de2ee02bdf8dd4aad22fab7f654e96904",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/understand-use-data-infrastructure-integrations/",
      "published_at": "2022-01-12T04:31:28Z",
      "updated_at": "2022-01-12T04:31:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With our infrastructure integrations, you can monitor the performance of many popular services. Our infrastructure integrations are separated into two main categories: Cloud integrations: Integrations for cloud platform services, including AWS, Azure, and GCP. On-host integrations: \"On-host\" refers to core services integrations that you can install directly on a host. Examples: MySQL, NGINX, Kubernetes, Redis. Here are some tips on how to find, understand, and use data reported from infrastructure integrations. Explore your infrastructure integration's data The best way to understand infrastructure integrations's data and see what you can do with it is to enable an integration and explore the data in the New Relic UI. Some recommendations for exploring: View dashboards: You can find your dashboards in New Relic One. For details, see Integration dashboards. Query data: You can run custom queries and charts of your integration data. For more information, see Query New Relic data. Create alert conditions: See Alert conditions. Learn more about what metrics and inventory data an integration reports: See an integration's documentation: cloud integrations and on-host integrations. Create alert conditions To create an alert condition for integration data in infrastructure, Go to one.newrelic.com > Infrastructure, choose an integration, and then select an available alert option. For more information, see Infrastructure and alerts. You can also create alert conditions using NRQL queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.14816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and use data from infrastructure <em>integrations</em>",
        "sections": "Understand and use data from infrastructure <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "With our infrastructure <em>integrations</em>, you can monitor the performance of many popular services. Our infrastructure <em>integrations</em> are separated into two main categories: Cloud <em>integrations</em>: <em>Integrations</em> for cloud platform services, including AWS, Azure, and GCP. On-host <em>integrations</em>: &quot;On-host&quot; refers"
      },
      "id": "617dc61d28ccbcceb080096e"
    },
    {
      "sections": [
        "Get started with New Relic observability",
        "Get your data into New Relic with our quickstarts",
        "Some technical detail",
        "Guided install for New Relic",
        "All the answers in one place"
      ],
      "title": "Get started with New Relic observability",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started"
      ],
      "external_id": "30f87d5f702f926efec49b59591679fa93627ad5",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability-2.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability/",
      "published_at": "2022-01-12T18:26:43Z",
      "updated_at": "2022-01-12T18:26:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "True observability is the power of knowing what's happening across your digital system and why it's happening—at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Our platform goes beyond simple monitoring by offering you observability: data insights to help you make proactive and predictive improvements to your environment. A comparison between simple monitoring and observability. Get your data into New Relic with our quickstarts New Relic I/O is a rich catalog of open-source quickstarts that automatically include integrations, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of tools. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edits to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide in GitHub. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process. Guided install for New Relic Alternatively, if you're comfortable with the command line, our guided install discovers the applications, infrastructure, and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. If your account reports data through our EU data center, click EU Guided install. Guided install EU Guided install All the answers in one place Once your data is in New Relic, we give you a UI with tools to cut through the layers of complexity surrounding your systems. This is all in one platform so you don't need to switch between diagnostic applications. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. All our observability tools are interconnected and accessible in New Relic One. Data reported to New Relic can be categorized as metrics, events, logs, and traces. This data feeds our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Our out-of-the-box observability UI experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find useful signals.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.60864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic observability",
        "sections": "<em>Get</em> <em>started</em> with New Relic observability",
        "tags": "<em>Get</em> <em>started</em>",
        "body": ". <em>Get</em> your data into New Relic with our quickstarts New Relic I&#x2F;O is a rich catalog of open-source quickstarts that automatically include <em>integrations</em>, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while"
      },
      "id": "61743c6764441f60375fd317"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2022-01-12T02:20:41Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.48204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/integrations-managed-policies": [
    {
      "sections": [
        "Understand and use data from infrastructure integrations",
        "Explore your infrastructure integration's data",
        "Create alert conditions"
      ],
      "title": "Understand and use data from infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "74fbfa8de2ee02bdf8dd4aad22fab7f654e96904",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/understand-use-data-infrastructure-integrations/",
      "published_at": "2022-01-12T04:31:28Z",
      "updated_at": "2022-01-12T04:31:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With our infrastructure integrations, you can monitor the performance of many popular services. Our infrastructure integrations are separated into two main categories: Cloud integrations: Integrations for cloud platform services, including AWS, Azure, and GCP. On-host integrations: \"On-host\" refers to core services integrations that you can install directly on a host. Examples: MySQL, NGINX, Kubernetes, Redis. Here are some tips on how to find, understand, and use data reported from infrastructure integrations. Explore your infrastructure integration's data The best way to understand infrastructure integrations's data and see what you can do with it is to enable an integration and explore the data in the New Relic UI. Some recommendations for exploring: View dashboards: You can find your dashboards in New Relic One. For details, see Integration dashboards. Query data: You can run custom queries and charts of your integration data. For more information, see Query New Relic data. Create alert conditions: See Alert conditions. Learn more about what metrics and inventory data an integration reports: See an integration's documentation: cloud integrations and on-host integrations. Create alert conditions To create an alert condition for integration data in infrastructure, Go to one.newrelic.com > Infrastructure, choose an integration, and then select an available alert option. For more information, see Infrastructure and alerts. You can also create alert conditions using NRQL queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.14804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and use data from infrastructure <em>integrations</em>",
        "sections": "Understand and use data from infrastructure <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "With our infrastructure <em>integrations</em>, you can monitor the performance of many popular services. Our infrastructure <em>integrations</em> are separated into two main categories: Cloud <em>integrations</em>: <em>Integrations</em> for cloud platform services, including AWS, Azure, and GCP. On-host <em>integrations</em>: &quot;On-host&quot; refers"
      },
      "id": "617dc61d28ccbcceb080096e"
    },
    {
      "sections": [
        "Get started with New Relic observability",
        "Get your data into New Relic with our quickstarts",
        "Some technical detail",
        "Guided install for New Relic",
        "All the answers in one place"
      ],
      "title": "Get started with New Relic observability",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started"
      ],
      "external_id": "30f87d5f702f926efec49b59591679fa93627ad5",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability-2.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability/",
      "published_at": "2022-01-12T18:26:43Z",
      "updated_at": "2022-01-12T18:26:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "True observability is the power of knowing what's happening across your digital system and why it's happening—at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Our platform goes beyond simple monitoring by offering you observability: data insights to help you make proactive and predictive improvements to your environment. A comparison between simple monitoring and observability. Get your data into New Relic with our quickstarts New Relic I/O is a rich catalog of open-source quickstarts that automatically include integrations, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of tools. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edits to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide in GitHub. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process. Guided install for New Relic Alternatively, if you're comfortable with the command line, our guided install discovers the applications, infrastructure, and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. If your account reports data through our EU data center, click EU Guided install. Guided install EU Guided install All the answers in one place Once your data is in New Relic, we give you a UI with tools to cut through the layers of complexity surrounding your systems. This is all in one platform so you don't need to switch between diagnostic applications. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. All our observability tools are interconnected and accessible in New Relic One. Data reported to New Relic can be categorized as metrics, events, logs, and traces. This data feeds our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Our out-of-the-box observability UI experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find useful signals.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.60849,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic observability",
        "sections": "<em>Get</em> <em>started</em> with New Relic observability",
        "tags": "<em>Get</em> <em>started</em>",
        "body": ". <em>Get</em> your data into New Relic with our quickstarts New Relic I&#x2F;O is a rich catalog of open-source quickstarts that automatically include <em>integrations</em>, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while"
      },
      "id": "61743c6764441f60375fd317"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2022-01-12T02:20:41Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.48203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations": [
    {
      "sections": [
        "Understand and use data from infrastructure integrations",
        "Explore your infrastructure integration's data",
        "Create alert conditions"
      ],
      "title": "Understand and use data from infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "74fbfa8de2ee02bdf8dd4aad22fab7f654e96904",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/understand-use-data-infrastructure-integrations/",
      "published_at": "2022-01-12T04:31:28Z",
      "updated_at": "2022-01-12T04:31:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With our infrastructure integrations, you can monitor the performance of many popular services. Our infrastructure integrations are separated into two main categories: Cloud integrations: Integrations for cloud platform services, including AWS, Azure, and GCP. On-host integrations: \"On-host\" refers to core services integrations that you can install directly on a host. Examples: MySQL, NGINX, Kubernetes, Redis. Here are some tips on how to find, understand, and use data reported from infrastructure integrations. Explore your infrastructure integration's data The best way to understand infrastructure integrations's data and see what you can do with it is to enable an integration and explore the data in the New Relic UI. Some recommendations for exploring: View dashboards: You can find your dashboards in New Relic One. For details, see Integration dashboards. Query data: You can run custom queries and charts of your integration data. For more information, see Query New Relic data. Create alert conditions: See Alert conditions. Learn more about what metrics and inventory data an integration reports: See an integration's documentation: cloud integrations and on-host integrations. Create alert conditions To create an alert condition for integration data in infrastructure, Go to one.newrelic.com > Infrastructure, choose an integration, and then select an available alert option. For more information, see Infrastructure and alerts. You can also create alert conditions using NRQL queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.14804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and use data from infrastructure <em>integrations</em>",
        "sections": "Understand and use data from infrastructure <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "With our infrastructure <em>integrations</em>, you can monitor the performance of many popular services. Our infrastructure <em>integrations</em> are separated into two main categories: Cloud <em>integrations</em>: <em>Integrations</em> for cloud platform services, including AWS, Azure, and GCP. On-host <em>integrations</em>: &quot;On-host&quot; refers"
      },
      "id": "617dc61d28ccbcceb080096e"
    },
    {
      "sections": [
        "Get started with New Relic observability",
        "Get your data into New Relic with our quickstarts",
        "Some technical detail",
        "Guided install for New Relic",
        "All the answers in one place"
      ],
      "title": "Get started with New Relic observability",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started"
      ],
      "external_id": "30f87d5f702f926efec49b59591679fa93627ad5",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability-2.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability/",
      "published_at": "2022-01-12T18:26:43Z",
      "updated_at": "2022-01-12T18:26:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "True observability is the power of knowing what's happening across your digital system and why it's happening—at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Our platform goes beyond simple monitoring by offering you observability: data insights to help you make proactive and predictive improvements to your environment. A comparison between simple monitoring and observability. Get your data into New Relic with our quickstarts New Relic I/O is a rich catalog of open-source quickstarts that automatically include integrations, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of tools. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edits to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide in GitHub. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process. Guided install for New Relic Alternatively, if you're comfortable with the command line, our guided install discovers the applications, infrastructure, and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. If your account reports data through our EU data center, click EU Guided install. Guided install EU Guided install All the answers in one place Once your data is in New Relic, we give you a UI with tools to cut through the layers of complexity surrounding your systems. This is all in one platform so you don't need to switch between diagnostic applications. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. All our observability tools are interconnected and accessible in New Relic One. Data reported to New Relic can be categorized as metrics, events, logs, and traces. This data feeds our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Our out-of-the-box observability UI experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find useful signals.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.60849,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic observability",
        "sections": "<em>Get</em> <em>started</em> with New Relic observability",
        "tags": "<em>Get</em> <em>started</em>",
        "body": ". <em>Get</em> your data into New Relic with our quickstarts New Relic I&#x2F;O is a rich catalog of open-source quickstarts that automatically include <em>integrations</em>, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while"
      },
      "id": "61743c6764441f60375fd317"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2022-01-12T02:20:41Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.17192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/polling-intervals-aws-integrations": [
    {
      "sections": [
        "Understand and use data from infrastructure integrations",
        "Explore your infrastructure integration's data",
        "Create alert conditions"
      ],
      "title": "Understand and use data from infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "74fbfa8de2ee02bdf8dd4aad22fab7f654e96904",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-integrations/get-started/understand-use-data-infrastructure-integrations/",
      "published_at": "2022-01-12T04:31:28Z",
      "updated_at": "2022-01-12T04:31:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With our infrastructure integrations, you can monitor the performance of many popular services. Our infrastructure integrations are separated into two main categories: Cloud integrations: Integrations for cloud platform services, including AWS, Azure, and GCP. On-host integrations: \"On-host\" refers to core services integrations that you can install directly on a host. Examples: MySQL, NGINX, Kubernetes, Redis. Here are some tips on how to find, understand, and use data reported from infrastructure integrations. Explore your infrastructure integration's data The best way to understand infrastructure integrations's data and see what you can do with it is to enable an integration and explore the data in the New Relic UI. Some recommendations for exploring: View dashboards: You can find your dashboards in New Relic One. For details, see Integration dashboards. Query data: You can run custom queries and charts of your integration data. For more information, see Query New Relic data. Create alert conditions: See Alert conditions. Learn more about what metrics and inventory data an integration reports: See an integration's documentation: cloud integrations and on-host integrations. Create alert conditions To create an alert condition for integration data in infrastructure, Go to one.newrelic.com > Infrastructure, choose an integration, and then select an available alert option. For more information, see Infrastructure and alerts. You can also create alert conditions using NRQL queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.14804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and use data from infrastructure <em>integrations</em>",
        "sections": "Understand and use data from infrastructure <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "With our infrastructure <em>integrations</em>, you can monitor the performance of many popular services. Our infrastructure <em>integrations</em> are separated into two main categories: Cloud <em>integrations</em>: <em>Integrations</em> for cloud platform services, including AWS, Azure, and GCP. On-host <em>integrations</em>: &quot;On-host&quot; refers"
      },
      "id": "617dc61d28ccbcceb080096e"
    },
    {
      "sections": [
        "Get started with New Relic observability",
        "Get your data into New Relic with our quickstarts",
        "Some technical detail",
        "Guided install for New Relic",
        "All the answers in one place"
      ],
      "title": "Get started with New Relic observability",
      "type": "docs",
      "tags": [
        "Observe everything",
        "Get started"
      ],
      "external_id": "30f87d5f702f926efec49b59591679fa93627ad5",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability-2.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/get-started-full-stack-observability/",
      "published_at": "2022-01-12T18:26:43Z",
      "updated_at": "2022-01-12T18:26:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "True observability is the power of knowing what's happening across your digital system and why it's happening—at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Our platform goes beyond simple monitoring by offering you observability: data insights to help you make proactive and predictive improvements to your environment. A comparison between simple monitoring and observability. Get your data into New Relic with our quickstarts New Relic I/O is a rich catalog of open-source quickstarts that automatically include integrations, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while others contain a mixture of tools. Each quickstart is created by observability experts around the world, vetted by New Relic, and ready for you to install with one click. Leverage community expertise and get more value out of your telemetry data with New Relic I/O, your hub for instant observability. Ready to get started? Find your quickstart in New Relic I/O: New Relic I/O New Relic I/O is open source, which means that you can modify and improve existing quickstarts, or build new ones, to suit your needs. We thoroughly review external edits to our quickstarts for value and quality. Interested in contributing to the community? Check out our contributor guide in GitHub. Some technical detail New Relic quickstarts use open source installation recipes to instrument integrations using our guided install process. Guided install for New Relic Alternatively, if you're comfortable with the command line, our guided install discovers the applications, infrastructure, and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. If your account reports data through our EU data center, click EU Guided install. Guided install EU Guided install All the answers in one place Once your data is in New Relic, we give you a UI with tools to cut through the layers of complexity surrounding your systems. This is all in one platform so you don't need to switch between diagnostic applications. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. All our observability tools are interconnected and accessible in New Relic One. Data reported to New Relic can be categorized as metrics, events, logs, and traces. This data feeds our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Our out-of-the-box observability UI experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find useful signals.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.60849,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with New Relic observability",
        "sections": "<em>Get</em> <em>started</em> with New Relic observability",
        "tags": "<em>Get</em> <em>started</em>",
        "body": ". <em>Get</em> your data into New Relic with our quickstarts New Relic I&#x2F;O is a rich catalog of open-source quickstarts that automatically include <em>integrations</em>, dashboards, and alerts for you to use immediately. Popular technologies such as Node.js, Python, and Ruby have full-featured quickstarts, while"
      },
      "id": "61743c6764441f60375fd317"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2022-01-12T02:20:41Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.48203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2022-01-12T02:31:56Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.629364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2022-01-12T04:33:51Z",
      "updated_at": "2022-01-12T04:33:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the infrastructure agent and waited a few minutes, but no data appears in the infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Query builder, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.990974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Verify install for yum (<em>Amazon</em> Linux, CentOS, or RHEL)",
        "tags": "Infrastructure monitoring <em>troubleshooting</em>",
        "body": " the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see <em>troubleshooting</em> procedures for: APM data missing from infrastructure monitoring <em>Amazon</em>&#x2F;AWS <em>integrations</em> On-host <em>integrations</em>"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "3e2a8516fb6173784f4bb0d1dad6672255030d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2022-01-12T11:29:37Z",
      "updated_at": "2022-01-12T11:29:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.977844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing Infrastructure <em>integration</em> data",
        "sections": "<em>Troubleshoot</em> <em>integration</em> requirements",
        "tags": "Create <em>integrations</em>",
        "body": "Problem You created a custom infrastructure on-host integration using the <em>Integrations</em> SDK, but you&#x27;re not seeing data in the infrastructure UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic Infrastructure&#x27;s integration requirements. After ruling out"
      },
      "id": "617db89228ccbc29ac7fe921"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2022-01-12T02:31:56Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.629364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2022-01-12T04:33:51Z",
      "updated_at": "2022-01-12T04:33:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the infrastructure agent and waited a few minutes, but no data appears in the infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Query builder, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.990974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Verify install for yum (<em>Amazon</em> Linux, CentOS, or RHEL)",
        "tags": "Infrastructure monitoring <em>troubleshooting</em>",
        "body": " the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see <em>troubleshooting</em> procedures for: APM data missing from infrastructure monitoring <em>Amazon</em>&#x2F;AWS <em>integrations</em> On-host <em>integrations</em>"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "3e2a8516fb6173784f4bb0d1dad6672255030d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2022-01-12T11:29:37Z",
      "updated_at": "2022-01-12T11:29:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.977844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing Infrastructure <em>integration</em> data",
        "sections": "<em>Troubleshoot</em> <em>integration</em> requirements",
        "tags": "Create <em>integrations</em>",
        "body": "Problem You created a custom infrastructure on-host integration using the <em>Integrations</em> SDK, but you&#x27;re not seeing data in the infrastructure UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic Infrastructure&#x27;s integration requirements. After ruling out"
      },
      "id": "617db89228ccbc29ac7fe921"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/cannot-create-alert-condition-infrastructure-integration": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2022-01-12T02:31:56Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.629364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2022-01-12T04:33:51Z",
      "updated_at": "2022-01-12T04:33:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the infrastructure agent and waited a few minutes, but no data appears in the infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Query builder, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.99089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Verify install for yum (<em>Amazon</em> Linux, CentOS, or RHEL)",
        "tags": "Infrastructure monitoring <em>troubleshooting</em>",
        "body": " the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see <em>troubleshooting</em> procedures for: APM data missing from infrastructure monitoring <em>Amazon</em>&#x2F;AWS <em>integrations</em> On-host <em>integrations</em>"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "3e2a8516fb6173784f4bb0d1dad6672255030d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2022-01-12T11:29:37Z",
      "updated_at": "2022-01-12T11:29:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.97775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing Infrastructure <em>integration</em> data",
        "sections": "<em>Troubleshoot</em> <em>integration</em> requirements",
        "tags": "Create <em>integrations</em>",
        "body": "Problem You created a custom infrastructure on-host integration using the <em>Integrations</em> SDK, but you&#x27;re not seeing data in the infrastructure UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic Infrastructure&#x27;s integration requirements. After ruling out"
      },
      "id": "617db89228ccbc29ac7fe921"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2022-01-12T02:31:56Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.629364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2022-01-12T04:33:51Z",
      "updated_at": "2022-01-12T04:33:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the infrastructure agent and waited a few minutes, but no data appears in the infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Query builder, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.99089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Verify install for yum (<em>Amazon</em> Linux, CentOS, or RHEL)",
        "tags": "Infrastructure monitoring <em>troubleshooting</em>",
        "body": " the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see <em>troubleshooting</em> procedures for: APM data missing from infrastructure monitoring <em>Amazon</em>&#x2F;AWS <em>integrations</em> On-host <em>integrations</em>"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "3e2a8516fb6173784f4bb0d1dad6672255030d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2022-01-12T11:29:37Z",
      "updated_at": "2022-01-12T11:29:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.97775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing Infrastructure <em>integration</em> data",
        "sections": "<em>Troubleshoot</em> <em>integration</em> requirements",
        "tags": "Create <em>integrations</em>",
        "body": "Problem You created a custom infrastructure on-host integration using the <em>Integrations</em> SDK, but you&#x27;re not seeing data in the infrastructure UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic Infrastructure&#x27;s integration requirements. After ruling out"
      },
      "id": "617db89228ccbc29ac7fe921"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/invalid-principal-error-unsupported-aws-regions": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2022-01-12T02:31:56Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.62935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2022-01-12T04:33:51Z",
      "updated_at": "2022-01-12T04:33:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the infrastructure agent and waited a few minutes, but no data appears in the infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Query builder, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.9908,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Verify install for yum (<em>Amazon</em> Linux, CentOS, or RHEL)",
        "tags": "Infrastructure monitoring <em>troubleshooting</em>",
        "body": " the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see <em>troubleshooting</em> procedures for: APM data missing from infrastructure monitoring <em>Amazon</em>&#x2F;AWS <em>integrations</em> On-host <em>integrations</em>"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "3e2a8516fb6173784f4bb0d1dad6672255030d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2022-01-12T11:29:37Z",
      "updated_at": "2022-01-12T11:29:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.97767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing Infrastructure <em>integration</em> data",
        "sections": "<em>Troubleshoot</em> <em>integration</em> requirements",
        "tags": "Create <em>integrations</em>",
        "body": "Problem You created a custom infrastructure on-host integration using the <em>Integrations</em> SDK, but you&#x27;re not seeing data in the infrastructure UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic Infrastructure&#x27;s integration requirements. After ruling out"
      },
      "id": "617db89228ccbc29ac7fe921"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations": [
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2022-01-12T04:33:51Z",
      "updated_at": "2022-01-12T04:33:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the infrastructure agent and waited a few minutes, but no data appears in the infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Query builder, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.9908,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Verify install for yum (<em>Amazon</em> Linux, CentOS, or RHEL)",
        "tags": "Infrastructure monitoring <em>troubleshooting</em>",
        "body": " the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see <em>troubleshooting</em> procedures for: APM data missing from infrastructure monitoring <em>Amazon</em>&#x2F;AWS <em>integrations</em> On-host <em>integrations</em>"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "3e2a8516fb6173784f4bb0d1dad6672255030d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2022-01-12T11:29:37Z",
      "updated_at": "2022-01-12T11:29:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.97767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing Infrastructure <em>integration</em> data",
        "sections": "<em>Troubleshoot</em> <em>integration</em> requirements",
        "tags": "Create <em>integrations</em>",
        "body": "Problem You created a custom infrastructure on-host integration using the <em>Integrations</em> SDK, but you&#x27;re not seeing data in the infrastructure UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic Infrastructure&#x27;s integration requirements. After ruling out"
      },
      "id": "617db89228ccbc29ac7fe921"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2022-01-12T02:30:22Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.09013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/no-data-appears-aws-integrations": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2022-01-12T02:31:56Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.62934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2022-01-12T04:33:51Z",
      "updated_at": "2022-01-12T04:33:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the infrastructure agent and waited a few minutes, but no data appears in the infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Query builder, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.990715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Verify install for yum (<em>Amazon</em> Linux, CentOS, or RHEL)",
        "tags": "Infrastructure monitoring <em>troubleshooting</em>",
        "body": " the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see <em>troubleshooting</em> procedures for: APM data missing from infrastructure monitoring <em>Amazon</em>&#x2F;AWS <em>integrations</em> On-host <em>integrations</em>"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "3e2a8516fb6173784f4bb0d1dad6672255030d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2022-01-12T11:29:37Z",
      "updated_at": "2022-01-12T11:29:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.977585,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing Infrastructure <em>integration</em> data",
        "sections": "<em>Troubleshoot</em> <em>integration</em> requirements",
        "tags": "Create <em>integrations</em>",
        "body": "Problem You created a custom infrastructure on-host integration using the <em>Integrations</em> SDK, but you&#x27;re not seeing data in the infrastructure UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic Infrastructure&#x27;s integration requirements. After ruling out"
      },
      "id": "617db89228ccbc29ac7fe921"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/no-data-metric-streams": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2022-01-12T01:58:08Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "sections": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " to 24 hours. Inventory: the Inventory page is not supported with AWS <em>CloudWatch</em> <em>metric</em> <em>streams</em> (inventory telemetry is not included in the <em>stream</em>). <em>Integrations</em> not fully replaced by <em>metric</em> <em>streams</em> The AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> integration only collects <em>CloudWatch</em> metrics, resource metadata"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2022-01-12T02:20:41Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.54712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> integration is the recommended solution to monitor all <em>CloudWatch</em> metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2022-01-12T02:20:41Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.74947,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To start receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS <em>CloudWatch</em> <em>metric</em> <em>streams</em> is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/partial-or-missing-logs-rds-vpc-aws-lambda": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2022-01-12T02:31:56Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.62933,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2022-01-12T04:33:51Z",
      "updated_at": "2022-01-12T04:33:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the infrastructure agent and waited a few minutes, but no data appears in the infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Query builder, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.99063,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Verify install for yum (<em>Amazon</em> Linux, CentOS, or RHEL)",
        "tags": "Infrastructure monitoring <em>troubleshooting</em>",
        "body": " the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see <em>troubleshooting</em> procedures for: APM data missing from infrastructure monitoring <em>Amazon</em>&#x2F;AWS <em>integrations</em> On-host <em>integrations</em>"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "3e2a8516fb6173784f4bb0d1dad6672255030d1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2022-01-12T11:29:37Z",
      "updated_at": "2022-01-12T11:29:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.97749,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing Infrastructure <em>integration</em> data",
        "sections": "<em>Troubleshoot</em> <em>integration</em> requirements",
        "tags": "Create <em>integrations</em>",
        "body": "Problem You created a custom infrastructure on-host integration using the <em>Integrations</em> SDK, but you&#x27;re not seeing data in the infrastructure UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic Infrastructure&#x27;s integration requirements. After ruling out"
      },
      "id": "617db89228ccbc29ac7fe921"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration": [
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2022-01-12T03:50:15Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.51799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2022-01-12T03:51:10Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.4861,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9cc7726bfac01b6d287c335f5a5d6705b168e7a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2022-01-12T02:24:24Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.14214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No data appears",
        "sections": "ECS <em>integration</em> troubleshooting: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "617db44ce7b9d226b2c047e9"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration": [
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2022-01-12T03:51:10Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.31624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9cc7726bfac01b6d287c335f5a5d6705b168e7a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2022-01-12T02:24:24Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.14214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No data appears",
        "sections": "ECS <em>integration</em> troubleshooting: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "617db44ce7b9d226b2c047e9"
    },
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2022-01-12T03:51:10Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.14214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "sections": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the <em>container</em> ID of the New Relic <em>integration</em> <em>container</em>, by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Save the logs from the <em>container</em> with the command docker logs NRI_ECS_<em>CONTAINER</em>_ID &gt; logs.txt. Leave the command running for about three minutes to generate sufficient"
      },
      "id": "617db44c28ccbc965d80120d"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration": [
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2022-01-12T03:50:15Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.3532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the ECS <em>integration</em>",
        "sections": "<em>Install</em> the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9cc7726bfac01b6d287c335f5a5d6705b168e7a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2022-01-12T02:24:24Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.14214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No data appears",
        "sections": "ECS <em>integration</em> troubleshooting: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "617db44ce7b9d226b2c047e9"
    },
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2022-01-12T03:51:10Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.14214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "sections": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the <em>container</em> ID of the New Relic <em>integration</em> <em>container</em>, by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Save the logs from the <em>container</em> with the command docker logs NRI_ECS_<em>CONTAINER</em>_ID &gt; logs.txt. Leave the command running for about three minutes to generate sufficient"
      },
      "id": "617db44c28ccbc965d80120d"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs": [
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9cc7726bfac01b6d287c335f5a5d6705b168e7a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2022-01-12T02:24:24Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.54752,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". <em>Troubleshoot</em> in the UI To use the UI to <em>troubleshoot</em>: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "617db44ce7b9d226b2c047e9"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2022-01-12T03:50:15Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.04924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2022-01-12T03:51:10Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.01743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears": [
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2022-01-12T03:51:10Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.04695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec <em>INTEGRATION_CONTAINER</em>_ID &#x2F;usr&#x2F;bin&#x2F;newrelic-infra-ctl Copy For more details, see <em>Troubleshoot</em> the agent. Save"
      },
      "id": "617db44c28ccbc965d80120d"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2022-01-12T03:50:15Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.04924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2022-01-12T03:51:10Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.01743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions": [
    {
      "sections": [
        "Understand and use ECS data",
        "View data",
        "Query your data"
      ],
      "title": "Understand and use ECS data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "6373cb619a787c0a22f4d91c954cd2a8d6ad3b41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/understand-use-data/understand-use-ecs-data/",
      "published_at": "2022-01-12T03:52:11Z",
      "updated_at": "2021-11-13T16:40:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Here we explain how to find, understand, and use the data reported by this integration. View data To view the ECS integration dashboard: Go to one.newrelic.com and select Explorer. On the left, search for ECS clusters, or type the name of your ECS cluster in the search bar. To view a dashboard, select the entity name corresponding to your ECS cluster. In addition to the pre-built dashboards, you can also create your own custom queries and charts using the query builder. To learn how to query this data, see Understand data. Query your data Data reported by this integration is displayed in its dashboards and is also available for querying and the creation of custom charts and dashboards. This integration reports an EcsClusterSample event, with attributes clusterName, awsRegion, ecsLaunchType and arn. Other types of data that may be available for querying: Infrastructure agent-reported events, including Docker All the events reported from an ECS cluster contain the attributes ecsClusterName, ecsLaunchType and ecsClusterArn. Here's an example NRQL query that returns the count of containers associated with each Docker image in an ECS cluster named MyClusterName created in us-east-1: SELECT uniqueCount(containerId) FROM ContainerSample WHERE awsRegion = 'us-east-1' AND ecsClusterName = 'MyClusterName' FACET imageName SINCE 1 HOUR AGO Copy To learn more about creating custom queries and charts: How to query New Relic data Introduction to NRQL",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.55057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "sections": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Here we explain how to find, <em>understand</em>, and <em>use</em> the <em>data</em> reported by this <em>integration</em>. View <em>data</em> To view the ECS <em>integration</em> dashboard: Go to one.newrelic.com and select Explorer"
      },
      "id": "617db48de7b9d24953c05054"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2022-01-12T03:50:15Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.51799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the placeholder busybox <em>container</em>. Next steps: Wait a few minutes and then look for your <em>data</em> in the UI. Recommended: Install our ECS cloud <em>integration</em>, which gets you other ECS <em>data</em>, including information about clusters and services. See recommended alert conditions. <em>Understand</em> the AWS resources"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2022-01-12T03:51:10Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.48608,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation <em>Use</em> automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/understand-use-data/understand-use-ecs-data": [
    {
      "sections": [
        "Recommended ECS alert conditions",
        "Recommended alert conditions"
      ],
      "title": "Recommended ECS alert conditions",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "2adc4dd0bff89ea0d3e05fa756ba4d30adf9bf53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions/",
      "published_at": "2022-01-12T03:52:11Z",
      "updated_at": "2021-10-24T01:53:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go to the Alerts UI and add the following NRQL alert conditions to an existing or new alert policy: High CPU usage NRQL: FROM ContainerSample SELECT cpuUsedCoresPercent Critical: > 90% for 5 minutes High memory usage NRQL: FROM ContainerSample SELECT memoryUsageBytes / memorySizeLimitBytes Critical: > 80% for 5 minutes Restart count NRQL: FROM ContainerSample SELECT max(restartCount) - min(restartCount) Critical: > 5 for 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.15446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go"
      },
      "id": "617db48e64441f3722fbe764"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2022-01-12T03:50:15Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.51799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the placeholder busybox <em>container</em>. Next steps: Wait a few minutes and then look for your <em>data</em> in the UI. Recommended: Install our ECS cloud <em>integration</em>, which gets you other ECS <em>data</em>, including information about clusters and services. See recommended alert conditions. <em>Understand</em> the AWS resources"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2022-01-12T03:51:10Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.48608,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation <em>Use</em> automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-app-engine-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2022-01-12T03:36:08Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2022-01-12T07:38:14Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2022-01-12T07:38:15Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.25056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-bigquery-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2022-01-12T03:36:08Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2022-01-12T07:38:14Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2022-01-12T07:38:15Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.25056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-bigtable-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2022-01-12T03:36:08Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2022-01-12T07:38:14Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2022-01-12T07:38:15Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.25056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2022-01-12T03:36:08Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2022-01-12T07:38:14Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2022-01-12T07:38:15Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.25056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataflow-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2022-01-12T03:36:08Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2022-01-12T07:38:14Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2022-01-12T07:38:15Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.25056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataproc-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2022-01-12T03:36:08Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2022-01-12T07:38:14Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2022-01-12T07:38:15Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.25056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firebase-database-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2022-01-12T03:36:08Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2022-01-12T07:38:14Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2022-01-12T07:38:15Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.25056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firebase-hosting-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2022-01-12T03:36:08Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2022-01-12T07:38:14Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2022-01-12T07:38:15Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.25056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firebase-storage-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2022-01-12T03:36:08Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2022-01-12T07:38:14Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.03023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2022-01-12T07:38:15Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.25056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ]
}