{
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-span-attribute-trace-filter": [
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-25T04:59:22Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 348.64328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.88528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em>. <em>Trace</em> sampling How your traces are sampled will <em>depend</em> on your setup and the New Relic <em>tracing</em> tool you&#x27;re using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you&#x27;re using <em>Infinite</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:44:45Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.54877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-trace-observer-monitoring": [
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-25T04:59:22Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 348.64328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.88528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em>. <em>Trace</em> sampling How your traces are sampled will <em>depend</em> on your setup and the New Relic <em>tracing</em> tool you&#x27;re using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you&#x27;re using <em>Infinite</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:44:45Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.54877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing": [
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.8852,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em>. <em>Trace</em> sampling How your traces are sampled will <em>depend</em> on your setup and the New Relic <em>tracing</em> tool you&#x27;re using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you&#x27;re using <em>Infinite</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:44:45Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.54874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-25T05:02:05Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.83081,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up <em>Infinite</em> <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> data to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/set-trace-observer": [
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-25T04:59:22Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 348.64316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.8852,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em>. <em>Trace</em> sampling How your traces are sampled will <em>depend</em> on your setup and the New Relic <em>tracing</em> tool you&#x27;re using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you&#x27;re using <em>Infinite</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:44:45Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.54874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/other-requirements/infinite-tracing-configuring-ssl-java-7-8": [
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-25T04:59:22Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 348.64316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.8852,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em>. <em>Trace</em> sampling How your traces are sampled will <em>depend</em> on your setup and the New Relic <em>tracing</em> tool you&#x27;re using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you&#x27;re using <em>Infinite</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:44:45Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.54874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/trace-api/introduction-trace-api": [
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.3884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " don&#x27;t have Infinite <em>Tracing</em> enabled, our <em>Trace</em> <em>API</em> does no sampling (unless the default data limits are exceeded). It&#x27;s expected that you set up the <em>Trace</em> <em>API</em> to send us the traces you think are important. How <em>trace</em> data is structured Understanding the structure of a <em>distributed</em> <em>trace</em> can help you"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.82498,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:44:45Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.28032,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api": [
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.3884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " don&#x27;t have Infinite <em>Tracing</em> enabled, our <em>Trace</em> <em>API</em> does no sampling (unless the default data limits are exceeded). It&#x27;s expected that you set up the <em>Trace</em> <em>API</em> to send us the traces you think are important. How <em>trace</em> data is structured Understanding the structure of a <em>distributed</em> <em>trace</em> can help you"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.82498,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:44:45Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.28032,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api": [
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.38832,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " don&#x27;t have Infinite <em>Tracing</em> enabled, our <em>Trace</em> <em>API</em> does no sampling (unless the default data limits are exceeded). It&#x27;s expected that you set up the <em>Trace</em> <em>API</em> to send us the traces you think are important. How <em>trace</em> data is structured Understanding the structure of a <em>distributed</em> <em>trace</em> can help you"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.82495,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:44:45Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.2803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-decorate-spans-attributes": [
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.38832,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " don&#x27;t have Infinite <em>Tracing</em> enabled, our <em>Trace</em> <em>API</em> does no sampling (unless the default data limits are exceeded). It&#x27;s expected that you set up the <em>Trace</em> <em>API</em> to send us the traces you think are important. How <em>trace</em> data is structured Understanding the structure of a <em>distributed</em> <em>trace</em> can help you"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.82495,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:44:45Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.2803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits": [
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.38824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " don&#x27;t have Infinite <em>Tracing</em> enabled, our <em>Trace</em> <em>API</em> does no sampling (unless the default data limits are exceeded). It&#x27;s expected that you set up the <em>Trace</em> <em>API</em> to send us the traces you think are important. How <em>trace</em> data is structured Understanding the structure of a <em>distributed</em> <em>trace</em> can help you"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.82494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-25T05:44:45Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.28027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts": [
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-25T04:59:22Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.82242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.81558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Missing trace data",
        "Problem",
        "Solution",
        "Important",
        "Problems with enabling or instrumenting",
        "Missing spans due to service not having distributed tracing enabled",
        "Missing apps/services may require manual instrumentation",
        "Problems with spans",
        "Infinite Tracing: missing spans",
        "Missing span not getting exported",
        "Missing spans due to sampling process",
        "Missing spans due to span limits maxed out",
        "Missing spans due to spans being sent late",
        "Problems with trace details",
        "Middleware doesn't recognize proprietary New Relic header",
        "An intermediary is missing or isn't passing trace context",
        "Tip",
        "Stitching together spans from mixed sources",
        "Trace details are obfuscated",
        "Trace list information and trace details don't match",
        "Long traces with short backend times",
        "Problems with browser applications",
        "Missing spans and transactions after enabling for a browser application",
        "Not seeing browser app end-user spans",
        "Browser spans are not connected to other spans",
        "Other problems",
        "Search by entity.name not finding associated app names",
        "Supporting OpenTelemetry"
      ],
      "title": "Missing trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "2997172d74563c4fa31d5a9fc05c562d62c1c790",
      "image": "https://docs.newrelic.com/static/ef51359ad9a7999f7fdaf812fab535bc/d7542/missing-exporter.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/missing-trace-data/",
      "published_at": "2021-12-25T15:02:18Z",
      "updated_at": "2021-07-08T22:10:20Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have enabled distributed tracing but data you expected to see does not appear in New Relic's distributed tracing UI. Solution Important Before performing troubleshooting, we recommend reading How distributed tracing works. Here are some causes and solutions when you have problems finding expected data in the distributed tracing UI: Problems with enabling or instrumenting Missing spans due to service not having distributed tracing enabled In order for distributed tracing to report details for all nodes in a trace, each application must be monitored by a New Relic agent that has had distributed tracing enabled. If an application's New Relic account has not had distributed tracing enabled, it will have these issues: Its distributed tracing UI page won't have data. It won't report data to other accounts' distributed traces. Missing apps/services may require manual instrumentation When you enable distributed tracing for applications and services that New Relic automatically instruments, you'll usually see complete and detailed data for those nodes in the distributed tracing UI. However, you may notice that some services or applications are missing from traces, or that there are some internal spans you expect to see that are missing. If that's the case, you may want to implement custom instrumentation of applications or specific transactions to see more detail in traces. Some examples of when you may need to do this: Transactions not automatically instrumented. To ensure your application is automatically instrumented, read the compatibility and requirements documentation for the New Relic agent you're using. If an application isn't automatically instrumented, or if you'd like to add instrumentation of specific activity, see Custom instrumentation. All Go applications. The Go agent, unlike other agents, requires manual instrumentation of your code. For instructions, see Instrument a Go application. A service doesn't use HTTP. If a service doesn't communicate via HTTP, the New Relic agent won't send distributed tracing headers. This may be the case for some non-web applications or message queues. To remedy this, use the distributed tracing APIs to instrument either the calling or called application. Problems with spans Infinite Tracing: missing spans If your APM agent can’t write data fast enough to the trace observer, queue_size is an additional APM agent configuration to limit the number of spans the agent will hold. See the following examples for your agent: .NET configuration method Example Configuration file <configuration . . . > <infiniteTracing> <trace_observer> <span_events queue_size=\"100000\" /> </trace_observer> </infiniteTracing> </configuration> Copy Environment variable NEW_RELIC_INFINITE_TRACING_SPAN_EVENTS_QUEUE_SIZE=100000 Copy Python configuration method Example Configuration file infinite_tracing.span_queue_size = 100000 Environment Variable NEW_RELIC_INFINITE_TRACING_SPAN_QUEUE_SIZE = 100000 Missing span not getting exported Sometimes header propagation is successful, but the span information isn't getting sent to New Relic. For example, if OpenTelemetry is not instrumented with a New Relic exporter, the span details never make it to New Relic. In this diagram, notice that the header propagation is successful, but no exporter is set up in Service 2 to send the span to New Relic: The following diagram also shows successful header propagation, but it includes an exporter in Service 2 that sends the span details to New Relic (see Trace API): Missing spans due to sampling process Standard distributed tracing for APM uses adaptive sampling. This means that a percentage of calls to a service will be reported as part of a distributed trace. Specific calls to your service might not have been selected to be sampled. Missing spans due to span limits maxed out There are limits on the number of spans that can be collected and displayed. If an application generates a very large number of spans for a single call, it might exceed the APM agent's span-collection limit for that harvest cycle. This could result in missing spans and significantly limit the number of traces the agent can completely sample and report. We currently only show 10,000 spans at a time. Missing spans due to spans being sent late Spans must be sent within the last twenty minutes to be captured in a trace index. If you send any spans older than twenty minutes but newer than a day, the span data will still be written. However, it won't be rolled into the trace index, which controls the trace list in the distributed tracing UI. If a span has a timestamp older than a day, it will be dropped. This often occurs when there is clock skew (timing differences) between systems or long running background jobs. Problems with trace details Middleware doesn't recognize proprietary New Relic header If your transactions are only sending the proprietary New Relic header, some middleware might not recognize the format and then drop the information as shown in this diagram: One solution is to upgrade your New Relic agent to a version that supports W3C trace context. In the diagram below, the W3C-compliant New Relic agent passes the prior header along with two standardized headers: An intermediary is missing or isn't passing trace context Some potential problems with proxies and other intermediaries: Incomplete trace. Some intermediaries won't automatically propagate the distributed tracing header. In that case, you must configure that component to allow the header to be passed from source to destination. For instructions, consult the documentation for that intermediary component. Missing intermediary in trace. If the intermediary is New Relic-monitored, ensure that it propagates the newrelic header that is generated or updated by the New Relic agent running on that intermediary. This may manifest when an intermediary was previously visible in traces, but disappeared after distributed tracing was enabled for an upstream entity (for example, a browser-monitored application). Tip If some entities report trace data to another tracing system, you can use the trace ID from the New Relic UI to search other tracing systems for missing spans. Stitching together spans from mixed sources If each agent in a chain supports W3C Trace Context, then we can stitch the spans together into a complete trace. If part of the chain is from an agent, such as Zipkin, which doesn't support W3C Trace Context, then spans coming from that agent may not be included in the trace. Trace details are obfuscated If a trace contains data from applications monitored by multiple New Relic accounts, and your user permissions don't allow you to access those accounts, some of the span and service details will be obfuscated in the UI. For example, you may see a series of asterisks ( * * * * * ) instead of the service name in your distributed tracing list if you don't have access to the account linked with the service. Trace list information and trace details don't match The trace list is generated by trace indexes, which are captured in a twenty minute window from when the first spans are received. Usually, this is due to late spans. Long traces with short backend times If you're seeing unusually short backend times for long traces, this is likely an issue with the timestamps being sent. For example, the root span might be reposting microseconds as milliseconds. This can also happen if the root span is a browser application. When using an external client like a web browser, you may experience clock skew (timing differences) more often. Problems with browser applications Missing spans and transactions after enabling for a browser application Older versions of some APM agents are incompatible with distributed tracing for browser applications. If the browser application makes an AJAX request to an APM application running an incompatible agent, then the APM agent may not record transaction and span data for that request. If distributed tracing is enabled for a browser application and you are not seeing transaction or span data for downstream APM requests, review the browser data in distributed tracing requirements, and confirm that all applications are running supported versions of the APM agent. Not seeing browser app end-user spans If traces seem to be missing end-user spans, be sure you've read and understand the browser distributed tracing requirements and enable procedures. On the AJAX UI page, there are links to the distributed tracing UI regardless of whether there are end-user spans present in that trace. For details about what data generates spans, see Requirements. Browser spans are not connected to other spans Older versions of some APM agents are incompatible with distributed tracing for browser applications. If APM spans are missing consistently from traces that include browser applications, please refer to the browser data in distributed tracing requirements and confirm that all applications are running supported versions of the APM agent. For other causes of orphaned browser spans, see Browser span reporting. Other problems Search by entity.name not finding associated app names Potential cause: For applications that have multiple app names, the entity.name attribute will be associated only with the primary app name. To search by other app names, search using the appName attribute. Supporting OpenTelemetry Questions about integrating with OpenTelemetry should be taken to the Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.66092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing <em>trace</em> data",
        "sections": "Missing spans due to service not having <em>distributed</em> <em>tracing</em> enabled",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem You have enabled <em>distributed</em> <em>tracing</em> but data you expected to see does not appear in New Relic&#x27;s <em>distributed</em> <em>tracing</em> UI. Solution Important Before performing <em>troubleshooting</em>, we recommend reading How <em>distributed</em> <em>tracing</em> works. Here are some causes and solutions when you have problems"
      },
      "id": "6072a76764441f109b9d857b"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/missing-trace-data": [
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-25T04:59:22Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.82242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.81558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/2878076657e1173d9f8c92a6e7547a9f/83b75/intro-DT.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-12-25T13:53:03Z",
      "updated_at": "2021-11-13T19:56:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. You can also bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. You can also see logs in context of your infrastructure data, such as Kubernetes clusters. No need to switch to another UI page in New Relic One. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.65414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>distributed</em> <em>trace</em> data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    }
  ],
  "/docs/distributed-tracing/ui-data/query-distributed-trace-data": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-12-25T13:27:46Z",
      "updated_at": "2021-11-06T02:13:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.12164,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-25T04:59:22Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.82236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> <em>data</em> to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.81552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ": <em>Understand</em> how traces are displayed in our <em>UI</em> Help you query <em>trace</em> <em>data</em> A <em>distributed</em> <em>trace</em> has a tree-like structure, with &quot;child&quot; spans that refer to one &quot;parent&quot; span. This diagram shows some important span relationships in a <em>trace</em>: This diagram shows how spans in a <em>distributed</em> <em>trace</em> relate"
      },
      "id": "6072a66664441f14089d856c"
    }
  ],
  "/docs/distributed-tracing/ui-data/span-attributes": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-12-25T13:27:46Z",
      "updated_at": "2021-11-06T02:13:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.12164,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-25T04:59:22Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.82236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> <em>data</em> to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.81552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ": <em>Understand</em> how traces are displayed in our <em>UI</em> Help you query <em>trace</em> <em>data</em> A <em>distributed</em> <em>trace</em> has a tree-like structure, with &quot;child&quot; spans that refer to one &quot;parent&quot; span. This diagram shows some important span relationships in a <em>trace</em>: This diagram shows how spans in a <em>distributed</em> <em>trace</em> relate"
      },
      "id": "6072a66664441f14089d856c"
    }
  ],
  "/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui": [
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-25T04:59:22Z",
      "updated_at": "2021-12-19T15:33:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. Instructions for setting up Infinite Tracing are in the specific docs for our solutions. To get started, see our quick start guide. Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.8223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Infinite <em>Tracing</em>",
        "sections": "Introduction to Infinite <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is Infinite <em>Tracing</em>? Infinite <em>Tracing</em> allows you to send all your <em>trace</em> <em>data</em> to our cloud-based service and rely on Infinite <em>Tracing</em> to make sampling decisions. You can configure Infinite <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-12-25T05:43:56Z",
      "updated_at": "2021-12-19T15:31:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us. Or, if you're using Infinite Tracing, you'd probably send us all your trace data and rely on our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans are made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. For other details about limits, see New Relic data usage limits and policies. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and mobile trace reporting Browser monitoring distributed tracing and mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. See the table below for more details on the header: Item Description accountId This is your New Relic account ID. However, only those on your account and New Relic Admins can associate this Id with your account information in any way. appId This is the application ID of the application generating the trace header. Much like accountId, this identifier is not going to provide any information unless you're a user on the account. guid With Distributed Tracing, each segment of work in a trace is represented by a span, and each span has a guid attribute. The guid of the last span within the process is sent with the outgoing request so that the first segment of work in the receiving service can add this guid as the parentId attribute which connects data within the trace. Parent type The source of the trace header, as in mobile, browser, Ruby app, etc. This becomes the parent.type attribute on the transaction triggered by the request this header is attached to. Priority A randomly generated priority ranking value that helps determine which data is sampled when sampling limits are reached. This is a float value set by the first New Relic agent that’s part of the request so all data in the trace will have the same priority value. Sampled A boolean value that tells the agent if traced data should be collected for the request. This is also added as an attribute on any span and transaction data collected. If you want to read more about this sampling process, this guide goes into more detail. Timestamp Unix timestamp in milliseconds when the payload was created. traceId The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. This also is added as an attribute on the span and transaction data. transactionId The unique identifier for the transaction event. Trusted acount key This is a key that helps identify any other accounts associated with your account. So if you have multiple sub-accounts that the trace crosses, we can confirm that any data included in the trace is coming from a trusted source, and tells us what users should have access to the data. Version and data key This identifies major/minor versions, so if an agent receives a trace header from a version with breaking changes from the one it is on, it can reject that header and report the rejection and reason. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.81546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ": <em>Understand</em> how traces are displayed in our <em>UI</em> Help you query <em>trace</em> <em>data</em> A <em>distributed</em> <em>trace</em> has a tree-like structure, with &quot;child&quot; spans that refer to one &quot;parent&quot; span. This diagram shows some important span relationships in a <em>trace</em>: This diagram shows how spans in a <em>distributed</em> <em>trace</em> relate"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-12-25T13:26:52Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.24228,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span <em>data</em> that can be queried in New Relic. Here are ways to learn more about Span <em>data</em>: To explore your span <em>data</em>, you can use the query builder. To see the default attributes attached to span <em>data</em>, use the <em>data</em> dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    }
  ],
  "/docs/errors-inbox/error-limiting": [
    {
      "sections": [
        "Introduction to notifications",
        "Early access",
        "Destinations",
        "Message templates"
      ],
      "title": "Introduction to notifications",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Notifications",
        "Workflows",
        "Error Inbox"
      ],
      "external_id": "f623ca3e096307c13e6e9214cc2fa6908707d101",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/intro-notifications/",
      "published_at": "2021-12-25T04:31:38Z",
      "updated_at": "2021-11-25T00:02:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Notifications are a consolidation of the different ways to send notification-events to third-party services, such as Slack, Jira, ServiceNow, and email. You can also use webhooks to send your data to any compatible third-party service. Integrate with your systems by configuring destinations and message templates. Destinations Destinations are unique identifiers and connection details for third-party systems. Use destinations to integrate, send notifications and share data between New Relic and your third-party systems. Message templates Configure the eventual notification events and map New Relic One data to your third-party services using message-templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.68149,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Error</em> <em>Inbox</em>"
      },
      "id": "6190270f64441f165fe9d12b"
    },
    {
      "sections": [
        "Know your data limits",
        "Responses to limit violations",
        "System limits UI",
        "Troubleshooting system limits",
        "Account-level limits",
        "Data ingest API limits",
        "Finding other agent and integration limits"
      ],
      "title": "Know your data limits",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "7c540d94a8b5e4f024d175ad53cab9fab343187c",
      "image": "https://docs.newrelic.com/static/8ee61e3091f6e044202cff92026afada/8c557/limits-graph.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/view-system-limits/",
      "published_at": "2021-12-25T13:52:21Z",
      "updated_at": "2021-10-31T06:37:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure our systems are always up and ready to support you, and to keep you from unintended use, we place limits on the amount of data you can send, query, and store. Responses to limit violations Limits are enforced per child account, and across our APIs. You might reach a limit if you start monitoring a new high-traffic application, or have a sudden data spike. When you do reach a limit, New Relic responds according to the type of data and the limit that’s reached. For example: We place a limit on the number of ingested requests per minute (RPM) per data type. When this limit is reached, we stop accepting data and return a 429 status code for the duration of the minute. For queries, we place limits on the number of queries per minute and the number of records inspected (see query limits). When the number of queries per minute limit is reached, New Relic will begin rejecting queries until the number of queries is below the limit. When the records inspected limit is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow traffic from other sources. For metrics, we place a limit on the number of unique timeseries (cardinality) per account and per metric. When this limit is reached, aggregated data is turned off for the rest of the UTC day. For every major limit violation, New Relic creates an NrIntegrationError event for that account, which has these limit-related attributes: Attribute Description category RateLimit or ApiLimit. The RateLimit category is used for limits based on a unit of time such as the number of requests ingested per minute. The ApiLimit is used for constant limits, such as the number of attributes on a record. limitName The name of the limit. message Describes the limit and the impact. limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click Manage your data and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set a custom range from the top-right of the page. Non-limit-related NrIntegrationError events are not displayed here. In addition, this page does not display information about limits you have not hit, or how close you are to reaching a limit. For more on creating queries and alerts for data ingest and billing metrics, see Query billing/usage data. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a chart on the Limits UI page displaying a cardinality violation limit issue. To add more detail, or build a dashboard, click the View NRQL button on the chart to see the NRQL powering this view. The graph displays each unique limit type that was reached during the selected time-period. This can help you find any trends based on time. The Limits page also provides a table where you can find the limit name, the limit event message associated with it, and last occurrence time and date. If you click a limit in the table, you see more about what happened, and when. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a limit events table on the Limits UI page. Troubleshooting system limits To troubleshoot limits when you reach them, click the limit info in the table, and then follow the docs link that's provided. Different limits have different solutions. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Distributed tracing: Max age of span timestamp values 20 minutes. Timestamp must be within 20 minutes of current time at ingest or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Distributed tracing: Max spans per minute per account Dependent on agreement. Max limit: 2M. Distributed tracing: Max spans per trace 50K Distributed tracing: Max attributes per span 200 Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest API limits Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Finding other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our quickstarts here. Some default reporting limits are located in these tools' configuration docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.50085,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Know your data <em>limits</em>",
        "sections": "Know your data <em>limits</em>",
        "body": " monitoring a new high-traffic application, or have a sudden data spike. When you do <em>reach</em> a <em>limit</em>, New Relic responds according to the type of data and the <em>limit</em> that’s <em>reached</em>. For example: We place a <em>limit</em> on the number of ingested requests per minute (RPM) per data type. When this <em>limit</em> is <em>reached</em>"
      },
      "id": "60446a7c64441f48d7378f2b"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Errors when tailing a large amount of log files (Linux)",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "https://docs.newrelic.com/static/63ba6c3dc400e3cc4fb21668d5e7ba2a/c1b63/infrastructure-lic.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-12-26T01:47:48Z",
      "updated_at": "2021-12-25T01:46:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. Here is an example of where you can see logs in context of your infrastructure monitoring details in New Relic One. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by Infrastructure agent starting from 1.16.4. Built-in support for ARM64 architecture on Linux systems (in example, AWS Graviton architecture) added in Infrastructure agent 1.26.0. Important The log forwarding feature is not supported with the Docker container for infrastructure monitoring agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, 2019, and 2022, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors and inotify watches the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. Tailing a large number of files may require you to increase the maximum number of file descriptors and inotify watchers allowed by the operating system. Please refer to Errors when tailing a large amount of log files for more details on how to increase them. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Errors when tailing a large amount of log files (Linux) It's common to face either one of the following error messages when attempting to tail a large amount of files: Too many open files The user limit on the total number of inotify watches was reached or the kernel failed to allocate a needed resource The operating system defines a maximum amount of allocatable file descriptors (typically 1024 by default), and a maximum amount of allocatable inotify watches (typically 8192 by default). Any process attempting to go above these limits will fail, returning one of the errors above. The underlying technology we use to forward logs, Fluent Bit, opens one file descriptor and sets an inotify watch for each file you configure to be forwarded. Moreover, at the time of writing this section, Fluent Bit uses an extra set of 32 file descriptors for its normal operation, with another extra file descriptor when it shuts down. Therefore, to capture a large amount of files you need to ensure that both the file descriptor and inotify watch limits are slightly greater than the amount of log files you wish to tail. The following instructions summarize how to increase these limits if you want to tail 10,000 log files. Also, it assumes the infrastructure agent is installed in root running mode, and therefore must be run using the root user. Check which is the current hard limit for the amount of file descriptors per process. Typically, this limit should be quite high and should not need to be modified. ulimit -Hn Copy Add the following line to /etc/security/limits.conf. We specified a limit of 10100 here instead of just 10000 to allow Fluent Bit to allocate the extra file descriptors it may need to work. root soft nofile 10100 # replace root by nri-agent for non-root (privileged and unprivileged) installations Copy Add the following line to /etc/pam.d/common-session so that the previous limit is applied upon restart: session required pam_limits.so Copy Add the following line to /etc/sysctl.conf to increase the amount of allowed inotify watchers per user. We specified a limit of 18192 here instead of just 10000 so that the root user will still have 8192 available inotify watches (the default value). fs.inotify.max_user_watches=18192 Copy Restart your system. Ensure that the new limits have been enforced by running: ulimit -Sn # Should return 10100 cat /proc/sys/fs/inotify/max_user_watches # Should return 18192 Copy Learn more on how to increase open file limits, or on how to increase the inotify watches. Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 85.287155,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Runtime <em>error</em> on Windows",
        "body": "&#x27;s file descriptor <em>limit</em> is <em>reached</em>. Tailing a large number of files may require you to increase the maximum number of file descriptors and inotify watchers allowed by the operating system. Please refer to Errors when tailing a large amount of log files for more details on how to increase them"
      },
      "id": "603e9df164441f6b6f4e8843"
    }
  ],
  "/docs/errors-inbox/errors-inbox": [
    {
      "image": "https://docs.newrelic.com/static/45de34e3a56f26f44cbd62f69d1bb8b6/ae694/error.png",
      "url": "https://docs.newrelic.com/whats-new/2021/06/errors-inbox/",
      "sections": [
        "Errors Inbox: Error tracking across your entire stack"
      ],
      "published_at": "2021-12-25T23:48:22Z",
      "title": "Errors Inbox: Error tracking across your entire stack",
      "updated_at": "2021-06-25T12:10:39Z",
      "type": "docs",
      "external_id": "9ee9b292d1ae812a2b6cff8dbf6f0a2b19a9caa0",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Recently, we launched New Relic Errors Inbox, an error tracking solution that provides you a single place to view, triage and resolve errors across your full application stack. This exciting feature now includes Logs in Context and an integration with Slack. Read more about the latest updates in our blog post and watch a demo in the latest Nerdlog episode here. What’s Included with New Relic Errors Inbox: Errors Inbox. Errors are grouped and displayed on a single screen for visibility and easy triaging. Filter to just the applications and services that you care about. Rich Error Details. Resolve errors faster with context of the full stack, including APM, Browser (RUM), Mobile, and Serverless (AWS Lambda Function) data. Error data persists to provide continued context for recurring errors. Log Data. Logs in Context are provided alongside other error data right in the error group details for even more information to resolve errors faster. Cross Team Collaboration. Work errors as a team with shared error visibility, shared comments, and an integration with Slack. Next Steps New Relic Errors Inbox is available to all New Relic Full-Stack Observability customers in the U.S. datacenter. To enable Errors Inbox, sign up for a free account or log in to your existing account and follow these steps: From one.newrelic.com, select More in the top right and click Errors Inbox. If this is your first time accessing Errors Inbox, you will be prompted to select a workload in the top left.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.2646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Errors</em> <em>Inbox</em>: <em>Error</em> <em>tracking</em> across your entire stack",
        "sections": "<em>Errors</em> <em>Inbox</em>: <em>Error</em> <em>tracking</em> across your entire stack",
        "body": "Recently, we launched New Relic <em>Errors</em> <em>Inbox</em>, an <em>error</em> <em>tracking</em> solution that provides you a single place to view, triage and resolve <em>errors</em> across your full application stack. This exciting feature now includes Logs in Context and an integration with Slack. Read more about the latest updates"
      },
      "id": "60d5c7bfe7b9d208f1d67792"
    },
    {
      "image": "https://developer.newrelic.com/static/31a54fffa55465d7c2b36f21218a43d6/0086b/filters-pane.png",
      "url": "https://developer.newrelic.com/automate-workflows/error-inbox/manage-errors/",
      "sections": [
        "Manage your triaged errors",
        "lab",
        "View triaged errors",
        "Tip",
        "Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-26T01:38:07Z",
      "title": "Manage your triaged errors",
      "updated_at": "2021-12-19T01:46:41Z",
      "type": "developer",
      "external_id": "fb7cac4eab154359e99dfdfb32af2536f217b82b",
      "document_type": "page",
      "popularity": 1,
      "info": "Managed your triaged errors in Errors Inbox",
      "body": "lab This procedure is part of a lab that teaches you how to manage errors using Errors Inbox. Each procedure in the lab builds upon the last, so make sure you've triaged your errors before starting this one. You're now observing Geek's Movie Shop's errors in Errors Inbox, and you're trying to debug your application before pushing your site live. With your errors triaged, you can track their progress, look at who's working on a bug, or even create tasks in Jira to resolve them. View triaged errors Change the filter in Errors Inbox to view your triaged errors Step 1 of 3 In Errors Inbox, find the filter pane below the top navigation bar. Step 2 of 3 Click Unresolved to change the filter value. Here, you see three options in the dropdown: Resolved Unresolved Ignored Step 3 of 3 Select Resolved. Errors Inbox now shows you all your resolved error groups. If you only resolved pika.exceptions:ChannelWrongStateError, you don't see any resolved errors here because Errors Inbox unresolved that one when it saw another occurrence. Tip If you want to observe your ignored error groups instead of resolved ones, filter by Ignored. Optional: Integrate Errors Inbox with Slack, Jira, and CodeStream Being able to view resolved and ignored errors is useful, but you're trying to squash the bugs in your application before you deploy it to production. To help you manage this, connect your inbox to Slack, Jira, and CodeStream. Summary In this lab, you set up Errors Inbox to proactively observe and catch errors from across your stack. You analyzed the errors in full context and triaged them before they could affect your customers. You also managed your errors in Errors Inbox and integrated your inbox with Jira, CodeStream, and Slack to help you collaborate and resolve errors faster. Once you resolve your high priority errors, you'll be more confident in your production release. But Errors Inbox is helpful even when you're in production, because you'll be able to see, triage, and manage errors that come from your customers as well. Homework Now that you know how to track and triage errors using Errors Inbox, here are some other resources you can use to familiarize yourself even more with Errors Inbox. Read our documentation on Errors Inbox Read our blog Collaborate and fix errors quickly with Errors Inbox and workloads Read our blog Error Tracking Across Your Entire Stack with New Relic Errors Inbox",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.42198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your triaged <em>errors</em>",
        "sections": "Optional: Integrate <em>Errors</em> <em>Inbox</em> <em>with</em> Slack, Jira, and CodeStream",
        "info": "Managed your triaged <em>errors</em> in <em>Errors</em> <em>Inbox</em>",
        "body": " using <em>Errors</em> <em>Inbox</em>, here are some other resources you can use to familiarize yourself even more with <em>Errors</em> <em>Inbox</em>. Read our documentation on <em>Errors</em> <em>Inbox</em> Read our blog Collaborate and fix <em>errors</em> quickly with <em>Errors</em> <em>Inbox</em> and workloads Read our blog <em>Error</em> <em>Tracking</em> Across Your Entire Stack with New Relic <em>Errors</em> <em>Inbox</em>"
      },
      "id": "61be8f01196a67e048eef29c"
    },
    {
      "sections": [
        "Introduction to notifications",
        "Early access",
        "Destinations",
        "Message templates"
      ],
      "title": "Introduction to notifications",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Notifications",
        "Workflows",
        "Error Inbox"
      ],
      "external_id": "f623ca3e096307c13e6e9214cc2fa6908707d101",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/intro-notifications/",
      "published_at": "2021-12-25T04:31:38Z",
      "updated_at": "2021-11-25T00:02:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Notifications are a consolidation of the different ways to send notification-events to third-party services, such as Slack, Jira, ServiceNow, and email. You can also use webhooks to send your data to any compatible third-party service. Integrate with your systems by configuring destinations and message templates. Destinations Destinations are unique identifiers and connection details for third-party systems. Use destinations to integrate, send notifications and share data between New Relic and your third-party systems. Message templates Configure the eventual notification events and map New Relic One data to your third-party services using message-templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.09491,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Error</em> <em>Inbox</em>"
      },
      "id": "6190270f64441f165fe9d12b"
    }
  ],
  "/docs/gateway-api-import-data-other-observability-platforms": [
    {
      "sections": [
        "Amazon API Gateway monitoring integration",
        "Features",
        "Requirements",
        "Tip",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Inventory data",
        "Dimensions"
      ],
      "title": "Amazon API Gateway monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "dbeb75bde2ffb29fe6c7eb41b536fa477c2b80ab",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration/",
      "published_at": "2021-12-25T15:16:41Z",
      "updated_at": "2021-10-23T16:39:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon API Gateway data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features Amazon's API Gateway is a fully managed service that allows you to create, publish, maintain, monitor, and secure APIs at any scale. With the New Relic API Gateway integration, you get more data about how your API layer is working behind the scenes. You'll receive metric data about the number of API calls, the requests served, the number of errors, latency counts, and more. You can monitor and alert on your API Gateway data directly from New Relic, and query data and create dashboards. Requirements API Gateway will not send \"Call count by resource\", \"4xx error by resource\" and \"5xx errors by resource\" metrics unless you have explicitly enabled detailed CloudWatch metrics. Tip Enabling these metrics may add additional charges to your Amazon CloudWatch account pricing. To enable CloudWatch metrics, use either of these options: Go to the AWS Management Console, select the Settings option for CloudWatch, then select the option to enable detailed CloudWatch metrics. Call the stage:update action of the Amazon API Gateway REST API to update the metricsEnabled property to true. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon API gateway integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the API Gateway integration links. You can query and explore your data using the ApiGatewaySample event type. For more on how to use your data, see Understand and use integration data. Metric data This New Relic infrastructure integration collects the following Amazon API Gateway data: Metric Description 4XXError The number of client-side errors captured 5XXError The number of server-side errors captured. CacheHitCount The number of requests served from the API cache. CacheMissCount The number of requests served from the back end when API caching is enabled. Count The number of calls to API methods. IntegrationLatency The time in milliseconds between when API Gateway relays a request to the back end and when it receives a response from the back end. Latency The time in milliseconds between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Inventory data Inventory data provides information about the service's state and configuration. API Gateway configuration options are reported as inventory data. For more about inventory data, see Understand and use data. Object Inventory data /aws/apigateway/api apiId apiName awsRegion /aws/apigateway/resource awsRegion methods resource resourceid /aws/apigateway/stage apiName awsRegion cacheClusterEnable cacheClusterSize cacheClusterStatus lastUpdatedDate stageName /aws/apigateway/stage/variables value /aws/apigateway/stage/settings CacheDataEncrypted CacheTtlInSeconds CachingEnabled DataTraceEnabled LoginLevel MetricsEnabled RequireAuthorizationForCacheControl UnauthorizedCacheControlHeaderStrategy ThrottlingBurstLimit ThrottlingRateLimit /aws/apigateway/stage/resource-with-metrics apiName awsRegion method resource stageName Dimensions You can use the dimensions in the following table to filter API Gateway metrics. Dimensions Description ApiName Filters API Gateway metrics for an API of the specified API name. ApiName, Method, Resource, Stage Filters API Gateway metrics for an API method of the specified API, stage, resource, and method. ApiName, Stage Filters API Gateway metrics for an API stage of the specified API and stage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 92.888115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Amazon <em>API</em> <em>Gateway</em> monitoring integration",
        "sections": "Amazon <em>API</em> <em>Gateway</em> monitoring integration",
        "body": ", and more. You can monitor and alert on your <em>API</em> <em>Gateway</em> <em>data</em> directly <em>from</em> New Relic, and query <em>data</em> and create dashboards. Requirements <em>API</em> <em>Gateway</em> will not send &quot;Call count by resource&quot;, &quot;4xx error by resource&quot; and &quot;5xx errors by resource&quot; metrics unless you have explicitly enabled detailed CloudWatch"
      },
      "id": "617db3a028ccbc92a1801133"
    },
    {
      "sections": [
        "Azure API Management monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "API Management Service data"
      ],
      "title": "Azure API Management monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b4592ae87ea541c9673052fe5c9ee2392ab4926e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/microsoft-azure-integrations/azure-integrations-list/azure-api-management-monitoring-integration/",
      "published_at": "2021-12-25T15:28:43Z",
      "updated_at": "2021-10-23T17:36:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your Microsoft Azure API Management data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable the integration follow standard procedures to activate your Azure service in New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Azure API Management integration: New Relic polling interval: 5 minutes View and use data To view your integration data, go to one.newrelic.com > Infrastructure > Azure and select an integration. Data is attached to the following event type: Entity Event type Provider Service AzureApiManagementServiceSample AzureApiManagementService For more on how to use your data, see Understand and use integration data. Metric data This integration collects Azure API Management data for Service. API Management Service data Metric Unit Description totalRequests Count The total number of gateway requests in a given period. successfulRequests Count The total number of successful gateway requests in a given period. unauthorizedRequests Count The total number of unauthorized gateway requests in a given period. failedRequests Count The total number of failed gateway requests in a given period. otherRequests Count The total number of gateway requests in a given period that do not fall into the successful, unauthorized, or failed categories. durationMilliseconds Milliseconds The time between when API Management receives a request from a client and when it returns a response to the client. capacityPercent Percent Indicator of load on an API Management instance. eventHubTotalEvents Count The total number of events sent to EventHub from API Management in a given period. eventHubSuccessfulEvents Count The total number of successful EventHub events in a given period. eventHubTotalFailedEvents Count The total number of failed EventHub events in a given period. eventHubRejectedEvents Count The total number of rejected EventHub events (wrong configuration or unauthorized) in a given period. eventHubThrottledEvents Count The total number of throttled EventHub events in a given period. eventHubTimedoutEvents Count The total number of timed out EventHub events in a given period. eventHubDroppedEvents Count The total number of events skipped because of queue size limit reached in a given period. eventHubTotalBytesSentBytes Bytes The total size of EventHub events in bytes in a given period.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 89.15464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Azure <em>API</em> Management monitoring integration",
        "sections": "<em>API</em> Management Service <em>data</em>",
        "body": " Azure <em>API</em> Management <em>data</em> for Service. <em>API</em> Management Service <em>data</em> Metric Unit Description totalRequests Count The total number of <em>gateway</em> requests in a given period. successfulRequests Count The total number of successful <em>gateway</em> requests in a given period. unauthorizedRequests Count The total"
      },
      "id": "617da8f428ccbcc09f7ff203"
    },
    {
      "sections": [
        "Alerts and applied intelligence notification integrations",
        "Early access",
        "Integration details",
        "Atlassian Jira",
        "Permissions",
        "Set up a Jira destination",
        "Important",
        "Two-way sync",
        "Configure the message template",
        "Send a test notification",
        "ServiceNow (Incident-Management)",
        "Roles",
        "Set up a destination",
        "Slack",
        "Prerequisites",
        "Set up a Slack destination",
        "Configure the Slack message settings",
        "Webhook",
        "Set up a webhook destination",
        "Configure the webhook event template",
        "Customize the webhook payload",
        "Email",
        "Configure the email settings"
      ],
      "title": "Alerts and applied intelligence notification integrations",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident Intelligence",
        "Destinations"
      ],
      "external_id": "7220c630fc187bb61784ff2cc2213e588b269b00",
      "image": "https://docs.newrelic.com/static/d4e9baecc3a76dd1a5945f8ec0aeca66/c1b63/webhook-notification-template.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/notification-integrations/",
      "published_at": "2021-12-25T04:31:39Z",
      "updated_at": "2021-12-19T15:28:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Alerts and Applied Intelligence notification integrations are specific services and platforms you can use to send notifications from New Relic. Integration details Read more about each of our specific notification integrations. Atlassian Jira Integrate New Relic with Atlassian Jira(Cloud) and automatically create and update Jira issues. Permissions The required permissions from the Jira API-Token are create, edit, and close tickets. To enable the two-way sync toggle, the provided Jira API-Key should have an Admin role. Set up a Jira destination Create Jira issues, then enable Jira and New Relic to share updates and stay synced. To create a Jira destination, enter the following information: Destination name: Custom name to identify the destination Jira account endpoint: the URL of the destination User-name: this will be the email address of the user making the connection API token: generated from your Atlassian account Important New Relic currently supports Atlassian-Jira Classic (company-managed) projects. Before saving the destination, we recommend you test the connection via the test connection button. Jira destination configuration. We recommand to test the connection before saving. Two-way sync You can enable a two-way integration with Jira to keep the issues' state synced with the corresponding state in New Relic. To enable two-way sync, turn on the ‘two-way integration’ toggle. When turned on, a Jira Webhook would be created in your Jira account at a later stage, for the selected project (see ‘customize a message template’). The webhook would contain access details to Newrelic (URL and Newrelic-API-KEY) Configure the message template To configure a template for a Jira issue, you first need to choose a destination. You will be able to create a new destination at this stage. Upon successful connection to the destination, you will need to choose a project, and then select the Jira issue type you would like to be used. Once the issue-type is selected, the configured project's fields are fetched from your account and automatically mapped to your Jira instance. To help you get started, we automatically present the required and recommended fields and values. Required fields must be set with a value. You can add or remove optional fields(use the X mark on their right side) Jira message template. Send a test notification You can see how the JIRA issue will appear by clicking a test notification with default field values. If successful, a JIRA issue will be created and a link will appear. ServiceNow (Incident-Management) Integrate New Relic with ServiceNow Incident-Management and automatically create and update incidents. Roles As part of the integrations, we fetch fields from the your serviceNow incident table and optional values. For this, the provided ServiceNow user details required read permissions for the tables: sys_dictionary, sys_choice, sys_user and task. A read/write permission to incident To be able to fetch users for the caller column, we required read permissions for the sys_users table. The above permissions can be achieved with the roles personalize_choices, personalize_dictionary, rest_service, itil. Read/Write permissions to the api_key_credentials table is required to enable two-way integration. This can be covered with the roles credentials_admin and discovery_admin. Set up a destination To create a ServiceNow destination, enter the following information: Destination Name: custom name to identify the destination Domain: the URL of the destination User-name: the name of the user Password: the user name’s password Before saving the destination, we recommend testing the connection by clicking the test connection button. Two-way sync You can configure a two-way integration with ServiceNow Incidents Management to keep the incidents' state synced with the corresponding state in New Relic. Here are some required steps to remember when configuring the two-way integration: Turn on the two-way integration toggle. Open and download this XML file, which includes the business rule triggering events back to New Relic One. In the ServiceNow sidebar menu, go to System Definition > Business Rules. Click the menu icon in one of the column headers, select Import XML and upload the XML file you downloaded. Once the Destination is saved, a New-Relic API-Key will be kept in the api_key_credentials. The key would sent in a header as part of the callback REST call to New-Relic Configure the message template Upon a successful connection, ServiceNow incident table columns are fetched from your account and automatically mapped to your ServiceNow instance. To help you get started, we automatically present the required and recommended fields and values. Required fields must be set with a value. You can add or remove optional fields(use the X mark on their right side) Select, edit or remove fields for the ServiceNow-Incident template. Send a test notification You can see how the ServiceNow incident will appear by clicking a test notification with default field values. If successful, an incident will be created and a link will appear. Slack Send notifications-messages to your Slack channels. Prerequisites Your Slack workspace needs to have the New Relic application installed. The application must be approved by a workspace admin before it can be individually installed by users Set up a Slack destination Click on the `one-click Slack authentication' will lead you to the Slack landing page to continue the OAuth2 authentication process. On the Slack landing page, if you're not signed into the required workspace, you're redirected to Slack to sign in. Add your workspace name or select the relevant workspace and click Continue. When signed in to the selected workspace, you are requested to allow New Relic to perform the specified actions. Clicking `Allow' will redirect you back to the Destination page. Configure the Slack message settings Select a Destination(Workspace) and select a Slack-channel where the messages will be sent. You can create a new destination if there is no pre-defined destination for the required workspace. Note that, for privacy reasons, users need to be authenticated to select private channels (one-time process) Send a test notification You can send a test notification with a pre-defined example payload to the channel. This creates a message in the selected Slack-channel. Webhook Use the webhook notifier to send the notification messages to any endpoint you like. Set up a webhook destination To create a webhook destination, you need the following: Destination Name: A unique destination name URL: the endpoint of the target application, authentication and custom headers if needed. Authorization mechanism (Optional):. Can be basic authentication or a bearer token Configure the webhook event template Pick a webhook destination from the list and configure the HTTP-POST request. The request configuration requires you to: Set a name for the template. Select a pre-configured destination from the destinations list or create a new one. Add custom headers (optional). Configure the request’s payload. Customize the webhook payload You can use the default payload or customize it to contain the required data. Pick Variables from the variables menu and apply handlebars syntax to enrich your webhook. Note that the request’s content-type is JSON by default. Hence, the payload needs to keep the JSON form. See Usage examples The ‘preview’ section on the right hand-side shows an expected payload after the template is rendered. If the eventual payload would not form a valid Json, an error will be shown and it won’t be possible to save the template. If the webhook payload conforms a valid Json, you can send a test notification to your defined webhook destination We recommend sending a test notification to make sure that everything's connected correctly. Email Send email notifications to users. Configure the email settings Add one or more recipients. Users with New Relic accounts can be found via autocomplete when searching for their name or email address. To add a user without a New Relic account or email distribution list, add the full email address. Every recipient will be translated into a 'destination'. You can follow the email notifications per destination in the notifications-log Send a test notification You can send a test notification to make sure the email notifications reach the inbox.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 81.55428,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Important</em>",
        "body": " notifications. Alerts and Applied Intelligence notification integrations are specific services and <em>platforms</em> you can use to send notifications <em>from</em> New Relic. Integration details Read more about each of our specific notification integrations. Atlassian Jira Integrate New Relic with Atlassian Jira(Cloud"
      },
      "id": "618ff71628ccbc60710321e4"
    }
  ],
  "/docs/glossary/glossary": [
    {
      "sections": [
        "Choose your data center (US or EU)",
        "Requirements",
        "Regions and availability",
        "Regions and account hierarchy",
        "Hierarchy example for partnership accounts",
        "Create an EU region account",
        "API endpoints for EU region accounts",
        "Access New Relic One",
        "Billing and pricing",
        "Operational access and processing",
        "Verify your account is based in EU region"
      ],
      "title": "Choose your data center (US or EU)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "58aede83cf1625a8a52aaeed540cebfbaa024d61",
      "image": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/choose-your-data-center/images/Eu_account_hierarchy.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/choose-your-data-center/",
      "published_at": "2021-12-25T02:43:04Z",
      "updated_at": "2021-12-14T04:22:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's global data hosting structure consists of two regions: the European Union (EU) region and the United States (US) region. Selecting your preferred region during the account setup process allows you to specify the region where your performance monitoring data will be hosted. You can also create accounts in each region. Requirements Access to the New Relic EU region requires the latest agent version. For new customers: Install the most recent agent version. For existing customers: Update to the most recent agent version. Minimum agent version required: C SDK 1.0.0 or higher Go 2.0.0 or higher Java 4.0.0 or higher .NET 8.0.0 or higher Node.js 3.0.0 or higher PHP 8.0.0.204 or higher Python 3.0.0.89 or higher Ruby 5.0.0.342 or higher Regions and availability Your choice of data center is not limited by your geographic location. You can choose to create an account with data hosted in either the EU or US region, regardless of where you or your systems reside. You can also create accounts in each region. New Relic offers almost all the same active products, features, support offerings, and performance levels in the EU region as what is offered in the US region. Exceptions: The following are not supported with an EU region account: Infinite Tracing is not available. APM's weekly performance reports are not available. Errors inbox is not available. Log patterns Deprecated products and features are not available. New Relic's Incident Intelligence service operates solely in the US whether you store your data in New Relic’s US region data center or New Relic’s EU region data center, by using New Relic Incident Intelligence, you consent that New Relic may move and store your data in the US region. New Relic CodeStream operates solely in the US. Whether you have selected New Relic's US or EU region data center during setup of your New Relic account, when using New Relic CodeStream, you consent that your New Relic CodeStream data will get stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted in the US region, you must create a new account to store data in the EU region. You cannot view EU data from a US account, or US data from an EU account. The data collected remains separate. The data cannot be aggregated or migrated between accounts. For organizations that have a parent/child account structure, you can only have one parent account. For more, see Manage apps or users with child accounts. For partnership accounts, no changes to the partnership owner account are required. However, data cannot be shared across regions, so a partnership requires a parent account for each region. Hierarchy example for partnership accounts With partnership accounts, a new parent account must be created for any data to be host in the EU region. This hierarchy illustrates how global accounts are structured with partnership owner accounts. Data is not aggregated beyond the parent account. Example hierarchy for partnership organizations. Because data cannot be shared across regions, a partnership will require a parent account for each region. Create an EU region account To create a New Relic account in the EU region: Go to the New Relic signup page. OR If you have a specific offer from a New Relic partner, follow that link directly. Follow the online steps to create your account. From the Select your region dropdown, select European Union. Agree to the Terms of Service. When you receive an email confirmation message, select the link to confirm your account and sign in to New Relic. Then install or update to the most recent agent version. API endpoints for EU region accounts If you have an EU region account, use the appropriate endpoints to access the following New Relic APIs: API EU endpoint Browser source maps API sourcemaps.service. eu .newrelic.com Copy Infrastructure Alert API infra-api. eu .newrelic.com Copy Dashboard API rpm. eu .newrelic.com/api/explore/dashboards/list Copy Insert API insights-collector. eu01 .nr-data.net Copy Insights Query API insights-api. eu .newrelic.com Copy Mobile apps rpm. eu .newrelic.com/mobile Copy NerdGraph GraphiQL API api. eu .newrelic.com/graphiql Copy Partner API The partner API is a global API with no regional data differences. Use this endpoint for both EU and US accounts: rpm.newrelic.com/api/v2/partners/ Copy REST API api. eu .newrelic.com Copy Synthetics API synthetics. eu .newrelic.com/synthetics/api Copy Trace API trace-api. eu .newrelic.com/trace/v1 Copy Metric API metric-api. eu .newrelic.com/metric/v1 Copy Log API log-api. eu .newrelic.com/log/v1 Copy Access New Relic One If your accounts report data to the EU data center, use the following link to go to New Relic One: one.eu.newrelic.com. Billing and pricing New Relic's account billing process and pricing options are the same for both the EU and US regions. Operational access and processing Customer Data is hosted in the region selected during account creation. Systems Operations Data is stored in the US region. All other information, including account information (such as license subscription information, billing, and internal monitoring) is hosted in the US region and replicated in the EU region. New Relic may access and process Customer Data in the United States and such other jurisdictions where New Relic has affiliates and subsidiaries, including as may be necessary to maintain, secure, or perform the services, to provide technical support, or as necessary to comply with law or a binding order of a government body. Customer Data from existing New Relic accounts cannot be transferred or shared across regions, and new data generated cannot be shared with existing accounts, even in partnership accounts. Verify your account is based in EU region Use either of these options to verify whether your account data is hosted in the EU region's data center: In APM, mouse over the application name to view the URL. If it begins with rpm.eu.newrelic.com/, it is an EU-based account. Check your New Relic license key. If it begins with EU, it is an EU-based account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.03772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Access <em>New</em> <em>Relic</em> One",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " <em>New</em> <em>Relic</em>&#x27;s US or EU region data center during setup of your <em>New</em> <em>Relic</em> account, when <em>using</em> <em>New</em> <em>Relic</em> CodeStream, you consent that your <em>New</em> <em>Relic</em> CodeStream data will <em>get</em> stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted"
      },
      "id": "61b81bf6e7b9d2a96fef4e3a"
    },
    {
      "sections": [
        "Find help and use the Support portal",
        "Ask in New Relic's Explorers Hub, our free forum",
        "Run the New Relic Diagnostics tool",
        "Find answers in New Relic Docs and New Relic University",
        "Contribute to our documentation",
        "Don't find what you need? File a documentation issue",
        "File a ticket in the support portal",
        "Important",
        "Check the status of our systems",
        "Licenses and security information"
      ],
      "title": "Find help and use the Support portal",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "ce14a732f0aae92aa495e61aac701f6880378a3d",
      "image": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/find-help-use-support-portal/images/new-relic-explorers-hub.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/find-help-use-support-portal/",
      "published_at": "2021-12-25T05:19:12Z",
      "updated_at": "2021-12-14T04:10:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of support options, including online help, a troubleshooting tool, open source documentation with detailed procedures and troubleshooting tips, and support assistance. Ask in New Relic's Explorers Hub. Run the New Relic Diagnostics tool. Find answers in New Relic Docs and New Relic University. Contribute to our documentation. Don't find what you need? File a documentation issue. File a ticket in the support portal. Check the status of our systems. Read about our licenses, data security, and compliance information. Ask in New Relic's Explorers Hub, our free forum New Relic's Explorer Hub is our forum that's free for all users. New Relic users and employees engage every day in conversations to troubleshoot and solve issues, find workarounds, and discuss new features. discuss.newrelic.com: The Explorer Hub is our public forum. Use it to ask questions and find answers. Join our community of users to learn more about New Relic and get some inspiration. Run the New Relic Diagnostics tool New Relic Diagnostics is our automated diagnostic tool for Linux, Windows, and Mac. If it detects a problem with any of our agents, it suggests solutions and saves troubleshooting logs that you can attach to tickets. Find answers in New Relic Docs and New Relic University New Relic's docs site contains helpful installation, configuration, and troubleshooting tips. From the main page, select from frequently-used categories and topics, like release notes. Or, search from any page. For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. Contribute to our documentation Our documentation is open source and available in GitHub, and we encourage you to contribute! We really care about ensuring our docs are helpful, complete, and accurate. To edit a page, click the Edit page button in any document to create a pull request with the edit you think is needed. We don't want you to worry about style. When you edit a file, tech writers on our team review it for style, grammar, and formatting. docs.newrelic.com: At the right-hand side of each page you'll find a feedback widget. Use it to tell us whether a page is helpful, create an issue, or edit the page. Don't find what you need? File a documentation issue If you can't find an answer in the documentation, you can file an issue to ask us for help. When you find places the docs could be better, let us know too! To do it, click the Create issue button in any document and we'll look into your problem to find a solution. docs.newrelic.com: At the right-hand side of each page you'll find a feedback widget. Use it to tell us whether a page is helpful, create an issue, or edit the page. File a ticket in the support portal If none of the above methods worked, go to support.newrelic.com. The Support portal gives you access to unified search across all of New Relic's help resources. If you can't find what you are looking for and your subscription level includes technical support, you can file a support ticket. Important Support for beta or limited release features may not be available. To file a new ticket: Go to support.newrelic.com > Login. From the Support portal, select the area of New Relic where you need help. Select your account. Provide as many details as possible. Include the URL, if applicable, or select Attach file to include a log file, a New Relic Diagnostics file, screenshots, or other useful attachments. Click Submit. Check the status of our systems It's always a good idea to visit status.newrelic.com to check the status of our systems. If there are open incidents, you'll be able to find more information. Licenses and security information Review New Relic's licenses, attributions, and other notices. Read about our data security, privacy, and compliance policies.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.00523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find help and <em>use</em> the Support portal",
        "sections": "Ask in <em>New</em> <em>Relic&#x27;s</em> Explorers Hub, our free forum",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " <em>Relic</em>&#x27;s Explorer Hub is our forum that&#x27;s free for all users. <em>New</em> <em>Relic</em> users and employees engage every day in conversations to troubleshoot and solve issues, find workarounds, and discuss <em>new</em> features. discuss.newrelic.com: The Explorer Hub is our public forum. <em>Use</em> it to ask questions and find"
      },
      "id": "603eb6b5e7b9d299072a07e5"
    },
    {
      "sections": [
        "View our UI in dark mode",
        "Switch between light and dark mode"
      ],
      "title": "View our UI in dark mode",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "b36ae1720e821d90136751f9a2f90d3d1f030c16",
      "image": "https://docs.newrelic.com/static/cbbd29dd03ca29a197b3cee88707141b/c1b63/APM_distributed_tracing_dark-Mode.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/view-our-ui-dark-mode/",
      "published_at": "2021-12-25T14:33:33Z",
      "updated_at": "2021-12-14T03:44:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're checking on incidents in the middle of the night, or just want to avoid straining your eyes, you can view our UI in dark mode. To switch between light mode and dark mode in New Relic's UI, click the account dropdown. Switch between light and dark mode To view our UI in dark mode: From one.newrelic.com, click the account dropdown. [ NOTE: Currently dark mode is not supported in the Firefox browser.] Click Theme: to switch between the following options: Theme: auto (default): matches the UI with what you already have enabled with your OS. Theme: dark: keeps the UI in dark mode. Theme: light: keeps the UI in light mode.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.93213,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": "When you&#x27;re checking on incidents in the middle of the night, or just want to avoid straining your eyes, you can view our UI in dark mode. To switch between light mode and dark mode in <em>New</em> <em>Relic</em>&#x27;s UI, click the account dropdown. Switch between light and dark mode To view our UI in dark mode: From"
      },
      "id": "603e987964441ff7db4e8876"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-cognito-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45949,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00551,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-sqs-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-transit-gateway-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-albnlb-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-athena-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-auto-scaling-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45879,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01091,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudfront-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45879,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01091,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0109,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00543,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-25T07:36:42Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.67224,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-connect-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.4586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0109,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00543,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-direct-connect-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-documentdb-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-dynamodb-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ebs-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01085,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-25T07:36:42Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.67223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-efs-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01085,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00539,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elastic-beanstalk-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elasticache-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01082,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elb-classic-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01082,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elemental-mediaconvert-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01082,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elemental-mediapackage-vod-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0108,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-emr-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0108,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-fsx-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45735,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-glue-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45735,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01079,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45718,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01077,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00531,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-iam-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45718,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01077,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00531,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-iot-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-analytics-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-firehose-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-streams-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45682,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45682,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-managed-kafka-msk-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-25T07:36:42Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.67218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-mq-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45647,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01071,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-neptune-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45647,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01071,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-qldb-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45647,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01071,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-rds-enhanced-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0107,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-rds-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0107,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-redshift-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45612,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-route-53-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45612,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-route53-resolver-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45593,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45593,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-simple-email-service-ses-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45593,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-sns-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45575,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01065,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00519,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-step-functions-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45575,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01065,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00519,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-trusted-advisor-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00517,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-vpc-flow-logs-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00517,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.4554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01062,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-waf-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.4554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.01062,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-x-ray-monitoring-integration": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.45522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "sections": "<em>AWS</em> CloudTrail monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your <em>AWS</em> CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.0106,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-25T07:23:50Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.00514,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/rate-limit-alerts-amazon": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2021-12-25T15:19:19Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.99347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.67143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-25T12:39:43Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.66352,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/aws-integrations-metrics": [
    {
      "sections": [
        "Introduction to Azure monitoring integrations",
        "Requirements",
        "Features",
        "Cost considerations"
      ],
      "title": "Introduction to Azure monitoring integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "7ce4149eca2602fa1a29c921fa8876ad96abd254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/microsoft-azure-integrations/get-started/introduction-azure-monitoring-integrations/",
      "published_at": "2021-12-25T13:06:55Z",
      "updated_at": "2021-12-25T13:06:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Microsoft Azure integrations allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure integrations are not the same as APM's .NET support for Azure. Requirements Check the Azure integrations documentation for requirements on individual integrations. New Relic cannot obtain monitoring data from resources that are located in Azure Government or that were created through the classic deployment model. Features After you activate your Azure integration, New Relic begins to query your Azure platform services according to a regular polling interval. You can use our integrations UI to: View performance data from Integrations dashboards that automatically scale as you make changes to your ecosystem. Manage alert conditions with alerts. Query your data. Cost considerations When evaluating the cost of the Microsoft Azure integrations with New Relic, consider Azure's Monitor Pricing. Refer to the \"Metric queries\" cost item in the Azure pricing documentation. Pricing is based on the number of API calls per month. An estimation of the API calls peformed by New Relic to the different Azure services can be seen in the UI, under Infrastructure > Azure > Azure Status Dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.58,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Azure monitoring <em>integrations</em>",
        "sections": "Introduction to Azure monitoring <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "Our Microsoft Azure <em>integrations</em> allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure <em>integrations</em> are not the same as APM&#x27;s .NET support for Azure. Requirements Check the Azure <em>integrations</em>"
      },
      "id": "617d53f828ccbcd2fd7ffaf2"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-25T06:06:13Z",
      "updated_at": "2021-12-25T06:06:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags APM agents APM agent configuration Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.34851,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Get</em> <em>started</em>",
        "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can <em>get</em> <em>started</em> with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.4088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic": [
    {
      "sections": [
        "Introduction to Azure monitoring integrations",
        "Requirements",
        "Features",
        "Cost considerations"
      ],
      "title": "Introduction to Azure monitoring integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "7ce4149eca2602fa1a29c921fa8876ad96abd254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/microsoft-azure-integrations/get-started/introduction-azure-monitoring-integrations/",
      "published_at": "2021-12-25T13:06:55Z",
      "updated_at": "2021-12-25T13:06:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Microsoft Azure integrations allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure integrations are not the same as APM's .NET support for Azure. Requirements Check the Azure integrations documentation for requirements on individual integrations. New Relic cannot obtain monitoring data from resources that are located in Azure Government or that were created through the classic deployment model. Features After you activate your Azure integration, New Relic begins to query your Azure platform services according to a regular polling interval. You can use our integrations UI to: View performance data from Integrations dashboards that automatically scale as you make changes to your ecosystem. Manage alert conditions with alerts. Query your data. Cost considerations When evaluating the cost of the Microsoft Azure integrations with New Relic, consider Azure's Monitor Pricing. Refer to the \"Metric queries\" cost item in the Azure pricing documentation. Pricing is based on the number of API calls per month. An estimation of the API calls peformed by New Relic to the different Azure services can be seen in the UI, under Infrastructure > Azure > Azure Status Dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.5799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Azure monitoring <em>integrations</em>",
        "sections": "Introduction to Azure monitoring <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "Our Microsoft Azure <em>integrations</em> allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure <em>integrations</em> are not the same as APM&#x27;s .NET support for Azure. Requirements Check the Azure <em>integrations</em>"
      },
      "id": "617d53f828ccbcd2fd7ffaf2"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-25T06:06:13Z",
      "updated_at": "2021-12-25T06:06:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags APM agents APM agent configuration Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.348434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Get</em> <em>started</em>",
        "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can <em>get</em> <em>started</em> with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.40871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring": [
    {
      "sections": [
        "Introduction to Azure monitoring integrations",
        "Requirements",
        "Features",
        "Cost considerations"
      ],
      "title": "Introduction to Azure monitoring integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "7ce4149eca2602fa1a29c921fa8876ad96abd254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/microsoft-azure-integrations/get-started/introduction-azure-monitoring-integrations/",
      "published_at": "2021-12-25T13:06:55Z",
      "updated_at": "2021-12-25T13:06:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Microsoft Azure integrations allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure integrations are not the same as APM's .NET support for Azure. Requirements Check the Azure integrations documentation for requirements on individual integrations. New Relic cannot obtain monitoring data from resources that are located in Azure Government or that were created through the classic deployment model. Features After you activate your Azure integration, New Relic begins to query your Azure platform services according to a regular polling interval. You can use our integrations UI to: View performance data from Integrations dashboards that automatically scale as you make changes to your ecosystem. Manage alert conditions with alerts. Query your data. Cost considerations When evaluating the cost of the Microsoft Azure integrations with New Relic, consider Azure's Monitor Pricing. Refer to the \"Metric queries\" cost item in the Azure pricing documentation. Pricing is based on the number of API calls per month. An estimation of the API calls peformed by New Relic to the different Azure services can be seen in the UI, under Infrastructure > Azure > Azure Status Dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.5799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Azure monitoring <em>integrations</em>",
        "sections": "Introduction to Azure monitoring <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "Our Microsoft Azure <em>integrations</em> allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure <em>integrations</em> are not the same as APM&#x27;s .NET support for Azure. Requirements Check the Azure <em>integrations</em>"
      },
      "id": "617d53f828ccbcd2fd7ffaf2"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-25T06:06:13Z",
      "updated_at": "2021-12-25T06:06:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags APM agents APM agent configuration Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.348434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Get</em> <em>started</em>",
        "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can <em>get</em> <em>started</em> with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.40871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/integrations-managed-policies": [
    {
      "sections": [
        "Introduction to Azure monitoring integrations",
        "Requirements",
        "Features",
        "Cost considerations"
      ],
      "title": "Introduction to Azure monitoring integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "7ce4149eca2602fa1a29c921fa8876ad96abd254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/microsoft-azure-integrations/get-started/introduction-azure-monitoring-integrations/",
      "published_at": "2021-12-25T13:06:55Z",
      "updated_at": "2021-12-25T13:06:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Microsoft Azure integrations allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure integrations are not the same as APM's .NET support for Azure. Requirements Check the Azure integrations documentation for requirements on individual integrations. New Relic cannot obtain monitoring data from resources that are located in Azure Government or that were created through the classic deployment model. Features After you activate your Azure integration, New Relic begins to query your Azure platform services according to a regular polling interval. You can use our integrations UI to: View performance data from Integrations dashboards that automatically scale as you make changes to your ecosystem. Manage alert conditions with alerts. Query your data. Cost considerations When evaluating the cost of the Microsoft Azure integrations with New Relic, consider Azure's Monitor Pricing. Refer to the \"Metric queries\" cost item in the Azure pricing documentation. Pricing is based on the number of API calls per month. An estimation of the API calls peformed by New Relic to the different Azure services can be seen in the UI, under Infrastructure > Azure > Azure Status Dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.5798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Azure monitoring <em>integrations</em>",
        "sections": "Introduction to Azure monitoring <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "Our Microsoft Azure <em>integrations</em> allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure <em>integrations</em> are not the same as APM&#x27;s .NET support for Azure. Requirements Check the Azure <em>integrations</em>"
      },
      "id": "617d53f828ccbcd2fd7ffaf2"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-25T06:06:13Z",
      "updated_at": "2021-12-25T06:06:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags APM agents APM agent configuration Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.34834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Get</em> <em>started</em>",
        "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can <em>get</em> <em>started</em> with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.408615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations": [
    {
      "sections": [
        "Introduction to Azure monitoring integrations",
        "Requirements",
        "Features",
        "Cost considerations"
      ],
      "title": "Introduction to Azure monitoring integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "7ce4149eca2602fa1a29c921fa8876ad96abd254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/microsoft-azure-integrations/get-started/introduction-azure-monitoring-integrations/",
      "published_at": "2021-12-25T13:06:55Z",
      "updated_at": "2021-12-25T13:06:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Microsoft Azure integrations allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure integrations are not the same as APM's .NET support for Azure. Requirements Check the Azure integrations documentation for requirements on individual integrations. New Relic cannot obtain monitoring data from resources that are located in Azure Government or that were created through the classic deployment model. Features After you activate your Azure integration, New Relic begins to query your Azure platform services according to a regular polling interval. You can use our integrations UI to: View performance data from Integrations dashboards that automatically scale as you make changes to your ecosystem. Manage alert conditions with alerts. Query your data. Cost considerations When evaluating the cost of the Microsoft Azure integrations with New Relic, consider Azure's Monitor Pricing. Refer to the \"Metric queries\" cost item in the Azure pricing documentation. Pricing is based on the number of API calls per month. An estimation of the API calls peformed by New Relic to the different Azure services can be seen in the UI, under Infrastructure > Azure > Azure Status Dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.5798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Azure monitoring <em>integrations</em>",
        "sections": "Introduction to Azure monitoring <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "Our Microsoft Azure <em>integrations</em> allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure <em>integrations</em> are not the same as APM&#x27;s .NET support for Azure. Requirements Check the Azure <em>integrations</em>"
      },
      "id": "617d53f828ccbcd2fd7ffaf2"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-25T06:06:13Z",
      "updated_at": "2021-12-25T06:06:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags APM agents APM agent configuration Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.34834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Get</em> <em>started</em>",
        "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can <em>get</em> <em>started</em> with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.408615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/polling-intervals-aws-integrations": [
    {
      "sections": [
        "Introduction to Azure monitoring integrations",
        "Requirements",
        "Features",
        "Cost considerations"
      ],
      "title": "Introduction to Azure monitoring integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "7ce4149eca2602fa1a29c921fa8876ad96abd254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/microsoft-azure-integrations/get-started/introduction-azure-monitoring-integrations/",
      "published_at": "2021-12-25T13:06:55Z",
      "updated_at": "2021-12-25T13:06:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Microsoft Azure integrations allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure integrations are not the same as APM's .NET support for Azure. Requirements Check the Azure integrations documentation for requirements on individual integrations. New Relic cannot obtain monitoring data from resources that are located in Azure Government or that were created through the classic deployment model. Features After you activate your Azure integration, New Relic begins to query your Azure platform services according to a regular polling interval. You can use our integrations UI to: View performance data from Integrations dashboards that automatically scale as you make changes to your ecosystem. Manage alert conditions with alerts. Query your data. Cost considerations When evaluating the cost of the Microsoft Azure integrations with New Relic, consider Azure's Monitor Pricing. Refer to the \"Metric queries\" cost item in the Azure pricing documentation. Pricing is based on the number of API calls per month. An estimation of the API calls peformed by New Relic to the different Azure services can be seen in the UI, under Infrastructure > Azure > Azure Status Dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.5798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Azure monitoring <em>integrations</em>",
        "sections": "Introduction to Azure monitoring <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "Our Microsoft Azure <em>integrations</em> allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure <em>integrations</em> are not the same as APM&#x27;s .NET support for Azure. Requirements Check the Azure <em>integrations</em>"
      },
      "id": "617d53f828ccbcd2fd7ffaf2"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-12-25T06:06:13Z",
      "updated_at": "2021-12-25T06:06:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can get started with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags APM agents APM agent configuration Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Service Levels Configure and manage Service Levels Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing model) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.34834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Get</em> <em>started</em>",
        "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. After you sign up for a free New Relic account and install any of our monitoring services, you can <em>get</em> <em>started</em> with NerdGraph. What is NerdGraph? New Relic has several APIs. NerdGraph"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.408615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2021-12-25T15:19:19Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.99338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.67116,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-25T12:39:43Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.66351,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2021-12-25T15:19:19Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.99338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.67116,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "CloudWatch billing increase",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "CloudWatch billing increase",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "f4618f822e6076e80c856b99f67d61928f89c498",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-10-23T10:52:09Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After setting up New Relic Infrastructure Amazon integrations, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you need to manage your Amazon CloudWatch bill, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you need to manage your Amazon CloudWatch bill, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, contact your New Relic account representative or get support at support.newrelic.com. Cause New Relic Infrastructure Amazon integrations leverage CloudWatch to gather metrics. AWS charges joint customers for requests that exceed the first one million per month. CloudWatch billing issues may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.064224,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After setting up New Relic Infrastructure <em>Amazon</em> <em>integrations</em>, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account&#x27;s ARN Ensure that you are not collecting inventory information for the wrong ARN"
      },
      "id": "617dc45064441fe773fbe7f5"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/cannot-create-alert-condition-infrastructure-integration": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2021-12-25T15:19:19Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.99335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.67107,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-25T12:39:43Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.66351,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2021-12-25T15:19:19Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.99335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.67107,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-25T12:39:43Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.66351,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/invalid-principal-error-unsupported-aws-regions": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2021-12-25T15:19:19Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.99335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.67107,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-25T12:39:43Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.66351,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations": [
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.670975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-25T12:39:43Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.663506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    },
    {
      "sections": [
        "CloudWatch billing increase",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "CloudWatch billing increase",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "f4618f822e6076e80c856b99f67d61928f89c498",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-10-23T10:52:09Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After setting up New Relic Infrastructure Amazon integrations, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you need to manage your Amazon CloudWatch bill, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you need to manage your Amazon CloudWatch bill, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, contact your New Relic account representative or get support at support.newrelic.com. Cause New Relic Infrastructure Amazon integrations leverage CloudWatch to gather metrics. AWS charges joint customers for requests that exceed the first one million per month. CloudWatch billing issues may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.06422,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After setting up New Relic Infrastructure <em>Amazon</em> <em>integrations</em>, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account&#x27;s ARN Ensure that you are not collecting inventory information for the wrong ARN"
      },
      "id": "617dc45064441fe773fbe7f5"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/no-data-appears-aws-integrations": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2021-12-25T15:19:19Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.99332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.670975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-25T12:39:43Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.663506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/no-data-metric-streams": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-25T07:33:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.6112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "sections": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " to 24 hours. Inventory: the Inventory page is not supported with AWS <em>CloudWatch</em> <em>metric</em> <em>streams</em> (inventory telemetry is not included in the <em>stream</em>). <em>Integrations</em> not fully replaced by <em>metric</em> <em>streams</em> The AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> integration only collects <em>CloudWatch</em> metrics, resource metadata"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-25T12:38:56Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.89417,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> integration is the recommended solution to monitor all <em>CloudWatch</em> metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "FedRAMP Moderate",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "FedRAMP Moderate",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "d321748f3edb0e29c3db0734405faa40f93de13f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/fedramp-moderate/",
      "published_at": "2021-12-25T19:33:32Z",
      "updated_at": "2021-12-14T20:36:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Federal Risk and Authorization Management Program (FedRAMP) is a U.S. Federal government program that provides a standardized approach to security assessment, authorization, and continuous monitoring for cloud products and services. The FedRAMP program has helped to accelerate the adoption of secure cloud solutions through the reuse of assessments and authorizations across government agencies. FedRAMP leverages a standardized set of requirements, established in accordance with the Federal Information Security Management Act (FISMA), to improve consistency and confidence in the security of cloud solutions. Cloud Service Providers (CSP) that support U.S. government customers or operate on U.S. government information are responsible for complying with the requirements established by the FedRAMP program. For more information, see our public sector solutions, or download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services FedRAMP Moderate 2021-OCT-08 AWS & First Party New Relic One Platform Services not in scope The following services are not FedRAMP-authorized: Last Updated Infrastructure Services N/A AWS Amazon CloudWatch Metric Streams Integration N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A AWS CodeStream N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and Customer Programmability: New Relic One apps N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.47919,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " platform: Document Last Updated Infrastructure Services FedRAMP Moderate 2021-OCT-08 AWS &amp; First Party New Relic One Platform Services not in scope The following services are not FedRAMP-authorized: Last Updated Infrastructure Services N&#x2F;A AWS <em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> Integration N&#x2F;A GCP AI Ops"
      },
      "id": "61865459e7b9d24a35c2bacd"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/partial-or-missing-logs-rds-vpc-aws-lambda": [
    {
      "sections": [
        "Metric data delays in Amazon AWS integrations",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Metric data delays in Amazon AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "44204fb4ad7ec74ff82ad9c3858dd35b46e5137f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations/",
      "published_at": "2021-12-25T15:19:19Z",
      "updated_at": "2021-12-15T05:17:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You notice delays between the time your AWS integration makes an API request and New Relic Infrastructure returns the metric data. Solution Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. For more on this cause, see Cause. Normally, the delays do not sum up. With an explicit delay, New Relic expects the metric data to be at the delay point in time. For example, if New Relic uses an explicit delay of five minutes, at 9:00 the freshest data point should be the one for 8:55. However, delays may vary by customer and account. If you experience unusual delays in your metric data: Check whether your Infrastructure integration has explicit delays or implicit delays with API requests for metric data. CloudWatch users: Take a screenshot of the metric data in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console's screenshot, New Relic Support will troubleshoot if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the Amazon AWS integration, New Relic Infrastructure may experience explicit delays or implicit delays in the timing between the API request and the metric data returned. Metric data delays Comments Explicit delays (specifically set) Explicit delays are the ones that New Relic sets in the code to get more reliable data. In some cases, the API request to AWS may return one value, but a request for the same metric a minute later returns a different value. To reduce the possibility of this occurring, New Relic sets explicit delays. For example: If New Relic uses an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:50 to 8:55. If New Relic does not use an explicit delay of five minutes, an API call at 9:00 requests metrics from 8:55 to 9:00. Explicit delays may come from these Infrastructure Amazon integrations: ALB: 5 minutes ELB: 5 minutes CloudFront: 1 minute RDS: 5 minutes SNS: 10 minutes Implicit delays (expected but not specifically set) Implicit delays are patterns that New Relic has experienced with integrations. They are not always present, and they are not exact. In general, implicit delays tend to come from requests for AWS CloudWatch metrics, including these Infrastructure Amazon integrations: DynamoDB: Approximately 1 minute EBS: Approximately 15 minutes EC2: Approximately 5 minutes ElastiCache: Approximately 5 minutes Lambda: Approximately 1 minute SQS: Approximately 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.99329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "sections": "Metric data delays in <em>Amazon</em> AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in your CloudWatch console, and attach it when you request support at support.newrelic.com. Using your CloudWatch console&#x27;s screenshot, New Relic Support will <em>troubleshoot</em> if the delay occurs in New Relic Infrastructure or directly in AWS. Cause Depending on the <em>Amazon</em> AWS integration, New Relic"
      },
      "id": "617dc482196a6798f6f7c482"
    },
    {
      "sections": [
        "AWS CloudTrail monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Event attributes",
        "Query examples",
        "Query example: Count of failed API calls",
        "Query example: Count of console login errors"
      ],
      "title": "AWS CloudTrail monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "92331f857ea7c1a5ffe372c00c32fe1cef5ddfc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration/",
      "published_at": "2021-12-25T15:18:25Z",
      "updated_at": "2021-12-25T15:18:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic integrations include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records AWS account activity, mainly for audit and governance purposes. New Relic's AWS CloudTrail integration collects events that represent errors and AWS console logins. Errors give you awareness about API calls and services that have failed, and console logins help you monitor console activity and potential intrusion attempts. Besides these two types of data, New Relic does not collect any other data. This is because other AWS CloudTrail data is already reported by New Relic in the form of inventory change events. Activate integration Important The AWS CloudTrail integration collects data from us-east-1 region only by default. To enable all AWS regions please contact us at support.newrelic.com. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS CloudTrail integration: New Relic polling interval: 5 minutes Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS CloudTrail integration links. This integration does not provide metric or inventory data: only event data. You can use Infrastructure's Events page to view a timeline of these events. You can query and explore your data using the InfrastructureEvent event type, with a provider value of CloudTrail. For general information about how to find and use integration data, see Understand integration data. Event attributes Here are attributes that can be reported with CloudTrail events: Metadata Description awsRegion The AWS region the request was made of. cloudTrailEventType Identifies the type of event that generated the event record. This can be the one of the following values: AwsApiCall, AwsServiceEvent, ConsoleSignin. errorCode The AWS service error (if the request returns an error). For a list of the most common errors, see the AWS CloudTrail documentation. errorMessage If the request returns an error, the description of the error. eventId The unique identifier of the event. eventName The requested action. eventSource The AWS service the request was made of. sourceIpAddress The IP address from which the request was made. userAgent The agent through which the request was made, such as the AWS Management Console, an AWS service, the AWS SDKs, or the AWS CLI. userName The user name or role name of the requester that called the API in the event returned. Query examples You can use New Relic to run queries of AWS CloudTrail data, and optionally use New Relic alerts to set alerts on that data. Query example: Count of failed API calls Query for a count of failed API calls, aggregated by the AWS service that the request was made to: SELECT count(*) from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsApiCall' FACET eventSource Copy Query example: Count of console login errors Query to find all console login errors: SELECT * from InfrastructureEvent WHERE provider = 'CloudTrail' AND cloudTrailEventType = 'AwsConsoleSignIn' AND errorMessage IS NOT NULL Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.67088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS CloudTrail monitoring <em>integration</em>",
        "sections": "AWS CloudTrail monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic <em>integrations</em> include an integration for reporting your AWS CloudTrail events to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS CloudTrail, which captures and records"
      },
      "id": "617da7ae64441f7e6afbd43a"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-25T12:39:43Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.663506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration": [
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-25T12:41:13Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.47656,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-25T12:41:12Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.42181,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    },
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-12-25T07:39:03Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.92467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "sections": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Retrieve logs via SSH (EC2 launch type only) To <em>get</em> logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your <em>container</em> instances. Find"
      },
      "id": "617db44c28ccbc965d80120d"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration": [
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-25T12:41:12Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.41139,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "3beb992f60db19bb5f3c8a3ebef2b5904f958be8",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-12-25T12:40:27Z",
      "updated_at": "2021-10-24T00:51:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.17924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "617db40c196a6792daf7c8b2"
    },
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-12-25T07:39:03Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.92467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "sections": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the <em>container</em> ID of the New Relic <em>integration</em> <em>container</em>, by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Save the logs from the <em>container</em> with the command docker logs NRI_ECS_<em>CONTAINER</em>_ID &gt; logs.txt. Leave the command running for about three minutes to generate sufficient"
      },
      "id": "617db44c28ccbc965d80120d"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration": [
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-25T12:41:13Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.47552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the ECS <em>integration</em>",
        "sections": "<em>Install</em> the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "3beb992f60db19bb5f3c8a3ebef2b5904f958be8",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-12-25T12:40:27Z",
      "updated_at": "2021-10-24T00:51:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.17924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "617db40c196a6792daf7c8b2"
    },
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-12-25T07:39:03Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.92467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "sections": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the <em>container</em> ID of the New Relic <em>integration</em> <em>container</em>, by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Save the logs from the <em>container</em> with the command docker logs NRI_ECS_<em>CONTAINER</em>_ID &gt; logs.txt. Leave the command running for about three minutes to generate sufficient"
      },
      "id": "617db44c28ccbc965d80120d"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs": [
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9cc7726bfac01b6d287c335f5a5d6705b168e7a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-12-25T12:41:59Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.79774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". <em>Troubleshoot</em> in the UI To use the UI to <em>troubleshoot</em>: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "617db44ce7b9d226b2c047e9"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-25T12:41:13Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.21617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-25T12:41:12Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.16083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears": [
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-12-25T07:39:03Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.28958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec <em>INTEGRATION_CONTAINER</em>_ID &#x2F;usr&#x2F;bin&#x2F;newrelic-infra-ctl Copy For more details, see <em>Troubleshoot</em> the agent. Save"
      },
      "id": "617db44c28ccbc965d80120d"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-25T12:41:13Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.21617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-25T12:41:12Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.16083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions": [
    {
      "sections": [
        "Understand and use ECS data",
        "View data",
        "Query your data"
      ],
      "title": "Understand and use ECS data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "6373cb619a787c0a22f4d91c954cd2a8d6ad3b41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/understand-use-data/understand-use-ecs-data/",
      "published_at": "2021-12-25T12:41:59Z",
      "updated_at": "2021-11-13T16:40:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Here we explain how to find, understand, and use the data reported by this integration. View data To view the ECS integration dashboard: Go to one.newrelic.com and select Explorer. On the left, search for ECS clusters, or type the name of your ECS cluster in the search bar. To view a dashboard, select the entity name corresponding to your ECS cluster. In addition to the pre-built dashboards, you can also create your own custom queries and charts using the query builder. To learn how to query this data, see Understand data. Query your data Data reported by this integration is displayed in its dashboards and is also available for querying and the creation of custom charts and dashboards. This integration reports an EcsClusterSample event, with attributes clusterName, awsRegion, ecsLaunchType and arn. Other types of data that may be available for querying: Infrastructure agent-reported events, including Docker All the events reported from an ECS cluster contain the attributes ecsClusterName, ecsLaunchType and ecsClusterArn. Here's an example NRQL query that returns the count of containers associated with each Docker image in an ECS cluster named MyClusterName created in us-east-1: SELECT uniqueCount(containerId) FROM ContainerSample WHERE awsRegion = 'us-east-1' AND ecsClusterName = 'MyClusterName' FACET imageName SINCE 1 HOUR AGO Copy To learn more about creating custom queries and charts: How to query New Relic data Introduction to NRQL",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.45058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "sections": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Here we explain how to find, <em>understand</em>, and <em>use</em> the <em>data</em> reported by this <em>integration</em>. View <em>data</em> To view the ECS <em>integration</em> dashboard: Go to one.newrelic.com and select Explorer"
      },
      "id": "617db48de7b9d24953c05054"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-25T12:41:13Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.47656,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the placeholder busybox <em>container</em>. Next steps: Wait a few minutes and then look for your <em>data</em> in the UI. Recommended: Install our ECS cloud <em>integration</em>, which gets you other ECS <em>data</em>, including information about clusters and services. See recommended alert conditions. <em>Understand</em> the AWS resources"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-25T12:41:12Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.4218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation <em>Use</em> automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/understand-use-data/understand-use-ecs-data": [
    {
      "sections": [
        "Recommended ECS alert conditions",
        "Recommended alert conditions"
      ],
      "title": "Recommended ECS alert conditions",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "2adc4dd0bff89ea0d3e05fa756ba4d30adf9bf53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions/",
      "published_at": "2021-12-25T12:41:59Z",
      "updated_at": "2021-10-24T01:53:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go to the Alerts UI and add the following NRQL alert conditions to an existing or new alert policy: High CPU usage NRQL: FROM ContainerSample SELECT cpuUsedCoresPercent Critical: > 90% for 5 minutes High memory usage NRQL: FROM ContainerSample SELECT memoryUsageBytes / memorySizeLimitBytes Critical: > 80% for 5 minutes Restart count NRQL: FROM ContainerSample SELECT max(restartCount) - min(restartCount) Critical: > 5 for 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.56151,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go"
      },
      "id": "617db48e64441f3722fbe764"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-25T12:41:13Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.47656,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the placeholder busybox <em>container</em>. Next steps: Wait a few minutes and then look for your <em>data</em> in the UI. Recommended: Install our ECS cloud <em>integration</em>, which gets you other ECS <em>data</em>, including information about clusters and services. See recommended alert conditions. <em>Understand</em> the AWS resources"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-25T12:41:12Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.4218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation <em>Use</em> automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-app-engine-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-25T12:46:13Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.95204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-25T12:43:22Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.95071,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-25T12:44:05Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.98444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-bigquery-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-25T12:46:13Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.95203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-25T12:43:22Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.95071,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-25T12:44:05Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.98444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-bigtable-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-25T12:46:13Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.95203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-25T12:43:22Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.95071,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-25T12:44:05Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.98444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-25T12:46:13Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.95203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-25T12:43:22Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.9507,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-25T12:44:05Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.98444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ]
}